{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a modification of the evaluate_target_network_on_evaluation file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run this only if you dont have these folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# mkdir results\n",
    "# mkdir formatted_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import target_network_raw_emg_enhanced\n",
    "import load_pre_training_dataset\n",
    "import load_evaluation_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method to shuffle examples and labels\n",
    "\n",
    "As we went over before, shuffling is used to introduce randomness and reduce the chances that the model will be able to learn any bias in the order of the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble(examples, labels, second_labels=[]):\n",
    "    random_vec = np.arange(len(labels))\n",
    "    np.random.shuffle(random_vec)\n",
    "    new_labels = []\n",
    "    new_examples = []\n",
    "    if len(second_labels) == len(labels):\n",
    "        new_second_labels = []\n",
    "        for i in random_vec:\n",
    "            new_labels.append(labels[i])\n",
    "            new_examples.append(examples[i])\n",
    "            new_second_labels.append(second_labels[i])\n",
    "        return new_examples, new_labels, new_second_labels\n",
    "    else:\n",
    "        for i in random_vec:\n",
    "            new_labels.append(labels[i])\n",
    "            new_examples.append(examples[i])\n",
    "        return new_examples, new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to calculate the pre training network\n",
    "\n",
    "The reason begind the j in range 19 is that there are 19 patients\n",
    "The reason that we have the k<21 is that there should be 5 times 7=35 total entries for data points and we want to use the first 3 times 7=21 for training and the rest for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pre_training(examples, labels):\n",
    "    list_train_dataloader = []\n",
    "    list_validation_dataloader = []\n",
    "    human_number = 0\n",
    "    for j in range(19):\n",
    "        # 19 patients \n",
    "        examples_personne_training = []\n",
    "        labels_gesture_personne_training = []\n",
    "        labels_human_personne_training = []\n",
    "\n",
    "        examples_personne_valid = []\n",
    "        labels_gesture_personne_valid = []\n",
    "        labels_human_personne_valid = []\n",
    "\n",
    "        for k in range(len(examples[j])):\n",
    "            if k < 21:\n",
    "                examples_personne_training.extend(examples[j][k])\n",
    "                labels_gesture_personne_training.extend(labels[j][k])\n",
    "                labels_human_personne_training.extend(human_number * np.ones(len(labels[j][k])))\n",
    "            else:\n",
    "                examples_personne_valid.extend(examples[j][k])\n",
    "                labels_gesture_personne_valid.extend(labels[j][k])\n",
    "                labels_human_personne_valid.extend(human_number * np.ones(len(labels[j][k])))\n",
    "\n",
    "        print(np.shape(examples_personne_training))\n",
    "        examples_personne_scrambled, labels_gesture_personne_scrambled, labels_human_personne_scrambled = scramble(\n",
    "            examples_personne_training, labels_gesture_personne_training, labels_human_personne_training)\n",
    "\n",
    "        examples_personne_scrambled_valid, labels_gesture_personne_scrambled_valid, labels_human_personne_scrambled_valid = scramble(\n",
    "            examples_personne_valid, labels_gesture_personne_valid, labels_human_personne_valid)\n",
    "\n",
    "        \n",
    "        # Create the training and validaiton datasets\n",
    "        train = TensorDataset(torch.from_numpy(np.array(examples_personne_scrambled, dtype=np.float32)),\n",
    "                              torch.from_numpy(np.array(labels_gesture_personne_scrambled, dtype=np.int64)))\n",
    "        validation = TensorDataset(torch.from_numpy(np.array(examples_personne_scrambled_valid, dtype=np.float32)),\n",
    "                                   torch.from_numpy(np.array(labels_gesture_personne_scrambled_valid, dtype=np.int64)))\n",
    "\n",
    "        trainLoader = torch.utils.data.DataLoader(train, batch_size=3315, shuffle=True, drop_last=True)\n",
    "        validationLoader = torch.utils.data.DataLoader(validation, batch_size=1312, shuffle=True, drop_last=True)\n",
    "\n",
    "        list_train_dataloader.append(trainLoader)\n",
    "        list_validation_dataloader.append(validationLoader)\n",
    "\n",
    "        human_number += 1\n",
    "        print(\"Shape training : \", np.shape(examples_personne_scrambled))\n",
    "        print(\"Shape valid : \", np.shape(examples_personne_scrambled_valid))\n",
    "\n",
    "    cnn = target_network_raw_emg_enhanced.SourceNetwork(number_of_class=7, dropout_rate=.35).cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "    optimizer = optim.Adam(cnn.parameters(), lr=0.002335721469090121)\n",
    "    precision = 1e-8\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=.2, patience=15,\n",
    "                                                     verbose=True, eps=precision)\n",
    "\n",
    "    pre_train_model(cnn, criterion=criterion, optimizer=optimizer, scheduler=scheduler,\n",
    "                    dataloaders={\"train\": list_train_dataloader, \"val\": list_validation_dataloader},\n",
    "                    precision=precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train model\n",
    "This is a method that is used to pre train the source network.  At the end this prints out the best validation loss and then saves the cnn weights to a file so that they can be accessed later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_train_model(cnn, criterion, optimizer, scheduler, dataloaders, num_epochs=500, precision=1e-8):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a list of dictionaries that will hold the weights of the batch normalisation layers for each dataset\n",
    "    #  (i.e. each participants)\n",
    "    list_dictionaries_BN_weights = []\n",
    "    for index_BN_weights in range(len(dataloaders['val'])):\n",
    "        state_dict = cnn.state_dict()\n",
    "        batch_norm_dict = {}\n",
    "        for key in state_dict:\n",
    "            if \"batch_norm\" in key:\n",
    "                batch_norm_dict.update({key: state_dict[key]})\n",
    "        list_dictionaries_BN_weights.append(copy.deepcopy(batch_norm_dict))\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    best_weights = copy.deepcopy(cnn.state_dict())\n",
    "\n",
    "    patience = 30\n",
    "    patience_increase = 30\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                cnn.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                cnn.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_corrects = 0\n",
    "            total = 0\n",
    "\n",
    "            # Get a random order for the training dataset\n",
    "            random_vec = np.arange(len(dataloaders[phase]))\n",
    "            np.random.shuffle(random_vec)\n",
    "\n",
    "            for dataset_index in random_vec:\n",
    "                # Retrieves the BN weights calculated so far for this dataset\n",
    "                BN_weights = list_dictionaries_BN_weights[dataset_index]\n",
    "                cnn.load_state_dict(BN_weights, strict=False)\n",
    "\n",
    "                loss_over_datasets = 0.\n",
    "                correct_over_datasets = 0.\n",
    "                for i, data in enumerate(dataloaders[phase][dataset_index], 0):\n",
    "                    # get the inputs\n",
    "                    inputs, labels = data\n",
    "\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    if phase == 'train':\n",
    "                        cnn.train()\n",
    "                        # forward\n",
    "                        outputs = cnn(inputs)\n",
    "                        _, predictions = torch.max(outputs.data, 1)\n",
    "                        # backward\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        loss = loss.item()\n",
    "\n",
    "                    else:\n",
    "                        cnn.eval()\n",
    "                        # forward\n",
    "                        outputs = cnn(inputs)\n",
    "                        _, predictions = torch.max(outputs.data, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        loss = loss.item()\n",
    "                    # Statistic for this dataset\n",
    "                    loss_over_datasets += loss\n",
    "                    correct_over_datasets += torch.sum(predictions == labels.data)\n",
    "                    total += labels.size(0)\n",
    "                # Statistic global\n",
    "                running_loss += loss_over_datasets\n",
    "                running_corrects += correct_over_datasets\n",
    "\n",
    "                # Save the BN statistics for this dataset\n",
    "                state_dict = cnn.state_dict()\n",
    "                batch_norm_dict = {}\n",
    "                for key in state_dict:\n",
    "                    if \"batch_norm\" in key:\n",
    "                        batch_norm_dict.update({key: state_dict[key]})\n",
    "                list_dictionaries_BN_weights[dataset_index] = copy.deepcopy(batch_norm_dict)\n",
    "\n",
    "            epoch_loss = running_loss / total\n",
    "            epoch_acc = running_corrects.item() / total\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                scheduler.step(epoch_loss)\n",
    "                if epoch_loss + precision < best_loss:\n",
    "                    print(\"New best validation loss:\", epoch_loss)\n",
    "                    best_loss = epoch_loss\n",
    "                    best_weights = copy.deepcopy(cnn.state_dict())\n",
    "                    patience = patience_increase + epoch\n",
    "            print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "                epoch + 1, num_epochs, time.time() - epoch_start))\n",
    "        if epoch > patience:\n",
    "            break\n",
    "\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # Save the best weights found to file\n",
    "    torch.save(best_weights, 'convnet_weights/best_pre_train_weights_target_raw.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Fitness\n",
    "This is a very large method that is involved in training the target network for all 17 of the individuals. The examples and labels are self explanatory, but it is important to see that for some reason there are two testing sets. The parameter for the training cycle is an integer that is used to see how many of each movement should be included in the training set. making this number equal to 4 will ensure that all the data is used. Changing this variable would be a good way to test how much training data the network \"needs\" from each new individual to be accurate enough.\n",
    "\n",
    "At the end, it prints the average on test set 0 and 1 averaged over all 17 of the individuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(examples_training, labels_training, examples_test0, labels_test0, examples_test1, labels_test_1,\n",
    "                      learning_rate=.1, training_cycle=4):\n",
    "    accuracy_test0 = []\n",
    "    accuracy_test1 = []\n",
    "    for j in range(17): #17 individuals\n",
    "        print(\"CURRENT DATASET : \", j)\n",
    "        examples_personne_training = []\n",
    "        labels_gesture_personne_training = []\n",
    "        \n",
    "        for k in range(len(examples_training[j])):\n",
    "            if k < training_cycle * 7:\n",
    "                examples_personne_training.extend(examples_training[j][k])\n",
    "                labels_gesture_personne_training.extend(labels_training[j][k])\n",
    "        \n",
    "        X_test_0, Y_test_0 = [], []\n",
    "        for k in range(len(examples_test0)):\n",
    "            X_test_0.extend(examples_test0[j][k])\n",
    "            Y_test_0.extend(labels_test0[j][k])\n",
    "        \n",
    "        X_test_1, Y_test_1 = [], []\n",
    "        for k in range(len(examples_test1)):\n",
    "            X_test_1.extend(examples_test1[j][k])\n",
    "            Y_test_1.extend(labels_test_1[j][k])\n",
    "            \n",
    "        if training_cycle == 0:\n",
    "            cnn = target_network_raw_emg_enhanced.SourceNetwork(number_of_class=7, dropout_rate=.35).cuda()\n",
    "            cnn.eval()\n",
    "            X_test_0, Y_test_0 = scramble(X_test_0, Y_test_0)\n",
    "\n",
    "            test_0 = TensorDataset(torch.from_numpy(np.array(X_test_0, dtype=np.float32)),\n",
    "                                   torch.from_numpy(np.array(Y_test_0, dtype=np.int64)))\n",
    "\n",
    "            X_test_1, Y_test_1 = scramble(X_test_1, Y_test_1)\n",
    "\n",
    "            test_1 = TensorDataset(torch.from_numpy(np.array(X_test_1, dtype=np.float32)),\n",
    "                                   torch.from_numpy(np.array(Y_test_1, dtype=np.int64)))\n",
    "\n",
    "            test_0_loader = torch.utils.data.DataLoader(test_0, batch_size=256, shuffle=False)\n",
    "            total = 0\n",
    "            correct_prediction_test_0 = 0\n",
    "            for k, data_test_0 in enumerate(test_0_loader, 0):\n",
    "                # get the inputs\n",
    "                inputs_test_0, ground_truth_test_0 = data_test_0\n",
    "                inputs_test_0, ground_truth_test_0 = Variable(inputs_test_0.cuda()), Variable(\n",
    "                    ground_truth_test_0.cuda())\n",
    "    \n",
    "                outputs_test_0 = cnn(inputs_test_0)\n",
    "                _, predicted = torch.max(outputs_test_0.data, 1)\n",
    "                correct_prediction_test_0 += (predicted.cpu().numpy() == ground_truth_test_0.data.cpu().numpy()).sum()\n",
    "                total += ground_truth_test_0.size(0)\n",
    "            print(\"ACCURACY TEST_0 FINAL : %.3f %%\" % (100 * float(correct_prediction_test_0) / float(total)))\n",
    "            accuracy_test0.append(100 * float(correct_prediction_test_0) / float(total))\n",
    "\n",
    "            test_1_loader = torch.utils.data.DataLoader(test_1, batch_size=256, shuffle=False)\n",
    "            total = 0\n",
    "            correct_prediction_test_1 = 0\n",
    "            for k, data_test_1 in enumerate(test_1_loader, 0):\n",
    "                # get the inputs\n",
    "                inputs_test_1, ground_truth_test_1 = data_test_1\n",
    "                inputs_test_1, ground_truth_test_1 = Variable(inputs_test_1.cuda()), Variable(\n",
    "                    ground_truth_test_1.cuda())\n",
    "    \n",
    "                outputs_test_1 = cnn(inputs_test_1)\n",
    "                _, predicted = torch.max(outputs_test_1.data, 1)\n",
    "                correct_prediction_test_1 += (predicted.cpu().numpy() == ground_truth_test_1.data.cpu().numpy()).sum()\n",
    "                total += ground_truth_test_1.size(0)\n",
    "            print(\"ACCURACY TEST_1 FINAL : %.3f %%\" % (100 * float(correct_prediction_test_1) / float(total)))\n",
    "            accuracy_test1.append(100 * float(correct_prediction_test_1) / float(total))\n",
    "        else:\n",
    "            print(np.shape(examples_personne_training))\n",
    "            examples_personne_scrambled, labels_gesture_personne_scrambled = scramble(examples_personne_training,\n",
    "                                                                                      labels_gesture_personne_training)\n",
    "            valid_examples = examples_personne_scrambled[0:int(len(examples_personne_scrambled) * 0.1)]\n",
    "            labels_valid = labels_gesture_personne_scrambled[0:int(len(labels_gesture_personne_scrambled) * 0.1)]\n",
    "            \n",
    "            X_fine_tune = examples_personne_scrambled[int(len(examples_personne_scrambled) * 0.1):]\n",
    "            Y_fine_tune = labels_gesture_personne_scrambled[int(len(labels_gesture_personne_scrambled) * 0.1):]\n",
    "            \n",
    "            \n",
    "            train = TensorDataset(torch.from_numpy(np.array(X_fine_tune, dtype=np.float32)),\n",
    "                                  torch.from_numpy(np.array(Y_fine_tune, dtype=np.int64)))\n",
    "            \n",
    "            validation = TensorDataset(torch.from_numpy(np.array(valid_examples, dtype=np.float32)),\n",
    "                                       torch.from_numpy(np.array(labels_valid, dtype=np.int64)))\n",
    "            \n",
    "            trainloader = torch.utils.data.DataLoader(train, batch_size=256, shuffle=True, drop_last=True)\n",
    "            validationloader = torch.utils.data.DataLoader(validation, batch_size=128, shuffle=True, drop_last=True)\n",
    "    \n",
    "            pre_trained_weights = torch.load('convnet_weights/best_pre_train_weights_target_raw.pt')\n",
    "            cnn = target_network_raw_emg_enhanced.TargetNetwork(number_of_class=7,\n",
    "                                                                weights_pre_trained_convnet=pre_trained_weights,\n",
    "                                                                dropout=.5).cuda()\n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "            \n",
    "            precision = 1e-6\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=.2, patience=5,\n",
    "                                                             verbose=True, eps=precision)\n",
    "            \n",
    "            cnn = train_model(cnn, criterion, optimizer, scheduler, dataloaders={\"train\": trainloader,\n",
    "                                                                                 \"val\": validationloader},\n",
    "                              precision=precision)\n",
    "            \n",
    "            cnn.eval()\n",
    "            X_test_0, Y_test_0 = scramble(X_test_0, Y_test_0)\n",
    "            \n",
    "            test_0 = TensorDataset(torch.from_numpy(np.array(X_test_0, dtype=np.float32)),\n",
    "                                   torch.from_numpy(np.array(Y_test_0, dtype=np.int64)))\n",
    "            \n",
    "            X_test_1, Y_test_1 = scramble(X_test_1, Y_test_1)\n",
    "            \n",
    "            test_1 = TensorDataset(torch.from_numpy(np.array(X_test_1, dtype=np.float32)),\n",
    "                                   torch.from_numpy(np.array(Y_test_1, dtype=np.int64)))\n",
    "            \n",
    "            test_0_loader = torch.utils.data.DataLoader(test_0, batch_size=256, shuffle=False)\n",
    "            total = 0\n",
    "            correct_prediction_test_0 = 0\n",
    "            for k, data_test_0 in enumerate(test_0_loader, 0):\n",
    "                # get the inputs\n",
    "                inputs_test_0, ground_truth_test_0 = data_test_0\n",
    "                inputs_test_0, ground_truth_test_0 = Variable(inputs_test_0.cuda()), Variable(ground_truth_test_0.cuda())\n",
    "                \n",
    "                outputs_test_0 = cnn(inputs_test_0)\n",
    "                _, predicted = torch.max(outputs_test_0.data, 1)\n",
    "                correct_prediction_test_0 += (predicted.cpu().numpy() == ground_truth_test_0.data.cpu().numpy()).sum()\n",
    "                total += ground_truth_test_0.size(0)\n",
    "            print(\"ACCURACY TEST_0 FINAL : %.3f %%\" % (100 * float(correct_prediction_test_0) / float(total)))\n",
    "            accuracy_test0.append(100 * float(correct_prediction_test_0) / float(total))\n",
    "            \n",
    "            test_1_loader = torch.utils.data.DataLoader(test_1, batch_size=256, shuffle=False)\n",
    "            total = 0\n",
    "            correct_prediction_test_1 = 0\n",
    "            for k, data_test_1 in enumerate(test_1_loader, 0):\n",
    "                # get the inputs\n",
    "                inputs_test_1, ground_truth_test_1 = data_test_1\n",
    "                inputs_test_1, ground_truth_test_1 = Variable(inputs_test_1.cuda()), Variable(ground_truth_test_1.cuda())\n",
    "                \n",
    "                outputs_test_1 = cnn(inputs_test_1)\n",
    "                _, predicted = torch.max(outputs_test_1.data, 1)\n",
    "                correct_prediction_test_1 += (predicted.cpu().numpy() == ground_truth_test_1.data.cpu().numpy()).sum()\n",
    "                total += ground_truth_test_1.size(0)\n",
    "            print(\"ACCURACY TEST_1 FINAL : %.3f %%\" % (100 * float(correct_prediction_test_1) / float(total)))\n",
    "            accuracy_test1.append(100 * float(correct_prediction_test_1) / float(total))\n",
    "    \n",
    "    print(\"AVERAGE ACCURACY TEST 0 %.3f\" % np.array(accuracy_test0).mean())\n",
    "    print(\"AVERAGE ACCURACY TEST 1 %.3f\" % np.array(accuracy_test1).mean())\n",
    "    return accuracy_test0, accuracy_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "This takes in the dataloaders and the cnn and simply just trains the cnn and returns it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(cnn, criterion, optimizer, scheduler, dataloaders, num_epochs=500, precision=1e-8):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    patience = 30\n",
    "    patience_increase = 10\n",
    "    \n",
    "    best_weights = copy.deepcopy(cnn.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                cnn.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                cnn.train(False)  # Set model to evaluate mode\n",
    "            \n",
    "            running_loss = 0.\n",
    "            running_corrects = 0\n",
    "            total = 0\n",
    "            \n",
    "            for i, data in enumerate(dataloaders[phase], 0):\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                if phase == 'train':\n",
    "                    cnn.train()\n",
    "                    # forward\n",
    "                    outputs = cnn(inputs)\n",
    "                    _, predictions = torch.max(outputs.data, 1)\n",
    "                    # backward\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    loss = loss.item()\n",
    "                \n",
    "                else:\n",
    "                    cnn.eval()\n",
    "                    # forward\n",
    "                    outputs = cnn(inputs)\n",
    "                    _, predictions = torch.max(outputs.data, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss = loss.item()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss\n",
    "                running_corrects += torch.sum(predictions == labels.data)\n",
    "                total += labels.size(0)\n",
    "        \n",
    "            epoch_loss = running_loss / total\n",
    "            epoch_acc = running_corrects.item() / total\n",
    "            \n",
    "            print('{} Loss: {} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                scheduler.step(epoch_loss)\n",
    "                if epoch_loss + precision < best_loss:\n",
    "                    print(\"New best validation loss:\", epoch_loss)\n",
    "                    best_loss = epoch_loss\n",
    "                    best_weights = copy.deepcopy(cnn.state_dict())\n",
    "                    patience = patience_increase + epoch\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - epoch_start))\n",
    "        if epoch > patience:\n",
    "            break\n",
    "    print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    \n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    # load best model weights\n",
    "    cnn.load_state_dict(copy.deepcopy(best_weights))\n",
    "    cnn.eval()\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Training Dataset and Pre-Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment between here    \n",
    "# examples, labels = load_pre_training_dataset.read_data('../../PreTrainingDataset')\n",
    "# datasets = [examples, labels]\n",
    "\n",
    "# np.save(\"formatted_datasets/saved_pre_training_dataset_spectrogram.npy\", datasets)\n",
    "# And here if the pre-training dataset was already processed and saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3981, 1, 8, 52)\n",
      "Shape training :  (3981, 1, 8, 52)\n",
      "Shape valid :  (1330, 1, 8, 52)\n",
      "(3983, 1, 8, 52)\n",
      "Shape training :  (3983, 1, 8, 52)\n",
      "Shape valid :  (1327, 1, 8, 52)\n",
      "(3976, 1, 8, 52)\n",
      "Shape training :  (3976, 1, 8, 52)\n",
      "Shape valid :  (1328, 1, 8, 52)\n",
      "(3981, 1, 8, 52)\n",
      "Shape training :  (3981, 1, 8, 52)\n",
      "Shape valid :  (1327, 1, 8, 52)\n",
      "(3984, 1, 8, 52)\n",
      "Shape training :  (3984, 1, 8, 52)\n",
      "Shape valid :  (1328, 1, 8, 52)\n",
      "(3983, 1, 8, 52)\n",
      "Shape training :  (3983, 1, 8, 52)\n",
      "Shape valid :  (1325, 1, 8, 52)\n",
      "(3985, 1, 8, 52)\n",
      "Shape training :  (3985, 1, 8, 52)\n",
      "Shape valid :  (1329, 1, 8, 52)\n",
      "(3986, 1, 8, 52)\n",
      "Shape training :  (3986, 1, 8, 52)\n",
      "Shape valid :  (1326, 1, 8, 52)\n",
      "(3982, 1, 8, 52)\n",
      "Shape training :  (3982, 1, 8, 52)\n",
      "Shape valid :  (1329, 1, 8, 52)\n",
      "(3983, 1, 8, 52)\n",
      "Shape training :  (3983, 1, 8, 52)\n",
      "Shape valid :  (1327, 1, 8, 52)\n",
      "(3984, 1, 8, 52)\n",
      "Shape training :  (3984, 1, 8, 52)\n",
      "Shape valid :  (1330, 1, 8, 52)\n",
      "(3991, 1, 8, 52)\n",
      "Shape training :  (3991, 1, 8, 52)\n",
      "Shape valid :  (1327, 1, 8, 52)\n",
      "(3990, 1, 8, 52)\n",
      "Shape training :  (3990, 1, 8, 52)\n",
      "Shape valid :  (1330, 1, 8, 52)\n",
      "(3969, 1, 8, 52)\n",
      "Shape training :  (3969, 1, 8, 52)\n",
      "Shape valid :  (1323, 1, 8, 52)\n",
      "(3297, 1, 8, 52)\n",
      "Shape training :  (3297, 1, 8, 52)\n",
      "Shape valid :  (1099, 1, 8, 52)\n",
      "(3990, 1, 8, 52)\n",
      "Shape training :  (3990, 1, 8, 52)\n",
      "Shape valid :  (1330, 1, 8, 52)\n",
      "(3990, 1, 8, 52)\n",
      "Shape training :  (3990, 1, 8, 52)\n",
      "Shape valid :  (1330, 1, 8, 52)\n",
      "(3990, 1, 8, 52)\n",
      "Shape training :  (3990, 1, 8, 52)\n",
      "Shape valid :  (1330, 1, 8, 52)\n",
      "(4011, 1, 8, 52)\n",
      "Shape training :  (4011, 1, 8, 52)\n",
      "Shape valid :  (1337, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.35, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.35, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.35, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 1.53279836 Acc: 0.50474275\n",
      "Epoch 1 of 500 took 6.537s\n",
      "val Loss: 29.05439212 Acc: 0.47649898\n",
      "New best validation loss: 29.054392117471878\n",
      "Epoch 1 of 500 took 6.862s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.85717918 Acc: 0.70955254\n",
      "Epoch 2 of 500 took 1.380s\n",
      "val Loss: 10.74891231 Acc: 0.56241531\n",
      "New best validation loss: 10.74891231166638\n",
      "Epoch 2 of 500 took 1.694s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.66548084 Acc: 0.77769398\n",
      "Epoch 3 of 500 took 1.480s\n",
      "val Loss: 8.07471293 Acc: 0.53950711\n",
      "New best validation loss: 8.074712932352128\n",
      "Epoch 3 of 500 took 1.803s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.61574299 Acc: 0.79889392\n",
      "Epoch 4 of 500 took 1.550s\n",
      "val Loss: 2.55770594 Acc: 0.59353828\n",
      "New best validation loss: 2.557705941400554\n",
      "Epoch 4 of 500 took 1.869s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.59969415 Acc: 0.80000000\n",
      "Epoch 5 of 500 took 1.495s\n",
      "val Loss: 2.44739028 Acc: 0.65984925\n",
      "New best validation loss: 2.447390279634212\n",
      "Epoch 5 of 500 took 1.819s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.49931223 Acc: 0.83324954\n",
      "Epoch 6 of 500 took 1.425s\n",
      "val Loss: 3.57653475 Acc: 0.62593157\n",
      "Epoch 6 of 500 took 1.743s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.56251380 Acc: 0.81023965\n",
      "Epoch 7 of 500 took 1.397s\n",
      "val Loss: 1.88505233 Acc: 0.70431064\n",
      "New best validation loss: 1.8850523264104435\n",
      "Epoch 7 of 500 took 1.709s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.48130562 Acc: 0.84571812\n",
      "Epoch 8 of 500 took 1.445s\n",
      "val Loss: 2.13251839 Acc: 0.50588584\n",
      "Epoch 8 of 500 took 1.758s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.48157018 Acc: 0.83479135\n",
      "Epoch 9 of 500 took 1.402s\n",
      "val Loss: 1.17371008 Acc: 0.75050813\n",
      "New best validation loss: 1.1737100803432103\n",
      "Epoch 9 of 500 took 1.748s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.41716961 Acc: 0.85473437\n",
      "Epoch 10 of 500 took 1.531s\n",
      "val Loss: 0.70067956 Acc: 0.78764397\n",
      "New best validation loss: 0.7006795626022628\n",
      "Epoch 10 of 500 took 1.844s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.36986128 Acc: 0.87972180\n",
      "Epoch 11 of 500 took 1.357s\n",
      "val Loss: 1.19283060 Acc: 0.77049458\n",
      "Epoch 11 of 500 took 1.671s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.40546945 Acc: 0.86458857\n",
      "Epoch 12 of 500 took 1.410s\n",
      "val Loss: 0.96712062 Acc: 0.79056572\n",
      "Epoch 12 of 500 took 1.679s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.38862840 Acc: 0.87404056\n",
      "Epoch 13 of 500 took 1.440s\n",
      "val Loss: 0.51282297 Acc: 0.84684112\n",
      "New best validation loss: 0.5128229678807866\n",
      "Epoch 13 of 500 took 1.752s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.33571651 Acc: 0.89798894\n",
      "Epoch 14 of 500 took 1.383s\n",
      "val Loss: 0.63178538 Acc: 0.82914126\n",
      "Epoch 14 of 500 took 1.693s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.30817043 Acc: 0.90056980\n",
      "Epoch 15 of 500 took 1.422s\n",
      "val Loss: 0.41632247 Acc: 0.86792852\n",
      "New best validation loss: 0.4163224700343641\n",
      "Epoch 15 of 500 took 1.737s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.31325105 Acc: 0.90224568\n",
      "Epoch 16 of 500 took 1.367s\n",
      "val Loss: 0.73999080 Acc: 0.68665312\n",
      "Epoch 16 of 500 took 1.675s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.26828108 Acc: 0.91704374\n",
      "Epoch 17 of 500 took 1.454s\n",
      "val Loss: 0.46655558 Acc: 0.86056064\n",
      "Epoch 17 of 500 took 1.778s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.26971183 Acc: 0.91298810\n",
      "Epoch 18 of 500 took 1.475s\n",
      "val Loss: 0.54132686 Acc: 0.80377710\n",
      "Epoch 18 of 500 took 1.826s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.32025100 Acc: 0.89872633\n",
      "Epoch 19 of 500 took 1.399s\n",
      "val Loss: 0.56145978 Acc: 0.83362974\n",
      "Epoch 19 of 500 took 1.705s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.32200961 Acc: 0.89750293\n",
      "Epoch 20 of 500 took 1.362s\n",
      "val Loss: 0.38022665 Acc: 0.86543022\n",
      "New best validation loss: 0.38022664500284326\n",
      "Epoch 20 of 500 took 1.673s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.26830393 Acc: 0.91680912\n",
      "Epoch 21 of 500 took 1.413s\n",
      "val Loss: 0.45886784 Acc: 0.86094173\n",
      "Epoch 21 of 500 took 1.725s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.29335401 Acc: 0.90180995\n",
      "Epoch 22 of 500 took 1.364s\n",
      "val Loss: 0.67389057 Acc: 0.73009824\n",
      "Epoch 22 of 500 took 1.675s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.27981389 Acc: 0.91307190\n",
      "Epoch 23 of 500 took 1.408s\n",
      "val Loss: 0.36160581 Acc: 0.88274898\n",
      "New best validation loss: 0.36160581027912253\n",
      "Epoch 23 of 500 took 1.683s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.24728416 Acc: 0.92084800\n",
      "Epoch 24 of 500 took 1.401s\n",
      "val Loss: 0.35573362 Acc: 0.88224085\n",
      "New best validation loss: 0.3557336191497844\n",
      "Epoch 24 of 500 took 1.718s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.23224611 Acc: 0.93147310\n",
      "Epoch 25 of 500 took 1.357s\n",
      "val Loss: 0.57110457 Acc: 0.82914126\n",
      "Epoch 25 of 500 took 1.666s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.25202906 Acc: 0.92094855\n",
      "Epoch 26 of 500 took 1.438s\n",
      "val Loss: 0.31315852 Acc: 0.90548780\n",
      "New best validation loss: 0.313158515669143\n",
      "Epoch 26 of 500 took 1.798s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.21502802 Acc: 0.93231104\n",
      "Epoch 27 of 500 took 1.449s\n",
      "val Loss: 0.48699758 Acc: 0.83375678\n",
      "Epoch 27 of 500 took 1.766s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.20193157 Acc: 0.93546171\n",
      "Epoch 28 of 500 took 1.414s\n",
      "val Loss: 0.39493411 Acc: 0.85586043\n",
      "Epoch 28 of 500 took 1.728s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.18362404 Acc: 0.94196414\n",
      "Epoch 29 of 500 took 1.361s\n",
      "val Loss: 0.29142264 Acc: 0.92771850\n",
      "New best validation loss: 0.29142264008198976\n",
      "Epoch 29 of 500 took 1.675s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.18008190 Acc: 0.94328808\n",
      "Epoch 30 of 500 took 1.399s\n",
      "val Loss: 0.30188613 Acc: 0.91493056\n",
      "Epoch 30 of 500 took 1.717s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.17422898 Acc: 0.94772918\n",
      "Epoch 31 of 500 took 1.354s\n",
      "val Loss: 0.38052480 Acc: 0.84722222\n",
      "Epoch 31 of 500 took 1.664s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.17490746 Acc: 0.94648902\n",
      "Epoch 32 of 500 took 1.403s\n",
      "val Loss: 0.59166475 Acc: 0.73475610\n",
      "Epoch 32 of 500 took 1.711s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.20134646 Acc: 0.93777443\n",
      "Epoch 33 of 500 took 1.396s\n",
      "val Loss: 0.31890395 Acc: 0.91175474\n",
      "Epoch 33 of 500 took 1.712s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.17637713 Acc: 0.94360650\n",
      "Epoch 34 of 500 took 1.405s\n",
      "val Loss: 0.35786751 Acc: 0.87576220\n",
      "Epoch 34 of 500 took 1.672s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.16124525 Acc: 0.94910340\n",
      "Epoch 35 of 500 took 1.442s\n",
      "val Loss: 0.30816421 Acc: 0.90654641\n",
      "Epoch 35 of 500 took 1.817s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.14474743 Acc: 0.95552204\n",
      "Epoch 36 of 500 took 1.422s\n",
      "val Loss: 0.43139665 Acc: 0.80237974\n",
      "Epoch 36 of 500 took 1.735s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.14588165 Acc: 0.95471761\n",
      "Epoch 37 of 500 took 1.402s\n",
      "val Loss: 0.22134377 Acc: 0.94634993\n",
      "New best validation loss: 0.22134377066358965\n",
      "Epoch 37 of 500 took 1.724s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.14822825 Acc: 0.95155019\n",
      "Epoch 38 of 500 took 1.363s\n",
      "val Loss: 0.41851656 Acc: 0.82596545\n",
      "Epoch 38 of 500 took 1.673s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.15228423 Acc: 0.95175130\n",
      "Epoch 39 of 500 took 1.732s\n",
      "val Loss: 0.19967084 Acc: 0.94884824\n",
      "New best validation loss: 0.199670835804487\n",
      "Epoch 39 of 500 took 2.139s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.14136291 Acc: 0.95344394\n",
      "Epoch 40 of 500 took 1.493s\n",
      "val Loss: 0.35392019 Acc: 0.85645325\n",
      "Epoch 40 of 500 took 1.807s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.13074701 Acc: 0.96073404\n",
      "Epoch 41 of 500 took 1.488s\n",
      "val Loss: 0.26511291 Acc: 0.91742886\n",
      "Epoch 41 of 500 took 1.797s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.13080340 Acc: 0.95941009\n",
      "Epoch 42 of 500 took 1.360s\n",
      "val Loss: 0.19390613 Acc: 0.94630759\n",
      "New best validation loss: 0.19390612695275283\n",
      "Epoch 42 of 500 took 1.672s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.13082622 Acc: 0.95837104\n",
      "Epoch 43 of 500 took 1.512s\n",
      "val Loss: 0.27122875 Acc: 0.91349085\n",
      "Epoch 43 of 500 took 1.822s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.12344932 Acc: 0.96291269\n",
      "Epoch 44 of 500 took 1.495s\n",
      "val Loss: 0.18436478 Acc: 0.95702066\n",
      "New best validation loss: 0.18436477807802237\n",
      "Epoch 44 of 500 took 1.820s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.11940612 Acc: 0.96331490\n",
      "Epoch 45 of 500 took 1.356s\n",
      "val Loss: 0.18545228 Acc: 0.94474085\n",
      "Epoch 45 of 500 took 1.664s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.12171917 Acc: 0.96125356\n",
      "Epoch 46 of 500 took 1.442s\n",
      "val Loss: 0.28322563 Acc: 0.88630589\n",
      "Epoch 46 of 500 took 1.755s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.13058556 Acc: 0.95786828\n",
      "Epoch 47 of 500 took 1.374s\n",
      "val Loss: 0.22018921 Acc: 0.94706978\n",
      "Epoch 47 of 500 took 1.687s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.12696194 Acc: 0.95679571\n",
      "Epoch 48 of 500 took 1.415s\n",
      "val Loss: 0.33753251 Acc: 0.86212737\n",
      "Epoch 48 of 500 took 1.726s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.13648606 Acc: 0.95691302\n",
      "Epoch 49 of 500 took 1.365s\n",
      "val Loss: 0.18526499 Acc: 0.94863652\n",
      "Epoch 49 of 500 took 1.675s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.10376662 Acc: 0.96594604\n",
      "Epoch 50 of 500 took 1.404s\n",
      "val Loss: 0.17535872 Acc: 0.95227812\n",
      "New best validation loss: 0.1753587205074021\n",
      "Epoch 50 of 500 took 1.715s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.09625474 Acc: 0.97239819\n",
      "Epoch 51 of 500 took 1.368s\n",
      "val Loss: 0.24841442 Acc: 0.93775407\n",
      "Epoch 51 of 500 took 1.687s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.10252666 Acc: 0.96529244\n",
      "Epoch 52 of 500 took 1.704s\n",
      "val Loss: 0.19182600 Acc: 0.94893293\n",
      "Epoch 52 of 500 took 2.162s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.09230070 Acc: 0.97306854\n",
      "Epoch 53 of 500 took 1.618s\n",
      "val Loss: 0.14700970 Acc: 0.96443089\n",
      "New best validation loss: 0.14700969698306346\n",
      "Epoch 53 of 500 took 2.026s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.09165584 Acc: 0.97157701\n",
      "Epoch 54 of 500 took 1.486s\n",
      "val Loss: 0.16978498 Acc: 0.96294885\n",
      "Epoch 54 of 500 took 1.752s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.08062993 Acc: 0.97590079\n",
      "Epoch 55 of 500 took 1.442s\n",
      "val Loss: 0.16605211 Acc: 0.95896850\n",
      "Epoch 55 of 500 took 1.767s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.08116838 Acc: 0.97514664\n",
      "Epoch 56 of 500 took 1.439s\n",
      "val Loss: 0.12013031 Acc: 0.97417005\n",
      "New best validation loss: 0.12013030520622646\n",
      "Epoch 56 of 500 took 1.753s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.08732117 Acc: 0.97385621\n",
      "Epoch 57 of 500 took 1.406s\n",
      "val Loss: 0.26907971 Acc: 0.90404810\n",
      "Epoch 57 of 500 took 1.714s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.09052254 Acc: 0.97316910\n",
      "Epoch 58 of 500 took 1.408s\n",
      "val Loss: 0.32736857 Acc: 0.89164126\n",
      "Epoch 58 of 500 took 1.716s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.09019142 Acc: 0.97124183\n",
      "Epoch 59 of 500 took 1.427s\n",
      "val Loss: 0.17679756 Acc: 0.95871443\n",
      "Epoch 59 of 500 took 1.751s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.08749569 Acc: 0.97241495\n",
      "Epoch 60 of 500 took 1.396s\n",
      "val Loss: 0.13919740 Acc: 0.95977304\n",
      "Epoch 60 of 500 took 1.725s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.09158209 Acc: 0.97197922\n",
      "Epoch 61 of 500 took 1.525s\n",
      "val Loss: 0.17086043 Acc: 0.95723238\n",
      "Epoch 61 of 500 took 1.834s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.08723327 Acc: 0.97285068\n",
      "Epoch 62 of 500 took 1.362s\n",
      "val Loss: 0.15308795 Acc: 0.95558096\n",
      "Epoch 62 of 500 took 1.669s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.07318775 Acc: 0.97714094\n",
      "Epoch 63 of 500 took 1.426s\n",
      "val Loss: 0.17427500 Acc: 0.96282182\n",
      "Epoch 63 of 500 took 1.735s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.06963549 Acc: 0.97863248\n",
      "Epoch 64 of 500 took 1.361s\n",
      "val Loss: 0.11882082 Acc: 0.97048611\n",
      "New best validation loss: 0.11882082166952815\n",
      "Epoch 64 of 500 took 1.675s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.06746359 Acc: 0.98081113\n",
      "Epoch 65 of 500 took 1.410s\n",
      "val Loss: 0.10033388 Acc: 0.97336551\n",
      "New best validation loss: 0.10033387523194962\n",
      "Epoch 65 of 500 took 1.680s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.06378192 Acc: 0.98059326\n",
      "Epoch 66 of 500 took 1.397s\n",
      "val Loss: 0.12324879 Acc: 0.97209519\n",
      "Epoch 66 of 500 took 1.702s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.06474746 Acc: 0.98143120\n",
      "Epoch 67 of 500 took 1.391s\n",
      "val Loss: 0.11860080 Acc: 0.97141768\n",
      "Epoch 67 of 500 took 1.698s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.06466186 Acc: 0.97958773\n",
      "Epoch 68 of 500 took 1.429s\n",
      "val Loss: 0.16394869 Acc: 0.95096545\n",
      "Epoch 68 of 500 took 1.738s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.06802980 Acc: 0.97963801\n",
      "Epoch 69 of 500 took 1.394s\n",
      "val Loss: 0.10217031 Acc: 0.96807249\n",
      "Epoch 69 of 500 took 1.754s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.06611187 Acc: 0.97898441\n",
      "Epoch 70 of 500 took 1.514s\n",
      "val Loss: 0.11862874 Acc: 0.96993564\n",
      "Epoch 70 of 500 took 1.829s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.06915037 Acc: 0.97886710\n",
      "Epoch 71 of 500 took 1.401s\n",
      "val Loss: 0.10523063 Acc: 0.97755759\n",
      "Epoch 71 of 500 took 1.711s\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.06475114 Acc: 0.97957097\n",
      "Epoch 72 of 500 took 1.407s\n",
      "val Loss: 0.18788557 Acc: 0.95299797\n",
      "Epoch 72 of 500 took 1.715s\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.06232664 Acc: 0.98074409\n",
      "Epoch 73 of 500 took 1.398s\n",
      "val Loss: 0.09408620 Acc: 0.97611789\n",
      "New best validation loss: 0.09408619561734885\n",
      "Epoch 73 of 500 took 1.751s\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.05832261 Acc: 0.98171611\n",
      "Epoch 74 of 500 took 1.408s\n",
      "val Loss: 0.18238635 Acc: 0.94546070\n",
      "Epoch 74 of 500 took 1.720s\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.07278623 Acc: 0.97784481\n",
      "Epoch 75 of 500 took 1.371s\n",
      "val Loss: 0.17480186 Acc: 0.95562331\n",
      "Epoch 75 of 500 took 1.679s\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.06502543 Acc: 0.97965477\n",
      "Epoch 76 of 500 took 1.406s\n",
      "val Loss: 0.13739350 Acc: 0.96443089\n",
      "Epoch 76 of 500 took 1.704s\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.06409801 Acc: 0.97943690\n",
      "Epoch 77 of 500 took 1.531s\n",
      "val Loss: 0.12545729 Acc: 0.96620935\n",
      "Epoch 77 of 500 took 1.882s\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.06621840 Acc: 0.98055975\n",
      "Epoch 78 of 500 took 1.480s\n",
      "val Loss: 0.11287761 Acc: 0.97755759\n",
      "Epoch 78 of 500 took 1.826s\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.06020885 Acc: 0.97978884\n",
      "Epoch 79 of 500 took 1.476s\n",
      "val Loss: 0.23319920 Acc: 0.92619411\n",
      "Epoch 79 of 500 took 1.791s\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.06140449 Acc: 0.98064354\n",
      "Epoch 80 of 500 took 1.438s\n",
      "val Loss: 0.10286651 Acc: 0.97493225\n",
      "Epoch 80 of 500 took 1.747s\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.05855150 Acc: 0.98123010\n",
      "Epoch 81 of 500 took 1.521s\n",
      "val Loss: 0.14613775 Acc: 0.95769817\n",
      "Epoch 81 of 500 took 1.839s\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.06182691 Acc: 0.98195073\n",
      "Epoch 82 of 500 took 1.390s\n",
      "val Loss: 0.20407902 Acc: 0.95431064\n",
      "Epoch 82 of 500 took 1.703s\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.07504012 Acc: 0.97590079\n",
      "Epoch 83 of 500 took 1.411s\n",
      "val Loss: 0.25837968 Acc: 0.92826897\n",
      "Epoch 83 of 500 took 1.732s\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.08916873 Acc: 0.97310206\n",
      "Epoch 84 of 500 took 1.372s\n",
      "val Loss: 0.15335003 Acc: 0.95621612\n",
      "Epoch 84 of 500 took 1.685s\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.07461692 Acc: 0.97595106\n",
      "Epoch 85 of 500 took 1.447s\n",
      "val Loss: 0.15886380 Acc: 0.96692920\n",
      "Epoch 85 of 500 took 1.770s\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.07160320 Acc: 0.97620245\n",
      "Epoch 86 of 500 took 1.392s\n",
      "val Loss: 0.19519402 Acc: 0.94626524\n",
      "Epoch 86 of 500 took 1.776s\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.05963912 Acc: 0.98149824\n",
      "Epoch 87 of 500 took 1.484s\n",
      "val Loss: 0.33613871 Acc: 0.94050644\n",
      "Epoch 87 of 500 took 1.753s\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.06241336 Acc: 0.97972180\n",
      "Epoch 88 of 500 took 1.413s\n",
      "val Loss: 0.50438642 Acc: 0.80153286\n",
      "Epoch 88 of 500 took 1.723s\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.06158406 Acc: 0.98293950\n",
      "Epoch 89 of 500 took 1.362s\n",
      "val Loss: 0.14249421 Acc: 0.96515075\n",
      "Epoch    89: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 89 of 500 took 1.671s\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.05306283 Acc: 0.98309033\n",
      "Epoch 90 of 500 took 1.409s\n",
      "val Loss: 0.09762741 Acc: 0.97861619\n",
      "Epoch 90 of 500 took 1.722s\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.03875952 Acc: 0.98835261\n",
      "Epoch 91 of 500 took 1.362s\n",
      "val Loss: 0.08703172 Acc: 0.98102981\n",
      "New best validation loss: 0.08703171550662214\n",
      "Epoch 91 of 500 took 1.678s\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.03699788 Acc: 0.98929110\n",
      "Epoch 92 of 500 took 1.403s\n",
      "val Loss: 0.08724761 Acc: 0.98107215\n",
      "Epoch 92 of 500 took 1.715s\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.03572742 Acc: 0.98950897\n",
      "Epoch 93 of 500 took 1.398s\n",
      "val Loss: 0.09043931 Acc: 0.98043699\n",
      "Epoch 93 of 500 took 1.709s\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.03601635 Acc: 0.98952572\n",
      "Epoch 94 of 500 took 1.408s\n",
      "val Loss: 0.08758389 Acc: 0.98124153\n",
      "Epoch 94 of 500 took 1.722s\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.03671800 Acc: 0.98955924\n",
      "Epoch 95 of 500 took 1.417s\n",
      "val Loss: 0.09045699 Acc: 0.98086043\n",
      "Epoch 95 of 500 took 1.862s\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.03445558 Acc: 0.98964304\n",
      "Epoch 96 of 500 took 1.546s\n",
      "val Loss: 0.09143027 Acc: 0.98060637\n",
      "Epoch 96 of 500 took 1.849s\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.03345341 Acc: 0.99059829\n",
      "Epoch 97 of 500 took 1.557s\n",
      "val Loss: 0.09216881 Acc: 0.98111450\n",
      "Epoch 97 of 500 took 1.930s\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.03552440 Acc: 0.98955924\n",
      "Epoch 98 of 500 took 1.481s\n",
      "val Loss: 0.09367136 Acc: 0.98090278\n",
      "Epoch 98 of 500 took 1.791s\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.03485289 Acc: 0.99021284\n",
      "Epoch 99 of 500 took 1.489s\n",
      "val Loss: 0.08842919 Acc: 0.98149560\n",
      "Epoch 99 of 500 took 1.790s\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.03421628 Acc: 0.99004525\n",
      "Epoch 100 of 500 took 1.378s\n",
      "val Loss: 0.08992153 Acc: 0.98141091\n",
      "Epoch 100 of 500 took 1.684s\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.03476524 Acc: 0.98959276\n",
      "Epoch 101 of 500 took 1.454s\n",
      "val Loss: 0.09090151 Acc: 0.98124153\n",
      "Epoch 101 of 500 took 1.758s\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.03406462 Acc: 0.98979387\n",
      "Epoch 102 of 500 took 1.361s\n",
      "val Loss: 0.08805085 Acc: 0.98196138\n",
      "Epoch 102 of 500 took 1.665s\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.03419453 Acc: 0.99001173\n",
      "Epoch 103 of 500 took 1.438s\n",
      "val Loss: 0.09105611 Acc: 0.98213076\n",
      "Epoch 103 of 500 took 1.778s\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.03331377 Acc: 0.99029663\n",
      "Epoch 104 of 500 took 1.487s\n",
      "val Loss: 0.09117719 Acc: 0.98263889\n",
      "Epoch 104 of 500 took 1.798s\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.03239057 Acc: 0.99111781\n",
      "Epoch 105 of 500 took 1.415s\n",
      "val Loss: 0.09119685 Acc: 0.98204607\n",
      "Epoch 105 of 500 took 1.727s\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.03210374 Acc: 0.99098374\n",
      "Epoch 106 of 500 took 1.436s\n",
      "val Loss: 0.08831603 Acc: 0.98255420\n",
      "Epoch 106 of 500 took 1.750s\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.03304468 Acc: 0.99076588\n",
      "Epoch 107 of 500 took 1.419s\n",
      "val Loss: 0.08961875 Acc: 0.98280827\n",
      "Epoch   107: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 107 of 500 took 1.686s\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.03266842 Acc: 0.99081616\n",
      "Epoch 108 of 500 took 1.404s\n",
      "val Loss: 0.08987337 Acc: 0.98310467\n",
      "Epoch 108 of 500 took 1.714s\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.03170501 Acc: 0.99084967\n",
      "Epoch 109 of 500 took 1.367s\n",
      "val Loss: 0.08848581 Acc: 0.98314702\n",
      "Epoch 109 of 500 took 1.672s\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.03363623 Acc: 0.99016256\n",
      "Epoch 110 of 500 took 1.438s\n",
      "val Loss: 0.08850074 Acc: 0.98327405\n",
      "Epoch 110 of 500 took 1.747s\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.03171222 Acc: 0.99111781\n",
      "Epoch 111 of 500 took 1.389s\n",
      "val Loss: 0.08750001 Acc: 0.98318936\n",
      "Epoch 111 of 500 took 1.702s\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.03185405 Acc: 0.99084967\n",
      "Epoch 112 of 500 took 1.569s\n",
      "val Loss: 0.08854379 Acc: 0.98310467\n",
      "Epoch 112 of 500 took 1.934s\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.03086440 Acc: 0.99125189\n",
      "Epoch 113 of 500 took 1.399s\n",
      "val Loss: 0.08839801 Acc: 0.98352812\n",
      "Epoch 113 of 500 took 1.716s\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.03322068 Acc: 0.99004525\n",
      "Epoch 114 of 500 took 1.432s\n",
      "val Loss: 0.08774954 Acc: 0.98318936\n",
      "Epoch 114 of 500 took 1.745s\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.03281933 Acc: 0.99063181\n",
      "Epoch 115 of 500 took 1.369s\n",
      "val Loss: 0.08846775 Acc: 0.98306233\n",
      "Epoch 115 of 500 took 1.680s\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.03141376 Acc: 0.99113457\n",
      "Epoch 116 of 500 took 1.409s\n",
      "val Loss: 0.08704068 Acc: 0.98331640\n",
      "Epoch 116 of 500 took 1.721s\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.03232892 Acc: 0.99053126\n",
      "Epoch 117 of 500 took 1.376s\n",
      "val Loss: 0.08736694 Acc: 0.98310467\n",
      "Epoch 117 of 500 took 1.687s\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.03126969 Acc: 0.99022960\n",
      "Epoch 118 of 500 took 1.412s\n",
      "val Loss: 0.08724263 Acc: 0.98348577\n",
      "Epoch 118 of 500 took 1.680s\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.03144663 Acc: 0.99029663\n",
      "Epoch 119 of 500 took 1.410s\n",
      "val Loss: 0.08670597 Acc: 0.98361280\n",
      "New best validation loss: 0.08670597148902694\n",
      "Epoch 119 of 500 took 1.724s\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.03182728 Acc: 0.99068208\n",
      "Epoch 120 of 500 took 1.382s\n",
      "val Loss: 0.08741883 Acc: 0.98306233\n",
      "Epoch 120 of 500 took 1.724s\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.03118643 Acc: 0.99088319\n",
      "Epoch 121 of 500 took 1.562s\n",
      "val Loss: 0.08569870 Acc: 0.98365515\n",
      "New best validation loss: 0.08569869914957824\n",
      "Epoch 121 of 500 took 1.934s\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.03073341 Acc: 0.99140271\n",
      "Epoch 122 of 500 took 1.437s\n",
      "val Loss: 0.08675002 Acc: 0.98306233\n",
      "Epoch 122 of 500 took 1.761s\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.03073796 Acc: 0.99113457\n",
      "Epoch 123 of 500 took 1.531s\n",
      "val Loss: 0.08749080 Acc: 0.98314702\n",
      "Epoch 123 of 500 took 1.844s\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.03158697 Acc: 0.99140271\n",
      "Epoch 124 of 500 took 1.406s\n",
      "val Loss: 0.08777779 Acc: 0.98310467\n",
      "Epoch 124 of 500 took 1.718s\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.03045021 Acc: 0.99133568\n",
      "Epoch 125 of 500 took 1.470s\n",
      "val Loss: 0.08781193 Acc: 0.98297764\n",
      "Epoch 125 of 500 took 1.773s\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.03171875 Acc: 0.99073236\n",
      "Epoch 126 of 500 took 1.358s\n",
      "val Loss: 0.08736490 Acc: 0.98335874\n",
      "Epoch 126 of 500 took 1.662s\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.03094225 Acc: 0.99136920\n",
      "Epoch 127 of 500 took 1.413s\n",
      "val Loss: 0.08893608 Acc: 0.98306233\n",
      "Epoch 127 of 500 took 1.724s\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.03063443 Acc: 0.99126864\n",
      "Epoch 128 of 500 took 1.371s\n",
      "val Loss: 0.08868222 Acc: 0.98323171\n",
      "Epoch 128 of 500 took 1.679s\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.03231646 Acc: 0.99026311\n",
      "Epoch 129 of 500 took 1.411s\n",
      "val Loss: 0.08797127 Acc: 0.98310467\n",
      "Epoch 129 of 500 took 1.757s\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.03088728 Acc: 0.99095023\n",
      "Epoch 130 of 500 took 1.523s\n",
      "val Loss: 0.08688897 Acc: 0.98323171\n",
      "Epoch 130 of 500 took 1.899s\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.03182809 Acc: 0.99089995\n",
      "Epoch 131 of 500 took 1.407s\n",
      "val Loss: 0.08780842 Acc: 0.98340108\n",
      "Epoch 131 of 500 took 1.720s\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.03133261 Acc: 0.99034691\n",
      "Epoch 132 of 500 took 1.429s\n",
      "val Loss: 0.08854068 Acc: 0.98318936\n",
      "Epoch 132 of 500 took 1.737s\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.02931329 Acc: 0.99163734\n",
      "Epoch 133 of 500 took 1.395s\n",
      "val Loss: 0.08782641 Acc: 0.98344343\n",
      "Epoch 133 of 500 took 1.706s\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.03037145 Acc: 0.99108430\n",
      "Epoch 134 of 500 took 1.440s\n",
      "val Loss: 0.08894365 Acc: 0.98306233\n",
      "Epoch 134 of 500 took 1.747s\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.02981355 Acc: 0.99173789\n",
      "Epoch 135 of 500 took 1.388s\n",
      "val Loss: 0.08968106 Acc: 0.98318936\n",
      "Epoch 135 of 500 took 1.702s\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.03072813 Acc: 0.99157030\n",
      "Epoch 136 of 500 took 1.431s\n",
      "val Loss: 0.09008991 Acc: 0.98285061\n",
      "Epoch 136 of 500 took 1.742s\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.03173511 Acc: 0.99069884\n",
      "Epoch 137 of 500 took 1.396s\n",
      "val Loss: 0.09053620 Acc: 0.98331640\n",
      "Epoch   137: reducing learning rate of group 0 to 1.8686e-05.\n",
      "Epoch 137 of 500 took 1.739s\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.03091101 Acc: 0.99120161\n",
      "Epoch 138 of 500 took 1.495s\n",
      "val Loss: 0.09038131 Acc: 0.98323171\n",
      "Epoch 138 of 500 took 1.824s\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.03108820 Acc: 0.99140271\n",
      "Epoch 139 of 500 took 1.441s\n",
      "val Loss: 0.08912559 Acc: 0.98357046\n",
      "Epoch 139 of 500 took 1.748s\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.03115942 Acc: 0.99113457\n",
      "Epoch 140 of 500 took 1.406s\n",
      "val Loss: 0.08951683 Acc: 0.98335874\n",
      "Epoch 140 of 500 took 1.720s\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.03124016 Acc: 0.99078264\n",
      "Epoch 141 of 500 took 1.449s\n",
      "val Loss: 0.08853791 Acc: 0.98348577\n",
      "Epoch 141 of 500 took 1.758s\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.03127785 Acc: 0.99113457\n",
      "Epoch 142 of 500 took 1.398s\n",
      "val Loss: 0.08779923 Acc: 0.98352812\n",
      "Epoch 142 of 500 took 1.704s\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.03053485 Acc: 0.99131892\n",
      "Epoch 143 of 500 took 1.425s\n",
      "val Loss: 0.08809068 Acc: 0.98335874\n",
      "Epoch 143 of 500 took 1.733s\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.03090885 Acc: 0.99120161\n",
      "Epoch 144 of 500 took 1.392s\n",
      "val Loss: 0.08772495 Acc: 0.98344343\n",
      "Epoch 144 of 500 took 1.705s\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.02909628 Acc: 0.99175465\n",
      "Epoch 145 of 500 took 1.425s\n",
      "val Loss: 0.08650876 Acc: 0.98348577\n",
      "Epoch 145 of 500 took 1.732s\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.03031971 Acc: 0.99193900\n",
      "Epoch 146 of 500 took 1.408s\n",
      "val Loss: 0.08707934 Acc: 0.98327405\n",
      "Epoch 146 of 500 took 1.754s\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.03150640 Acc: 0.99038043\n",
      "Epoch 147 of 500 took 1.540s\n",
      "val Loss: 0.08690164 Acc: 0.98335874\n",
      "Epoch 147 of 500 took 1.869s\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.03082416 Acc: 0.99116809\n",
      "Epoch 148 of 500 took 1.380s\n",
      "val Loss: 0.08678101 Acc: 0.98327405\n",
      "Epoch 148 of 500 took 1.703s\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.03037116 Acc: 0.99089995\n",
      "Epoch 149 of 500 took 1.393s\n",
      "val Loss: 0.08665056 Acc: 0.98340108\n",
      "Epoch 149 of 500 took 1.713s\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.03011430 Acc: 0.99143623\n",
      "Epoch 150 of 500 took 1.422s\n",
      "val Loss: 0.08729850 Acc: 0.98327405\n",
      "Epoch 150 of 500 took 1.735s\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.03114297 Acc: 0.99069884\n",
      "Epoch 151 of 500 took 1.379s\n",
      "val Loss: 0.08684136 Acc: 0.98327405\n",
      "Epoch 151 of 500 took 1.683s\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.03019466 Acc: 0.99100050\n",
      "Epoch 152 of 500 took 1.404s\n",
      "val Loss: 0.08625252 Acc: 0.98340108\n",
      "Epoch 152 of 500 took 1.713s\n",
      "\n",
      "Training complete in 4m 31s\n",
      "Best val loss: 0.085699\n"
     ]
    }
   ],
   "source": [
    "datasets_pre_training = np.load(\"formatted_datasets/saved_pre_training_dataset_spectrogram.npy\", encoding=\"bytes\", allow_pickle=True)\n",
    "examples_pre_training, labels_pre_training = datasets_pre_training\n",
    "calculate_pre_training(examples_pre_training, labels_pre_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load evaluation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment between here\n",
    "# examples, labels = load_evaluation_dataset.read_data('../../EvaluationDataset', type=\"training0\")\n",
    "# datasets = [examples, labels]\n",
    "\n",
    "# np.save(\"formatted_datasets/saved_evaluation_dataset_training.npy\", datasets)\n",
    "\n",
    "# examples, labels = load_evaluation_dataset.read_data('../../EvaluationDataset', type=\"Test0\")\n",
    "# datasets = [examples, labels]\n",
    "\n",
    "# np.save(\"formatted_datasets/saved_evaluation_dataset_test0.npy\", datasets)\n",
    "\n",
    "# examples, labels = load_evaluation_dataset.read_data('../../EvaluationDataset', type=\"Test1\")\n",
    "# datasets = [examples, labels]\n",
    "\n",
    "# np.save(\"formatted_datasets/saved_evaluation_dataset_test1.npy\", datasets)\n",
    "\n",
    "# And here if the pre-training dataset was already processed and saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_training = np.load(\"formatted_datasets/saved_evaluation_dataset_training.npy\", encoding=\"bytes\", allow_pickle=True)\n",
    "examples_training, labels_training = datasets_training\n",
    "\n",
    "datasets_test0 = np.load(\"formatted_datasets/saved_evaluation_dataset_test0.npy\", encoding=\"bytes\", allow_pickle=True)\n",
    "examples_test0, labels_test0 = datasets_test0\n",
    "\n",
    "datasets_test1 = np.load(\"formatted_datasets/saved_evaluation_dataset_test1.npy\", encoding=\"bytes\", allow_pickle=True)\n",
    "examples_test1, labels_test1 = datasets_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This next part actually returns the results\n",
    "This part simply runs calculate fitness a given number of times and prints the results of the trials to the screen. The actual results that are meaningful are printed out to a text file for better reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT DATASET :  0\n",
      "(5309, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/eNABLE_repo/myoArmBandDataset/MyoArmbandDataset/PyTorchImplementation/RawEnhancedConvNet/target_network_raw_emg_enhanced.py:123: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n",
      "/home/jovyan/work/eNABLE_repo/myoArmBandDataset/MyoArmbandDataset/PyTorchImplementation/RawEnhancedConvNet/target_network_raw_emg_enhanced.py:126: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5149335964686341 Acc: 0.8361545138888888\n",
      "val Loss: 0.040895371697843075 Acc: 0.986328125\n",
      "New best validation loss: 0.040895371697843075\n",
      "Epoch 1 of 500 took 0.570s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.08209535396761364 Acc: 0.97265625\n",
      "val Loss: 0.015548140276223421 Acc: 0.99609375\n",
      "New best validation loss: 0.015548140276223421\n",
      "Epoch 2 of 500 took 0.401s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.04208566351897187 Acc: 0.9835069444444444\n",
      "val Loss: 0.004912353120744228 Acc: 1.0\n",
      "New best validation loss: 0.004912353120744228\n",
      "Epoch 3 of 500 took 0.377s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.03519743251510792 Acc: 0.9887152777777778\n",
      "val Loss: 0.0036725192330777645 Acc: 1.0\n",
      "New best validation loss: 0.0036725192330777645\n",
      "Epoch 4 of 500 took 0.364s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.0309506653704577 Acc: 0.98828125\n",
      "val Loss: 0.0023973220959305763 Acc: 1.0\n",
      "New best validation loss: 0.0023973220959305763\n",
      "Epoch 5 of 500 took 0.342s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.025588678144332435 Acc: 0.990234375\n",
      "val Loss: 0.0017060237005352974 Acc: 1.0\n",
      "New best validation loss: 0.0017060237005352974\n",
      "Epoch 6 of 500 took 0.348s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.02196779117609064 Acc: 0.9917534722222222\n",
      "val Loss: 0.0015066219493746758 Acc: 1.0\n",
      "New best validation loss: 0.0015066219493746758\n",
      "Epoch 7 of 500 took 0.335s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.016134644341137674 Acc: 0.9956597222222222\n",
      "val Loss: 0.0010729003697633743 Acc: 1.0\n",
      "New best validation loss: 0.0010729003697633743\n",
      "Epoch 8 of 500 took 0.374s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.014547938687933816 Acc: 0.9952256944444444\n",
      "val Loss: 0.0006657438352704048 Acc: 1.0\n",
      "New best validation loss: 0.0006657438352704048\n",
      "Epoch 9 of 500 took 0.381s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.017286027626444895 Acc: 0.9950086805555556\n",
      "val Loss: 0.0007755449041724205 Acc: 1.0\n",
      "Epoch 10 of 500 took 0.354s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.015163962832755513 Acc: 0.9952256944444444\n",
      "val Loss: 0.0007964456453919411 Acc: 1.0\n",
      "Epoch 11 of 500 took 0.352s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.01607178446526329 Acc: 0.994140625\n",
      "val Loss: 0.0008925814181566238 Acc: 1.0\n",
      "Epoch 12 of 500 took 0.515s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.012839341950085428 Acc: 0.9954427083333334\n",
      "val Loss: 0.0006053075194358826 Acc: 1.0\n",
      "New best validation loss: 0.0006053075194358826\n",
      "Epoch 13 of 500 took 0.390s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.01245221345581942 Acc: 0.9967447916666666\n",
      "val Loss: 0.0008183615282177925 Acc: 1.0\n",
      "Epoch 14 of 500 took 0.681s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.012889414922230773 Acc: 0.99609375\n",
      "val Loss: 0.00023853033781051636 Acc: 1.0\n",
      "New best validation loss: 0.00023853033781051636\n",
      "Epoch 15 of 500 took 0.681s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.009056219831109047 Acc: 0.9976128472222222\n",
      "val Loss: 0.00045261159539222717 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.382s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.01044234550661511 Acc: 0.9967447916666666\n",
      "val Loss: 0.000537356361746788 Acc: 1.0\n",
      "Epoch 17 of 500 took 0.367s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00859442027285695 Acc: 0.9965277777777778\n",
      "val Loss: 0.000299147330224514 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.366s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.010093828249308798 Acc: 0.9965277777777778\n",
      "val Loss: 0.0005350764840841293 Acc: 1.0\n",
      "Epoch 19 of 500 took 0.383s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.0084723391984072 Acc: 0.9965277777777778\n",
      "val Loss: 0.00022523757070302963 Acc: 1.0\n",
      "New best validation loss: 0.00022523757070302963\n",
      "Epoch 20 of 500 took 0.377s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.004959330376651552 Acc: 0.9986979166666666\n",
      "val Loss: 0.0001625576987862587 Acc: 1.0\n",
      "New best validation loss: 0.0001625576987862587\n",
      "Epoch 21 of 500 took 0.352s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00728439808719688 Acc: 0.9971788194444444\n",
      "val Loss: 0.00011271517723798752 Acc: 1.0\n",
      "New best validation loss: 0.00011271517723798752\n",
      "Epoch 22 of 500 took 0.313s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.004573072177461452 Acc: 0.9986979166666666\n",
      "val Loss: 0.00010402034968137741 Acc: 1.0\n",
      "New best validation loss: 0.00010402034968137741\n",
      "Epoch 23 of 500 took 0.318s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.0038475660710699027 Acc: 0.9989149305555556\n",
      "val Loss: 0.00011684559285640717 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.310s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.0033186812264223895 Acc: 0.9991319444444444\n",
      "val Loss: 0.00016602687537670135 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.327s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.004613783520956834 Acc: 0.9986979166666666\n",
      "val Loss: 0.00012623611837625504 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.376s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00403311134626468 Acc: 0.9991319444444444\n",
      "val Loss: 7.341429591178894e-05 Acc: 1.0\n",
      "New best validation loss: 7.341429591178894e-05\n",
      "Epoch 27 of 500 took 0.427s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.006734264911048942 Acc: 0.9978298611111112\n",
      "val Loss: 5.974993109703064e-05 Acc: 1.0\n",
      "New best validation loss: 5.974993109703064e-05\n",
      "Epoch 28 of 500 took 0.505s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.004046120887829198 Acc: 0.9986979166666666\n",
      "val Loss: 8.116103708744049e-05 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.429s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.003550042760454946 Acc: 0.9991319444444444\n",
      "val Loss: 7.827207446098328e-05 Acc: 1.0\n",
      "Epoch 30 of 500 took 0.431s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.0033810677834682995 Acc: 0.9989149305555556\n",
      "val Loss: 0.00012740027159452438 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.375s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.002627436459685365 Acc: 0.9993489583333334\n",
      "val Loss: 6.035994738340378e-05 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.382s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0060648089792165495 Acc: 0.998046875\n",
      "val Loss: 4.6523287892341614e-05 Acc: 1.0\n",
      "New best validation loss: 4.6523287892341614e-05\n",
      "Epoch 33 of 500 took 0.389s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.005016062098244826 Acc: 0.9982638888888888\n",
      "val Loss: 8.48080962896347e-05 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.405s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.004466363668648733 Acc: 0.9982638888888888\n",
      "val Loss: 8.111819624900818e-05 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.373s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0028946934681799677 Acc: 0.9993489583333334\n",
      "val Loss: 6.860774010419846e-05 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.388s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.0028921563385261428 Acc: 0.9991319444444444\n",
      "val Loss: 7.199309766292572e-05 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.436s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.0023205133879350293 Acc: 0.9993489583333334\n",
      "val Loss: 5.9905461966991425e-05 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.382s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.0035784373370309672 Acc: 0.9986979166666666\n",
      "val Loss: 5.080364644527435e-05 Acc: 1.0\n",
      "Epoch    39: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 39 of 500 took 0.426s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.0021833801228139135 Acc: 0.9997829861111112\n",
      "val Loss: 5.757622420787811e-05 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.384s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.003215574969847997 Acc: 0.9991319444444444\n",
      "val Loss: 4.6275556087493896e-05 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.371s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.0029651885852217674 Acc: 0.9993489583333334\n",
      "val Loss: 4.220940172672272e-05 Acc: 1.0\n",
      "New best validation loss: 4.220940172672272e-05\n",
      "Epoch 42 of 500 took 0.373s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.0040169946538905306 Acc: 0.9982638888888888\n",
      "val Loss: 4.044733941555023e-05 Acc: 1.0\n",
      "New best validation loss: 4.044733941555023e-05\n",
      "Epoch 43 of 500 took 0.393s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0018983073791282044 Acc: 0.9997829861111112\n",
      "val Loss: 4.16245311498642e-05 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.392s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.001985336964329084 Acc: 0.9997829861111112\n",
      "val Loss: 5.0455331802368164e-05 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.364s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.002061180459956328 Acc: 0.9995659722222222\n",
      "val Loss: 4.121847450733185e-05 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.368s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0020608589984476566 Acc: 0.9993489583333334\n",
      "val Loss: 4.209205508232117e-05 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.402s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.0037425991354717147 Acc: 0.9982638888888888\n",
      "val Loss: 5.807913839817047e-05 Acc: 1.0\n",
      "Epoch 48 of 500 took 0.381s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.0023556596909960112 Acc: 0.9993489583333334\n",
      "val Loss: 4.047714173793793e-05 Acc: 1.0\n",
      "Epoch    49: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 49 of 500 took 0.502s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.0015105388334227933 Acc: 0.9995659722222222\n",
      "val Loss: 3.412365913391113e-05 Acc: 1.0\n",
      "New best validation loss: 3.412365913391113e-05\n",
      "Epoch 50 of 500 took 0.418s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.0033436225106318793 Acc: 0.9991319444444444\n",
      "val Loss: 3.2627955079078674e-05 Acc: 1.0\n",
      "New best validation loss: 3.2627955079078674e-05\n",
      "Epoch 51 of 500 took 0.402s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0018955644013153182 Acc: 0.9995659722222222\n",
      "val Loss: 3.884173929691315e-05 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.605s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0027442843549781376 Acc: 0.9991319444444444\n",
      "val Loss: 3.7631019949913025e-05 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.558s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0019567570028205714 Acc: 0.9991319444444444\n",
      "val Loss: 4.207529127597809e-05 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.454s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.004266886609709925 Acc: 0.9984809027777778\n",
      "val Loss: 4.460476338863373e-05 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.379s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0031496304501261977 Acc: 0.9986979166666666\n",
      "val Loss: 5.0401315093040466e-05 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.298s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.001981632628788551 Acc: 0.9995659722222222\n",
      "val Loss: 4.199706017971039e-05 Acc: 1.0\n",
      "Epoch    57: reducing learning rate of group 0 to 1.8686e-05.\n",
      "Epoch 57 of 500 took 0.288s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.001460314728319645 Acc: 0.9995659722222222\n",
      "val Loss: 3.993697464466095e-05 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.287s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0014862758107483387 Acc: 0.9995659722222222\n",
      "val Loss: 4.088692367076874e-05 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.386s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0021610468005140624 Acc: 0.9995659722222222\n",
      "val Loss: 4.233419895172119e-05 Acc: 1.0\n",
      "Epoch 60 of 500 took 0.390s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.0021116738207638264 Acc: 0.9993489583333334\n",
      "val Loss: 4.072114825248718e-05 Acc: 1.0\n",
      "Epoch 61 of 500 took 0.416s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.0015754357187284364 Acc: 0.9997829861111112\n",
      "val Loss: 4.9447640776634216e-05 Acc: 1.0\n",
      "Epoch 62 of 500 took 0.298s\n",
      "\n",
      "Training complete in 0m 25s\n",
      "Best val loss: 0.000033\n",
      "ACCURACY TEST_0 FINAL : 99.411 %\n",
      "ACCURACY TEST_1 FINAL : 100.000 %\n",
      "CURRENT DATASET :  1\n",
      "(5312, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.4419376891520288 Acc: 0.8619791666666666\n",
      "val Loss: 0.015679304022341967 Acc: 0.99609375\n",
      "New best validation loss: 0.015679304022341967\n",
      "Epoch 1 of 500 took 0.309s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.037529468381156526 Acc: 0.9889322916666666\n",
      "val Loss: 0.0031285183504223824 Acc: 1.0\n",
      "New best validation loss: 0.0031285183504223824\n",
      "Epoch 2 of 500 took 0.299s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.025469022596047983 Acc: 0.9921875\n",
      "val Loss: 0.0067926328629255295 Acc: 0.99609375\n",
      "Epoch 3 of 500 took 0.301s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.022714690615733463 Acc: 0.9921875\n",
      "val Loss: 0.001735009253025055 Acc: 1.0\n",
      "New best validation loss: 0.001735009253025055\n",
      "Epoch 4 of 500 took 0.300s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.01947506781046589 Acc: 0.9937065972222222\n",
      "val Loss: 0.001339019276201725 Acc: 1.0\n",
      "New best validation loss: 0.001339019276201725\n",
      "Epoch 5 of 500 took 0.295s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.013136664767646127 Acc: 0.9963107638888888\n",
      "val Loss: 0.0014501921832561493 Acc: 1.0\n",
      "Epoch 6 of 500 took 0.318s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00889058711214198 Acc: 0.9982638888888888\n",
      "val Loss: 0.0012684939429163933 Acc: 1.0\n",
      "New best validation loss: 0.0012684939429163933\n",
      "Epoch 7 of 500 took 0.303s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.012318641775184207 Acc: 0.9969618055555556\n",
      "val Loss: 0.0007827747613191605 Acc: 1.0\n",
      "New best validation loss: 0.0007827747613191605\n",
      "Epoch 8 of 500 took 0.384s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.010403383730186356 Acc: 0.9971788194444444\n",
      "val Loss: 0.0009998520836234093 Acc: 1.0\n",
      "Epoch 9 of 500 took 0.311s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.009173935124029716 Acc: 0.9969618055555556\n",
      "val Loss: 0.001984049566090107 Acc: 1.0\n",
      "Epoch 10 of 500 took 0.310s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.008346079486525722 Acc: 0.9978298611111112\n",
      "val Loss: 0.0006543472409248352 Acc: 1.0\n",
      "New best validation loss: 0.0006543472409248352\n",
      "Epoch 11 of 500 took 0.302s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.006823918833914731 Acc: 0.9984809027777778\n",
      "val Loss: 0.001015818677842617 Acc: 1.0\n",
      "Epoch 12 of 500 took 0.339s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.005575019607527388 Acc: 0.9989149305555556\n",
      "val Loss: 0.0002956874668598175 Acc: 1.0\n",
      "New best validation loss: 0.0002956874668598175\n",
      "Epoch 13 of 500 took 0.314s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.0059296933468431234 Acc: 0.9989149305555556\n",
      "val Loss: 0.002211274579167366 Acc: 0.998046875\n",
      "Epoch 14 of 500 took 0.314s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.007741627697315481 Acc: 0.9976128472222222\n",
      "val Loss: 0.0013794153928756714 Acc: 1.0\n",
      "Epoch 15 of 500 took 0.298s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.004265591812630494 Acc: 0.9989149305555556\n",
      "val Loss: 0.0005598356947302818 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.303s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.005670609935704205 Acc: 0.9984809027777778\n",
      "val Loss: 0.0006848862394690514 Acc: 1.0\n",
      "Epoch 17 of 500 took 0.300s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.0049538921771778 Acc: 0.998046875\n",
      "val Loss: 0.0019544344395399094 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.296s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.006484942096802924 Acc: 0.9973958333333334\n",
      "val Loss: 0.0002507967874407768 Acc: 1.0\n",
      "New best validation loss: 0.0002507967874407768\n",
      "Epoch 19 of 500 took 0.325s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00524463364854455 Acc: 0.9984809027777778\n",
      "val Loss: 0.0003273375332355499 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.467s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.004259366283400191 Acc: 0.9989149305555556\n",
      "val Loss: 0.0006346814334392548 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.311s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.004865778403149711 Acc: 0.9978298611111112\n",
      "val Loss: 0.0016001751646399498 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.299s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.006002411970661746 Acc: 0.9976128472222222\n",
      "val Loss: 0.0008789636194705963 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.308s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.0055387550964951515 Acc: 0.9982638888888888\n",
      "val Loss: 0.0001749955117702484 Acc: 1.0\n",
      "New best validation loss: 0.0001749955117702484\n",
      "Epoch 24 of 500 took 0.300s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.002488281060424116 Acc: 0.9995659722222222\n",
      "val Loss: 0.0013215309008955956 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.335s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.0036189804474512735 Acc: 0.9989149305555556\n",
      "val Loss: 0.00026461947709321976 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.307s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.0037805167958140373 Acc: 0.9986979166666666\n",
      "val Loss: 0.00017789006233215332 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.302s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.0026622164684037366 Acc: 0.9993489583333334\n",
      "val Loss: 0.0002939002588391304 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.347s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.002058168666230308 Acc: 0.9997829861111112\n",
      "val Loss: 6.630830466747284e-05 Acc: 1.0\n",
      "New best validation loss: 6.630830466747284e-05\n",
      "Epoch 29 of 500 took 0.353s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.003530390922807985 Acc: 0.9984809027777778\n",
      "val Loss: 0.00023984163999557495 Acc: 1.0\n",
      "Epoch 30 of 500 took 0.536s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.003309748445947965 Acc: 0.9991319444444444\n",
      "val Loss: 0.002110712230205536 Acc: 0.998046875\n",
      "Epoch 31 of 500 took 0.548s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.001983188558369875 Acc: 0.9995659722222222\n",
      "val Loss: 5.500763654708862e-05 Acc: 1.0\n",
      "New best validation loss: 5.500763654708862e-05\n",
      "Epoch 32 of 500 took 0.547s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0027363024548523957 Acc: 0.9993489583333334\n",
      "val Loss: 7.078424096107483e-05 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.508s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.0028851062266363036 Acc: 0.9991319444444444\n",
      "val Loss: 0.0008191242814064026 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.383s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.002564429667674833 Acc: 0.9995659722222222\n",
      "val Loss: 0.00015270430594682693 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.378s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0033149458467960358 Acc: 0.9991319444444444\n",
      "val Loss: 5.303695797920227e-05 Acc: 1.0\n",
      "New best validation loss: 5.303695797920227e-05\n",
      "Epoch 36 of 500 took 0.371s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00524668436911371 Acc: 0.9978298611111112\n",
      "val Loss: 0.0012885406613349915 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.367s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.0022089682622916168 Acc: 0.9993489583333334\n",
      "val Loss: 0.00017795898020267487 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.380s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.002727063424471352 Acc: 0.9991319444444444\n",
      "val Loss: 0.0003778189420700073 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.311s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.003120261813617415 Acc: 0.9986979166666666\n",
      "val Loss: 0.0001070583239197731 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.316s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0031116599630978373 Acc: 0.9991319444444444\n",
      "val Loss: 9.279511868953705e-05 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.292s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.003590262701941861 Acc: 0.9986979166666666\n",
      "val Loss: 0.005184834823012352 Acc: 0.99609375\n",
      "Epoch    42: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 42 of 500 took 0.291s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.0028361456158260503 Acc: 0.9993489583333334\n",
      "val Loss: 0.002115938812494278 Acc: 0.998046875\n",
      "Epoch 43 of 500 took 0.285s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0025181338811914125 Acc: 0.9995659722222222\n",
      "val Loss: 0.0005172751843929291 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.357s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.0014758977728585403 Acc: 0.9993489583333334\n",
      "val Loss: 0.00023109279572963715 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.285s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0010070640386806594 Acc: 0.9997829861111112\n",
      "val Loss: 0.0001263786107301712 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.288s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0030378267789880433 Acc: 0.9993489583333334\n",
      "val Loss: 4.609953612089157e-05 Acc: 1.0\n",
      "New best validation loss: 4.609953612089157e-05\n",
      "Epoch 47 of 500 took 0.308s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.0010348867314557235 Acc: 0.9995659722222222\n",
      "val Loss: 3.9808452129364014e-05 Acc: 1.0\n",
      "New best validation loss: 3.9808452129364014e-05\n",
      "Epoch 48 of 500 took 0.315s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.002219144358403153 Acc: 0.9995659722222222\n",
      "val Loss: 4.6232715249061584e-05 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.310s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.002050889811168114 Acc: 0.9993489583333334\n",
      "val Loss: 5.570892244577408e-05 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.312s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.0011621665002571212 Acc: 0.9997829861111112\n",
      "val Loss: 0.00010443385690450668 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.312s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0009790848319729168 Acc: 0.9997829861111112\n",
      "val Loss: 0.00015517137944698334 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.296s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0011267218635314042 Acc: 1.0\n",
      "val Loss: 0.00015522167086601257 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.312s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.003140659330205785 Acc: 0.9991319444444444\n",
      "val Loss: 0.00021780654788017273 Acc: 1.0\n",
      "Epoch    54: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 54 of 500 took 0.317s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.0017411955632269382 Acc: 0.9995659722222222\n",
      "val Loss: 0.00021007098257541656 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.303s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0008998412845863237 Acc: 1.0\n",
      "val Loss: 0.00023807212710380554 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.348s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0022932017325527137 Acc: 0.9995659722222222\n",
      "val Loss: 0.00011694245040416718 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.323s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.0008169296714994642 Acc: 1.0\n",
      "val Loss: 0.00013342685997486115 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.341s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0011363855252663295 Acc: 1.0\n",
      "val Loss: 0.00012207217514514923 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.338s\n",
      "\n",
      "Training complete in 0m 20s\n",
      "Best val loss: 0.000040\n",
      "ACCURACY TEST_0 FINAL : 99.690 %\n",
      "ACCURACY TEST_1 FINAL : 99.255 %\n",
      "CURRENT DATASET :  2\n",
      "(5312, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.7183289958371056 Acc: 0.75\n",
      "val Loss: 0.18917809054255486 Acc: 0.921875\n",
      "New best validation loss: 0.18917809054255486\n",
      "Epoch 1 of 500 took 0.375s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.21056151141722998 Acc: 0.9212239583333334\n",
      "val Loss: 0.10499244928359985 Acc: 0.958984375\n",
      "New best validation loss: 0.10499244928359985\n",
      "Epoch 2 of 500 took 0.361s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.16548253347476324 Acc: 0.9377170138888888\n",
      "val Loss: 0.0872163437306881 Acc: 0.96875\n",
      "New best validation loss: 0.0872163437306881\n",
      "Epoch 3 of 500 took 0.351s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.1378037892282009 Acc: 0.9483506944444444\n",
      "val Loss: 0.0798133397474885 Acc: 0.97265625\n",
      "New best validation loss: 0.0798133397474885\n",
      "Epoch 4 of 500 took 0.346s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.11486401698655552 Acc: 0.958984375\n",
      "val Loss: 0.03998232539743185 Acc: 0.982421875\n",
      "New best validation loss: 0.03998232539743185\n",
      "Epoch 5 of 500 took 0.359s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.09113807562324736 Acc: 0.9689670138888888\n",
      "val Loss: 0.03792566433548927 Acc: 0.982421875\n",
      "New best validation loss: 0.03792566433548927\n",
      "Epoch 6 of 500 took 0.386s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.09099430239035024 Acc: 0.9639756944444444\n",
      "val Loss: 0.036521390080451965 Acc: 0.986328125\n",
      "New best validation loss: 0.036521390080451965\n",
      "Epoch 7 of 500 took 0.435s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.08106051364706622 Acc: 0.9711371527777778\n",
      "val Loss: 0.02316212933510542 Acc: 0.994140625\n",
      "New best validation loss: 0.02316212933510542\n",
      "Epoch 8 of 500 took 0.379s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.07040108078055912 Acc: 0.9737413194444444\n",
      "val Loss: 0.02761287707835436 Acc: 0.990234375\n",
      "Epoch 9 of 500 took 0.370s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.07591552121771707 Acc: 0.97265625\n",
      "val Loss: 0.018289883621037006 Acc: 0.99609375\n",
      "New best validation loss: 0.018289883621037006\n",
      "Epoch 10 of 500 took 0.370s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.057974128466513425 Acc: 0.9811197916666666\n",
      "val Loss: 0.020898585207760334 Acc: 0.98828125\n",
      "Epoch 11 of 500 took 0.406s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.06184947294079595 Acc: 0.9796006944444444\n",
      "val Loss: 0.021805922500789165 Acc: 0.994140625\n",
      "Epoch 12 of 500 took 0.561s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.058896394446492195 Acc: 0.9796006944444444\n",
      "val Loss: 0.015945706516504288 Acc: 0.99609375\n",
      "New best validation loss: 0.015945706516504288\n",
      "Epoch 13 of 500 took 0.401s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.05596954168544875 Acc: 0.9780815972222222\n",
      "val Loss: 0.01583952736109495 Acc: 0.99609375\n",
      "New best validation loss: 0.01583952736109495\n",
      "Epoch 14 of 500 took 0.351s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.04527079339863525 Acc: 0.9848090277777778\n",
      "val Loss: 0.01910527143627405 Acc: 0.994140625\n",
      "Epoch 15 of 500 took 0.667s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.047377935921152435 Acc: 0.9809027777777778\n",
      "val Loss: 0.006841888651251793 Acc: 1.0\n",
      "New best validation loss: 0.006841888651251793\n",
      "Epoch 16 of 500 took 0.555s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.04732378127260341 Acc: 0.9830729166666666\n",
      "val Loss: 0.014553514309227467 Acc: 0.994140625\n",
      "Epoch 17 of 500 took 0.395s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.03793824940092034 Acc: 0.9865451388888888\n",
      "val Loss: 0.007095811888575554 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.384s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.036869402353962265 Acc: 0.9874131944444444\n",
      "val Loss: 0.01383671909570694 Acc: 0.99609375\n",
      "Epoch 19 of 500 took 0.375s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.04136302787810564 Acc: 0.9874131944444444\n",
      "val Loss: 0.008702757768332958 Acc: 0.99609375\n",
      "Epoch 20 of 500 took 0.308s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.034876486803922385 Acc: 0.9884982638888888\n",
      "val Loss: 0.0064083244651556015 Acc: 0.998046875\n",
      "New best validation loss: 0.0064083244651556015\n",
      "Epoch 21 of 500 took 0.298s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.03237389690346188 Acc: 0.9889322916666666\n",
      "val Loss: 0.004503283649682999 Acc: 1.0\n",
      "New best validation loss: 0.004503283649682999\n",
      "Epoch 22 of 500 took 0.330s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.03171798286752568 Acc: 0.9898003472222222\n",
      "val Loss: 0.005493613891303539 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.343s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.029441103908336826 Acc: 0.9898003472222222\n",
      "val Loss: 0.0066881198436021805 Acc: 0.998046875\n",
      "Epoch 24 of 500 took 0.310s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.026861074949718185 Acc: 0.9887152777777778\n",
      "val Loss: 0.0031299106776714325 Acc: 1.0\n",
      "New best validation loss: 0.0031299106776714325\n",
      "Epoch 25 of 500 took 0.303s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.028367900962216988 Acc: 0.9893663194444444\n",
      "val Loss: 0.0030073747038841248 Acc: 1.0\n",
      "New best validation loss: 0.0030073747038841248\n",
      "Epoch 26 of 500 took 0.306s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.031135773493183985 Acc: 0.9884982638888888\n",
      "val Loss: 0.0033629760146141052 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.297s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.030381266234649554 Acc: 0.98828125\n",
      "val Loss: 0.004051755182445049 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.294s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.030589032918214798 Acc: 0.9895833333333334\n",
      "val Loss: 0.008223241195082664 Acc: 0.99609375\n",
      "Epoch 29 of 500 took 0.305s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.02605600603338745 Acc: 0.9904513888888888\n",
      "val Loss: 0.003718971274793148 Acc: 1.0\n",
      "Epoch 30 of 500 took 0.394s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.02842233505927854 Acc: 0.9895833333333334\n",
      "val Loss: 0.0031082453206181526 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.383s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.02047257089159555 Acc: 0.9915364583333334\n",
      "val Loss: 0.005463277921080589 Acc: 0.998046875\n",
      "Epoch    32: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 32 of 500 took 0.361s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.01954681622899241 Acc: 0.9943576388888888\n",
      "val Loss: 0.0041475603356957436 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.358s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.01745528458721108 Acc: 0.994140625\n",
      "val Loss: 0.002949485555291176 Acc: 1.0\n",
      "New best validation loss: 0.002949485555291176\n",
      "Epoch 34 of 500 took 0.366s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.020321903491599694 Acc: 0.9924045138888888\n",
      "val Loss: 0.003909924067556858 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.364s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.013454268996914228 Acc: 0.9965277777777778\n",
      "val Loss: 0.0034812092781066895 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.357s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.018164258191568985 Acc: 0.9924045138888888\n",
      "val Loss: 0.004204543307423592 Acc: 0.998046875\n",
      "Epoch 37 of 500 took 0.407s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.01616961881518364 Acc: 0.9950086805555556\n",
      "val Loss: 0.0033798227086663246 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.379s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.018695167524533138 Acc: 0.9939236111111112\n",
      "val Loss: 0.002883538603782654 Acc: 1.0\n",
      "New best validation loss: 0.002883538603782654\n",
      "Epoch 39 of 500 took 0.377s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.01613018661737442 Acc: 0.9934895833333334\n",
      "val Loss: 0.0034045446664094925 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.384s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.02021417047621475 Acc: 0.9921875\n",
      "val Loss: 0.003976049832999706 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.375s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.015957185274196997 Acc: 0.9952256944444444\n",
      "val Loss: 0.0030973730608820915 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.394s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.019873092623634472 Acc: 0.9930555555555556\n",
      "val Loss: 0.002720445394515991 Acc: 1.0\n",
      "New best validation loss: 0.002720445394515991\n",
      "Epoch 43 of 500 took 0.377s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.017117561410284705 Acc: 0.9945746527777778\n",
      "val Loss: 0.002680906094610691 Acc: 1.0\n",
      "New best validation loss: 0.002680906094610691\n",
      "Epoch 44 of 500 took 0.384s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.013550409736732641 Acc: 0.99609375\n",
      "val Loss: 0.0031906692311167717 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.377s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.012336034689926438 Acc: 0.99609375\n",
      "val Loss: 0.0028106393292546272 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.360s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.015705551176021498 Acc: 0.9947916666666666\n",
      "val Loss: 0.003077937290072441 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.388s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.01347015741177731 Acc: 0.9956597222222222\n",
      "val Loss: 0.0021762531250715256 Acc: 1.0\n",
      "New best validation loss: 0.0021762531250715256\n",
      "Epoch 48 of 500 took 0.379s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.012419546178231636 Acc: 0.9967447916666666\n",
      "val Loss: 0.002354709431529045 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.386s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.013542448584404256 Acc: 0.9952256944444444\n",
      "val Loss: 0.0025481535121798515 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.390s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.014503920606027046 Acc: 0.9965277777777778\n",
      "val Loss: 0.0029009152203798294 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.489s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.012752487789839506 Acc: 0.9967447916666666\n",
      "val Loss: 0.001947007142007351 Acc: 1.0\n",
      "New best validation loss: 0.001947007142007351\n",
      "Epoch 52 of 500 took 0.459s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.011664662458416488 Acc: 0.9965277777777778\n",
      "val Loss: 0.0031590815633535385 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.525s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.01249659661617544 Acc: 0.9963107638888888\n",
      "val Loss: 0.0019983844831585884 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.693s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.010247472828874985 Acc: 0.9965277777777778\n",
      "val Loss: 0.0021131420508027077 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.574s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.011273460410949256 Acc: 0.99609375\n",
      "val Loss: 0.002542381174862385 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.389s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.016221340797427628 Acc: 0.994140625\n",
      "val Loss: 0.002192358486354351 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.382s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.012968112197187211 Acc: 0.9958767361111112\n",
      "val Loss: 0.0017063124105334282 Acc: 1.0\n",
      "New best validation loss: 0.0017063124105334282\n",
      "Epoch 58 of 500 took 0.390s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.01287869488199552 Acc: 0.9952256944444444\n",
      "val Loss: 0.002566881477832794 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.384s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.00897290019525422 Acc: 0.9973958333333334\n",
      "val Loss: 0.0028548091650009155 Acc: 1.0\n",
      "Epoch 60 of 500 took 0.375s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.016235062800761726 Acc: 0.9937065972222222\n",
      "val Loss: 0.0032058358192443848 Acc: 0.998046875\n",
      "Epoch 61 of 500 took 0.378s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.014264089934941795 Acc: 0.9950086805555556\n",
      "val Loss: 0.001705205999314785 Acc: 1.0\n",
      "New best validation loss: 0.001705205999314785\n",
      "Epoch 62 of 500 took 0.408s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.013232244333873192 Acc: 0.99609375\n",
      "val Loss: 0.0013774801045656204 Acc: 1.0\n",
      "New best validation loss: 0.0013774801045656204\n",
      "Epoch 63 of 500 took 0.385s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.014891018987529807 Acc: 0.9937065972222222\n",
      "val Loss: 0.0017867572605609894 Acc: 1.0\n",
      "Epoch 64 of 500 took 0.379s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.014917459701084428 Acc: 0.9950086805555556\n",
      "val Loss: 0.0012293467298150063 Acc: 1.0\n",
      "New best validation loss: 0.0012293467298150063\n",
      "Epoch 65 of 500 took 0.323s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.008766619126415916 Acc: 0.9969618055555556\n",
      "val Loss: 0.0017197588458657265 Acc: 1.0\n",
      "Epoch 66 of 500 took 0.300s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.011647631414234638 Acc: 0.99609375\n",
      "val Loss: 0.001843797042965889 Acc: 1.0\n",
      "Epoch 67 of 500 took 0.413s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.00929201114922762 Acc: 0.9971788194444444\n",
      "val Loss: 0.0014037936925888062 Acc: 1.0\n",
      "Epoch 68 of 500 took 0.309s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.01114880588526527 Acc: 0.9965277777777778\n",
      "val Loss: 0.00176276545971632 Acc: 1.0\n",
      "Epoch 69 of 500 took 0.301s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.011951885186135769 Acc: 0.9952256944444444\n",
      "val Loss: 0.0025977566838264465 Acc: 1.0\n",
      "Epoch 70 of 500 took 0.300s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.011721881986078288 Acc: 0.9958767361111112\n",
      "val Loss: 0.0016097864136099815 Acc: 1.0\n",
      "Epoch    71: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 71 of 500 took 0.304s\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.011143197305500507 Acc: 0.9956597222222222\n",
      "val Loss: 0.0020013218745589256 Acc: 1.0\n",
      "Epoch 72 of 500 took 0.302s\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.010988838608480163 Acc: 0.9967447916666666\n",
      "val Loss: 0.001975097693502903 Acc: 1.0\n",
      "Epoch 73 of 500 took 0.302s\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.01246155948481626 Acc: 0.9967447916666666\n",
      "val Loss: 0.0016679205000400543 Acc: 1.0\n",
      "Epoch 74 of 500 took 0.307s\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.007579286065366533 Acc: 0.9978298611111112\n",
      "val Loss: 0.001560756005346775 Acc: 1.0\n",
      "Epoch 75 of 500 took 0.300s\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.011967249732050631 Acc: 0.9963107638888888\n",
      "val Loss: 0.0016259793192148209 Acc: 1.0\n",
      "Epoch 76 of 500 took 0.306s\n",
      "\n",
      "Training complete in 0m 29s\n",
      "Best val loss: 0.001229\n",
      "ACCURACY TEST_0 FINAL : 92.443 %\n",
      "ACCURACY TEST_1 FINAL : 96.398 %\n",
      "CURRENT DATASET :  3\n",
      "(5312, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5288699136839973 Acc: 0.8294270833333334\n",
      "val Loss: 0.07392003946006298 Acc: 0.974609375\n",
      "New best validation loss: 0.07392003946006298\n",
      "Epoch 1 of 500 took 0.448s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.09017826513283783 Acc: 0.9711371527777778\n",
      "val Loss: 0.034277298487722874 Acc: 0.98828125\n",
      "New best validation loss: 0.034277298487722874\n",
      "Epoch 2 of 500 took 0.374s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.051206861001749836 Acc: 0.98046875\n",
      "val Loss: 0.009368693921715021 Acc: 0.994140625\n",
      "New best validation loss: 0.009368693921715021\n",
      "Epoch 3 of 500 took 0.389s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.0421750300253431 Acc: 0.986328125\n",
      "val Loss: 0.007316218689084053 Acc: 0.99609375\n",
      "New best validation loss: 0.007316218689084053\n",
      "Epoch 4 of 500 took 0.388s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.037554411528011165 Acc: 0.9876302083333334\n",
      "val Loss: 0.004931692034006119 Acc: 0.998046875\n",
      "New best validation loss: 0.004931692034006119\n",
      "Epoch 5 of 500 took 0.297s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.030957125023835234 Acc: 0.9893663194444444\n",
      "val Loss: 0.003761693835258484 Acc: 0.998046875\n",
      "New best validation loss: 0.003761693835258484\n",
      "Epoch 6 of 500 took 0.283s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.02073453278798196 Acc: 0.9930555555555556\n",
      "val Loss: 0.007817355915904045 Acc: 0.99609375\n",
      "Epoch 7 of 500 took 0.280s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.024210768803540204 Acc: 0.9926215277777778\n",
      "val Loss: 0.0019502798095345497 Acc: 1.0\n",
      "New best validation loss: 0.0019502798095345497\n",
      "Epoch 8 of 500 took 0.322s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.023736639672683343 Acc: 0.9919704861111112\n",
      "val Loss: 0.0032391762360930443 Acc: 1.0\n",
      "Epoch 9 of 500 took 0.379s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.017787751276046038 Acc: 0.994140625\n",
      "val Loss: 0.0016468092799186707 Acc: 1.0\n",
      "New best validation loss: 0.0016468092799186707\n",
      "Epoch 10 of 500 took 0.390s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.023104783716715045 Acc: 0.9930555555555556\n",
      "val Loss: 0.003232118673622608 Acc: 1.0\n",
      "Epoch 11 of 500 took 0.365s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.014244053357591232 Acc: 0.9965277777777778\n",
      "val Loss: 0.0015241662040352821 Acc: 1.0\n",
      "New best validation loss: 0.0015241662040352821\n",
      "Epoch 12 of 500 took 0.374s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.012884600915842585 Acc: 0.9956597222222222\n",
      "val Loss: 0.0010761404410004616 Acc: 1.0\n",
      "New best validation loss: 0.0010761404410004616\n",
      "Epoch 13 of 500 took 0.367s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.017753862724122074 Acc: 0.9930555555555556\n",
      "val Loss: 0.0016010431572794914 Acc: 1.0\n",
      "Epoch 14 of 500 took 0.359s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.01773562954945697 Acc: 0.9945746527777778\n",
      "val Loss: 0.0013346755877137184 Acc: 1.0\n",
      "Epoch 15 of 500 took 0.541s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.010387616904659404 Acc: 0.9969618055555556\n",
      "val Loss: 0.0011261152103543282 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.429s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.0128925997349951 Acc: 0.9947916666666666\n",
      "val Loss: 0.0006575575098395348 Acc: 1.0\n",
      "New best validation loss: 0.0006575575098395348\n",
      "Epoch 17 of 500 took 0.643s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.008877193296535147 Acc: 0.9969618055555556\n",
      "val Loss: 0.0028152959421277046 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.635s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.008518038369301293 Acc: 0.9976128472222222\n",
      "val Loss: 0.000612025149166584 Acc: 1.0\n",
      "New best validation loss: 0.000612025149166584\n",
      "Epoch 19 of 500 took 0.398s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.010019739106711414 Acc: 0.9971788194444444\n",
      "val Loss: 0.000665644183754921 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.382s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.010472711744821735 Acc: 0.9969618055555556\n",
      "val Loss: 0.0027871355414390564 Acc: 0.998046875\n",
      "Epoch 21 of 500 took 0.365s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.005289930229385694 Acc: 0.9989149305555556\n",
      "val Loss: 0.00033397600054740906 Acc: 1.0\n",
      "New best validation loss: 0.00033397600054740906\n",
      "Epoch 22 of 500 took 0.384s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.007878060193939341 Acc: 0.9978298611111112\n",
      "val Loss: 0.00045656971633434296 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.383s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.0058768966442181 Acc: 0.9984809027777778\n",
      "val Loss: 0.0008834600448608398 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.443s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.007675030993090736 Acc: 0.9973958333333334\n",
      "val Loss: 0.0010162107646465302 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.404s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.007837263401597738 Acc: 0.9976128472222222\n",
      "val Loss: 0.00048729125410318375 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.388s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.005757437035855319 Acc: 0.998046875\n",
      "val Loss: 0.0011640237644314766 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.380s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.006679802408648862 Acc: 0.9971788194444444\n",
      "val Loss: 0.00026653241366147995 Acc: 1.0\n",
      "New best validation loss: 0.00026653241366147995\n",
      "Epoch 28 of 500 took 0.392s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.007373900463183721 Acc: 0.998046875\n",
      "val Loss: 0.00020014122128486633 Acc: 1.0\n",
      "New best validation loss: 0.00020014122128486633\n",
      "Epoch 29 of 500 took 0.379s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.004548263166927629 Acc: 0.9991319444444444\n",
      "val Loss: 0.00010249484330415726 Acc: 1.0\n",
      "New best validation loss: 0.00010249484330415726\n",
      "Epoch 30 of 500 took 0.376s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.005875320639461279 Acc: 0.9984809027777778\n",
      "val Loss: 0.00024720653891563416 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.376s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.004208974954154756 Acc: 0.9986979166666666\n",
      "val Loss: 0.00038394518196582794 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.376s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00332116542590989 Acc: 0.9991319444444444\n",
      "val Loss: 0.00024486519396305084 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.376s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.008666891139000654 Acc: 0.9967447916666666\n",
      "val Loss: 0.00013320241123437881 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.380s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.0029388455570571953 Acc: 0.9995659722222222\n",
      "val Loss: 0.00022952258586883545 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.394s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.004794164405514796 Acc: 0.9989149305555556\n",
      "val Loss: 0.00010449811816215515 Acc: 1.0\n",
      "Epoch    36: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 36 of 500 took 0.378s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.003131990114019977 Acc: 0.9991319444444444\n",
      "val Loss: 0.00011029839515686035 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.368s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.004382663716872533 Acc: 0.9984809027777778\n",
      "val Loss: 0.00021620746701955795 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.371s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00461526597953505 Acc: 0.9989149305555556\n",
      "val Loss: 0.00014050304889678955 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.400s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.0034178245502213636 Acc: 0.9991319444444444\n",
      "val Loss: 0.00027216412127017975 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.330s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.004102791038652261 Acc: 0.9984809027777778\n",
      "val Loss: 0.00019933190196752548 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.296s\n",
      "\n",
      "Training complete in 0m 16s\n",
      "Best val loss: 0.000102\n",
      "ACCURACY TEST_0 FINAL : 100.000 %\n",
      "ACCURACY TEST_1 FINAL : 99.969 %\n",
      "CURRENT DATASET :  4\n",
      "(5308, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.45062519216703045 Acc: 0.8585069444444444\n",
      "val Loss: 0.004878545179963112 Acc: 1.0\n",
      "New best validation loss: 0.004878545179963112\n",
      "Epoch 1 of 500 took 0.383s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.03940095017767615 Acc: 0.9869791666666666\n",
      "val Loss: 0.00409911572933197 Acc: 1.0\n",
      "New best validation loss: 0.00409911572933197\n",
      "Epoch 2 of 500 took 0.476s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.025366607846485242 Acc: 0.9906684027777778\n",
      "val Loss: 0.0015996936708688736 Acc: 1.0\n",
      "New best validation loss: 0.0015996936708688736\n",
      "Epoch 3 of 500 took 0.392s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.013785164492825666 Acc: 0.9967447916666666\n",
      "val Loss: 0.0009494572877883911 Acc: 1.0\n",
      "New best validation loss: 0.0009494572877883911\n",
      "Epoch 4 of 500 took 0.382s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.014750334072030254 Acc: 0.9954427083333334\n",
      "val Loss: 0.0006670830771327019 Acc: 1.0\n",
      "New best validation loss: 0.0006670830771327019\n",
      "Epoch 5 of 500 took 0.445s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.010410516885005765 Acc: 0.998046875\n",
      "val Loss: 0.0006936592981219292 Acc: 1.0\n",
      "Epoch 6 of 500 took 0.373s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.012489534190131558 Acc: 0.99609375\n",
      "val Loss: 0.0004718918353319168 Acc: 1.0\n",
      "New best validation loss: 0.0004718918353319168\n",
      "Epoch 7 of 500 took 0.390s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.01168472935549087 Acc: 0.9963107638888888\n",
      "val Loss: 0.00033826474100351334 Acc: 1.0\n",
      "New best validation loss: 0.00033826474100351334\n",
      "Epoch 8 of 500 took 0.386s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.010279169720080163 Acc: 0.9969618055555556\n",
      "val Loss: 0.0002771122381091118 Acc: 1.0\n",
      "New best validation loss: 0.0002771122381091118\n",
      "Epoch 9 of 500 took 0.380s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00938101542285747 Acc: 0.9971788194444444\n",
      "val Loss: 0.0002531791105866432 Acc: 1.0\n",
      "New best validation loss: 0.0002531791105866432\n",
      "Epoch 10 of 500 took 0.559s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.007153837165484826 Acc: 0.9973958333333334\n",
      "val Loss: 0.00023470818996429443 Acc: 1.0\n",
      "New best validation loss: 0.00023470818996429443\n",
      "Epoch 11 of 500 took 0.423s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.010062226973887946 Acc: 0.9956597222222222\n",
      "val Loss: 0.00022966042160987854 Acc: 1.0\n",
      "New best validation loss: 0.00022966042160987854\n",
      "Epoch 12 of 500 took 0.492s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.005497409341235955 Acc: 0.9989149305555556\n",
      "val Loss: 0.00016114488244056702 Acc: 1.0\n",
      "New best validation loss: 0.00016114488244056702\n",
      "Epoch 13 of 500 took 0.596s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.005506366698278321 Acc: 0.9991319444444444\n",
      "val Loss: 0.0001127738505601883 Acc: 1.0\n",
      "New best validation loss: 0.0001127738505601883\n",
      "Epoch 14 of 500 took 0.500s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.004872450191113684 Acc: 0.9986979166666666\n",
      "val Loss: 0.00014308467507362366 Acc: 1.0\n",
      "Epoch 15 of 500 took 0.377s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.005709859025147226 Acc: 0.998046875\n",
      "val Loss: 9.01632010936737e-05 Acc: 1.0\n",
      "New best validation loss: 9.01632010936737e-05\n",
      "Epoch 16 of 500 took 0.499s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.003823650586936209 Acc: 0.9993489583333334\n",
      "val Loss: 9.462051093578339e-05 Acc: 1.0\n",
      "Epoch 17 of 500 took 0.501s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.003997281141993072 Acc: 0.9995659722222222\n",
      "val Loss: 0.00011459179222583771 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.485s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.004756423541241222 Acc: 0.9989149305555556\n",
      "val Loss: 9.773485362529755e-05 Acc: 1.0\n",
      "Epoch 19 of 500 took 0.408s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00459164675946037 Acc: 0.9989149305555556\n",
      "val Loss: 7.653050124645233e-05 Acc: 1.0\n",
      "New best validation loss: 7.653050124645233e-05\n",
      "Epoch 20 of 500 took 0.351s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0037875638032952943 Acc: 0.9989149305555556\n",
      "val Loss: 0.00010753795504570007 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.514s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.003676903434097767 Acc: 0.9986979166666666\n",
      "val Loss: 6.758049130439758e-05 Acc: 1.0\n",
      "New best validation loss: 6.758049130439758e-05\n",
      "Epoch 22 of 500 took 0.505s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.0026920007334815133 Acc: 0.9993489583333334\n",
      "val Loss: 4.250556230545044e-05 Acc: 1.0\n",
      "New best validation loss: 4.250556230545044e-05\n",
      "Epoch 23 of 500 took 0.505s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.003937053287194835 Acc: 0.9989149305555556\n",
      "val Loss: 5.12395054101944e-05 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.474s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.0016582514055901105 Acc: 0.9995659722222222\n",
      "val Loss: 6.30207359790802e-05 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.410s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.003400084769560231 Acc: 0.9989149305555556\n",
      "val Loss: 3.8135796785354614e-05 Acc: 1.0\n",
      "New best validation loss: 3.8135796785354614e-05\n",
      "Epoch 26 of 500 took 0.373s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.002840109686884615 Acc: 0.9991319444444444\n",
      "val Loss: 2.9910355806350708e-05 Acc: 1.0\n",
      "New best validation loss: 2.9910355806350708e-05\n",
      "Epoch 27 of 500 took 0.364s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.006576893851161003 Acc: 0.9978298611111112\n",
      "val Loss: 6.137415766716003e-05 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.364s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.003310498988462819 Acc: 0.9989149305555556\n",
      "val Loss: 2.9120594263076782e-05 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.433s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0024302429002192286 Acc: 0.9991319444444444\n",
      "val Loss: 2.1496787667274475e-05 Acc: 1.0\n",
      "New best validation loss: 2.1496787667274475e-05\n",
      "Epoch 30 of 500 took 0.364s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.0017251670360565186 Acc: 0.9995659722222222\n",
      "val Loss: 2.3419037461280823e-05 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.377s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00401341263204813 Acc: 0.9991319444444444\n",
      "val Loss: 5.2444636821746826e-05 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.354s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0031842775642871857 Acc: 0.9991319444444444\n",
      "val Loss: 2.351030707359314e-05 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.408s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.0017505502328276634 Acc: 0.9993489583333334\n",
      "val Loss: 2.976134419441223e-05 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.372s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00350653271501263 Acc: 0.9986979166666666\n",
      "val Loss: 3.3000484108924866e-05 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.368s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00247275922447443 Acc: 0.9989149305555556\n",
      "val Loss: 1.955963671207428e-05 Acc: 1.0\n",
      "New best validation loss: 1.955963671207428e-05\n",
      "Epoch 36 of 500 took 0.369s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.0026870889899631343 Acc: 0.9993489583333334\n",
      "val Loss: 2.4145469069480896e-05 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.363s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.0013357674082120259 Acc: 0.9995659722222222\n",
      "val Loss: 2.1498650312423706e-05 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.360s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.0021075914717382854 Acc: 0.9991319444444444\n",
      "val Loss: 1.9945204257965088e-05 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.354s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.001974813122716215 Acc: 0.9993489583333334\n",
      "val Loss: 1.6337260603904724e-05 Acc: 1.0\n",
      "New best validation loss: 1.6337260603904724e-05\n",
      "Epoch 40 of 500 took 0.361s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0014539663162496355 Acc: 1.0\n",
      "val Loss: 1.5202909708023071e-05 Acc: 1.0\n",
      "New best validation loss: 1.5202909708023071e-05\n",
      "Epoch 41 of 500 took 0.351s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.0029138891647259393 Acc: 0.9989149305555556\n",
      "val Loss: 1.4334917068481445e-05 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.360s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.0026852989362345803 Acc: 0.9991319444444444\n",
      "val Loss: 2.2133812308311462e-05 Acc: 1.0\n",
      "Epoch 43 of 500 took 0.355s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.001804990280005667 Acc: 0.9993489583333334\n",
      "val Loss: 1.9300729036331177e-05 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.359s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.0019742842349741194 Acc: 0.9993489583333334\n",
      "val Loss: 1.193210482597351e-05 Acc: 1.0\n",
      "New best validation loss: 1.193210482597351e-05\n",
      "Epoch 45 of 500 took 0.375s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0016823341656062338 Acc: 0.9997829861111112\n",
      "val Loss: 2.1860003471374512e-05 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.505s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0009470594425996145 Acc: 1.0\n",
      "val Loss: 1.3869255781173706e-05 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.443s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.001179528215693103 Acc: 1.0\n",
      "val Loss: 1.50240957736969e-05 Acc: 1.0\n",
      "Epoch 48 of 500 took 0.379s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.0009866317527161704 Acc: 1.0\n",
      "val Loss: 1.4405697584152222e-05 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.549s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.0027288896963000298 Acc: 0.9991319444444444\n",
      "val Loss: 1.3163313269615173e-05 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.701s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.00241617558317052 Acc: 0.9993489583333334\n",
      "val Loss: 8.301809430122375e-06 Acc: 1.0\n",
      "New best validation loss: 8.301809430122375e-06\n",
      "Epoch 51 of 500 took 0.435s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.001647835597395897 Acc: 0.9997829861111112\n",
      "val Loss: 2.2005289793014526e-05 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.308s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0015949004122780429 Acc: 0.9995659722222222\n",
      "val Loss: 1.1608004570007324e-05 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.439s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0015099132433533669 Acc: 0.9997829861111112\n",
      "val Loss: 6.9588422775268555e-06 Acc: 1.0\n",
      "New best validation loss: 6.9588422775268555e-06\n",
      "Epoch 54 of 500 took 0.393s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.007236907362110085 Acc: 0.9978298611111112\n",
      "val Loss: 7.2196125984191895e-06 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.375s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.001573519470791022 Acc: 0.9997829861111112\n",
      "val Loss: 8.422881364822388e-06 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.369s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0009576973194877306 Acc: 1.0\n",
      "val Loss: 7.951632142066956e-06 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.372s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.002008119494550758 Acc: 0.9993489583333334\n",
      "val Loss: 7.575377821922302e-06 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.402s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0010878795550929175 Acc: 1.0\n",
      "val Loss: 8.042901754379272e-06 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.373s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0020650620054867533 Acc: 0.9997829861111112\n",
      "val Loss: 9.952113032341003e-06 Acc: 1.0\n",
      "Epoch    60: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 60 of 500 took 0.372s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.0010666289470261997 Acc: 1.0\n",
      "val Loss: 9.177252650260925e-06 Acc: 1.0\n",
      "Epoch 61 of 500 took 0.384s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.001275355720685588 Acc: 0.9993489583333334\n",
      "val Loss: 5.550682544708252e-06 Acc: 1.0\n",
      "New best validation loss: 5.550682544708252e-06\n",
      "Epoch 62 of 500 took 0.372s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.0018321065646078852 Acc: 0.9997829861111112\n",
      "val Loss: 8.048489689826965e-06 Acc: 1.0\n",
      "Epoch 63 of 500 took 0.366s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.001100546990831693 Acc: 0.9995659722222222\n",
      "val Loss: 8.717179298400879e-06 Acc: 1.0\n",
      "Epoch 64 of 500 took 0.379s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0023987090422047507 Acc: 0.9991319444444444\n",
      "val Loss: 6.748363375663757e-06 Acc: 1.0\n",
      "Epoch 65 of 500 took 0.383s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.0008282276491324106 Acc: 0.9995659722222222\n",
      "val Loss: 6.202608346939087e-06 Acc: 1.0\n",
      "Epoch 66 of 500 took 0.372s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.0009599493609534369 Acc: 1.0\n",
      "val Loss: 6.634742021560669e-06 Acc: 1.0\n",
      "Epoch 67 of 500 took 0.380s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.0006337231025099754 Acc: 1.0\n",
      "val Loss: 6.815418601036072e-06 Acc: 1.0\n",
      "Epoch    68: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 68 of 500 took 0.373s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0015452960506081581 Acc: 0.9993489583333334\n",
      "val Loss: 7.3052942752838135e-06 Acc: 1.0\n",
      "Epoch 69 of 500 took 0.383s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0018397379252645704 Acc: 0.9995659722222222\n",
      "val Loss: 5.234032869338989e-06 Acc: 1.0\n",
      "Epoch 70 of 500 took 0.384s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.0006179505338271459 Acc: 0.9997829861111112\n",
      "val Loss: 7.243826985359192e-06 Acc: 1.0\n",
      "Epoch 71 of 500 took 0.364s\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.0005743542893065347 Acc: 1.0\n",
      "val Loss: 8.532777428627014e-06 Acc: 1.0\n",
      "Epoch 72 of 500 took 0.333s\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.0010650773636168903 Acc: 0.9997829861111112\n",
      "val Loss: 6.901100277900696e-06 Acc: 1.0\n",
      "Epoch 73 of 500 took 0.300s\n",
      "\n",
      "Training complete in 0m 30s\n",
      "Best val loss: 0.000006\n",
      "ACCURACY TEST_0 FINAL : 99.814 %\n",
      "ACCURACY TEST_1 FINAL : 100.000 %\n",
      "CURRENT DATASET :  5\n",
      "(5313, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.6624136178029908 Acc: 0.7842881944444444\n",
      "val Loss: 0.14267699792981148 Acc: 0.939453125\n",
      "New best validation loss: 0.14267699792981148\n",
      "Epoch 1 of 500 took 0.377s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.17245891524685752 Acc: 0.9429253472222222\n",
      "val Loss: 0.09160520508885384 Acc: 0.970703125\n",
      "New best validation loss: 0.09160520508885384\n",
      "Epoch 2 of 500 took 0.446s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.1410145680937502 Acc: 0.9526909722222222\n",
      "val Loss: 0.07358723971992731 Acc: 0.97265625\n",
      "New best validation loss: 0.07358723971992731\n",
      "Epoch 3 of 500 took 0.404s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.12107028646601571 Acc: 0.9594184027777778\n",
      "val Loss: 0.07285401597619057 Acc: 0.974609375\n",
      "New best validation loss: 0.07285401597619057\n",
      "Epoch 4 of 500 took 0.400s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.09994307450122303 Acc: 0.9672309027777778\n",
      "val Loss: 0.06262428592890501 Acc: 0.978515625\n",
      "New best validation loss: 0.06262428592890501\n",
      "Epoch 5 of 500 took 0.401s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.09875466198556954 Acc: 0.9674479166666666\n",
      "val Loss: 0.05860173515975475 Acc: 0.978515625\n",
      "New best validation loss: 0.05860173515975475\n",
      "Epoch 6 of 500 took 0.381s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.0931762204402023 Acc: 0.9650607638888888\n",
      "val Loss: 0.05410696007311344 Acc: 0.982421875\n",
      "New best validation loss: 0.05410696007311344\n",
      "Epoch 7 of 500 took 0.373s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.08227742608222696 Acc: 0.9730902777777778\n",
      "val Loss: 0.04435280431061983 Acc: 0.984375\n",
      "New best validation loss: 0.04435280431061983\n",
      "Epoch 8 of 500 took 0.376s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.07988501195278433 Acc: 0.9715711805555556\n",
      "val Loss: 0.05489557143300772 Acc: 0.978515625\n",
      "Epoch 9 of 500 took 0.388s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.0697760929663976 Acc: 0.9756944444444444\n",
      "val Loss: 0.05110061354935169 Acc: 0.982421875\n",
      "Epoch 10 of 500 took 0.485s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.07576880593680674 Acc: 0.9715711805555556\n",
      "val Loss: 0.050189423374831676 Acc: 0.98046875\n",
      "Epoch 11 of 500 took 0.470s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.07849829685356882 Acc: 0.9722222222222222\n",
      "val Loss: 0.07417882420122623 Acc: 0.9765625\n",
      "Epoch 12 of 500 took 0.388s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.06981367907590336 Acc: 0.9754774305555556\n",
      "val Loss: 0.05263163335621357 Acc: 0.984375\n",
      "Epoch 13 of 500 took 0.563s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.060755772723091975 Acc: 0.9798177083333334\n",
      "val Loss: 0.042608123272657394 Acc: 0.982421875\n",
      "New best validation loss: 0.042608123272657394\n",
      "Epoch 14 of 500 took 0.644s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.056231169030070305 Acc: 0.9798177083333334\n",
      "val Loss: 0.03793923603370786 Acc: 0.986328125\n",
      "New best validation loss: 0.03793923603370786\n",
      "Epoch 15 of 500 took 0.297s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.060964457483755216 Acc: 0.978515625\n",
      "val Loss: 0.04025653935968876 Acc: 0.984375\n",
      "Epoch 16 of 500 took 0.299s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.04494470223370525 Acc: 0.9839409722222222\n",
      "val Loss: 0.04263533651828766 Acc: 0.984375\n",
      "Epoch 17 of 500 took 0.288s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.04926083981990814 Acc: 0.9809027777777778\n",
      "val Loss: 0.0325790261849761 Acc: 0.986328125\n",
      "New best validation loss: 0.0325790261849761\n",
      "Epoch 18 of 500 took 0.307s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.05668658287160926 Acc: 0.9813368055555556\n",
      "val Loss: 0.037790278904139996 Acc: 0.984375\n",
      "Epoch 19 of 500 took 0.324s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.054593444905347295 Acc: 0.98046875\n",
      "val Loss: 0.028764291666448116 Acc: 0.98828125\n",
      "New best validation loss: 0.028764291666448116\n",
      "Epoch 20 of 500 took 0.310s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0475863932321469 Acc: 0.9845920138888888\n",
      "val Loss: 0.028661303222179413 Acc: 0.986328125\n",
      "New best validation loss: 0.028661303222179413\n",
      "Epoch 21 of 500 took 0.374s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.04291390824235148 Acc: 0.984375\n",
      "val Loss: 0.030365368351340294 Acc: 0.98828125\n",
      "Epoch 22 of 500 took 0.359s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.04356851273526748 Acc: 0.9848090277777778\n",
      "val Loss: 0.04086056258529425 Acc: 0.984375\n",
      "Epoch 23 of 500 took 0.346s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.041695828860004745 Acc: 0.9845920138888888\n",
      "val Loss: 0.03143278881907463 Acc: 0.986328125\n",
      "Epoch 24 of 500 took 0.388s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.041236335722108684 Acc: 0.9854600694444444\n",
      "val Loss: 0.022013992071151733 Acc: 0.990234375\n",
      "New best validation loss: 0.022013992071151733\n",
      "Epoch 25 of 500 took 0.416s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.03953444316155381 Acc: 0.9852430555555556\n",
      "val Loss: 0.025641913525760174 Acc: 0.9921875\n",
      "Epoch 26 of 500 took 0.345s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.03952506339798371 Acc: 0.9858940972222222\n",
      "val Loss: 0.02926637791097164 Acc: 0.986328125\n",
      "Epoch 27 of 500 took 0.365s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.03812449508243137 Acc: 0.9874131944444444\n",
      "val Loss: 0.02713157795369625 Acc: 0.986328125\n",
      "Epoch 28 of 500 took 0.457s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.03352296595565147 Acc: 0.9880642361111112\n",
      "val Loss: 0.02417176589369774 Acc: 0.98828125\n",
      "Epoch 29 of 500 took 0.329s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.02541413178874387 Acc: 0.9911024305555556\n",
      "val Loss: 0.02786934282630682 Acc: 0.986328125\n",
      "Epoch 30 of 500 took 0.340s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.03221413938121663 Acc: 0.9887152777777778\n",
      "val Loss: 0.032414440996944904 Acc: 0.986328125\n",
      "Epoch    31: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 31 of 500 took 0.341s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.02946383650932047 Acc: 0.9904513888888888\n",
      "val Loss: 0.02931311633437872 Acc: 0.986328125\n",
      "Epoch 32 of 500 took 0.350s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.029082302055839036 Acc: 0.9889322916666666\n",
      "val Loss: 0.024170891381800175 Acc: 0.986328125\n",
      "Epoch 33 of 500 took 0.376s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.026007753227733903 Acc: 0.9891493055555556\n",
      "val Loss: 0.023290300741791725 Acc: 0.98828125\n",
      "Epoch 34 of 500 took 0.388s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.027040134494503338 Acc: 0.9915364583333334\n",
      "val Loss: 0.024383549578487873 Acc: 0.98828125\n",
      "Epoch 35 of 500 took 0.377s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.020140386910902128 Acc: 0.9939236111111112\n",
      "val Loss: 0.028126517310738564 Acc: 0.986328125\n",
      "Epoch 36 of 500 took 0.375s\n",
      "\n",
      "Training complete in 0m 14s\n",
      "Best val loss: 0.022014\n",
      "ACCURACY TEST_0 FINAL : 98.728 %\n",
      "ACCURACY TEST_1 FINAL : 91.692 %\n",
      "CURRENT DATASET :  6\n",
      "(5311, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5754279941320419 Acc: 0.8079427083333334\n",
      "val Loss: 0.08517574518918991 Acc: 0.96484375\n",
      "New best validation loss: 0.08517574518918991\n",
      "Epoch 1 of 500 took 0.292s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.1505317096081045 Acc: 0.9448784722222222\n",
      "val Loss: 0.02891584485769272 Acc: 0.9921875\n",
      "New best validation loss: 0.02891584485769272\n",
      "Epoch 2 of 500 took 0.358s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.1092600818309519 Acc: 0.9631076388888888\n",
      "val Loss: 0.026514549739658833 Acc: 0.9921875\n",
      "New best validation loss: 0.026514549739658833\n",
      "Epoch 3 of 500 took 0.394s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.0853517394926813 Acc: 0.9696180555555556\n",
      "val Loss: 0.019980146549642086 Acc: 0.994140625\n",
      "New best validation loss: 0.019980146549642086\n",
      "Epoch 4 of 500 took 0.370s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.0691411497278346 Acc: 0.9754774305555556\n",
      "val Loss: 0.042559121735394 Acc: 0.982421875\n",
      "Epoch 5 of 500 took 0.361s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.06730316103332573 Acc: 0.9791666666666666\n",
      "val Loss: 0.03369013499468565 Acc: 0.986328125\n",
      "Epoch 6 of 500 took 0.334s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.04400084540247917 Acc: 0.986328125\n",
      "val Loss: 0.017577714286744595 Acc: 0.9921875\n",
      "New best validation loss: 0.017577714286744595\n",
      "Epoch 7 of 500 took 0.344s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.043791554350819856 Acc: 0.9852430555555556\n",
      "val Loss: 0.014765365049242973 Acc: 0.994140625\n",
      "New best validation loss: 0.014765365049242973\n",
      "Epoch 8 of 500 took 0.361s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.039414560629261866 Acc: 0.9871961805555556\n",
      "val Loss: 0.00996930431574583 Acc: 0.99609375\n",
      "New best validation loss: 0.00996930431574583\n",
      "Epoch 9 of 500 took 0.356s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.03834722015178866 Acc: 0.9869791666666666\n",
      "val Loss: 0.009955169633030891 Acc: 0.99609375\n",
      "New best validation loss: 0.009955169633030891\n",
      "Epoch 10 of 500 took 0.354s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.042007133468157716 Acc: 0.9850260416666666\n",
      "val Loss: 0.0078028542920947075 Acc: 0.99609375\n",
      "New best validation loss: 0.0078028542920947075\n",
      "Epoch 11 of 500 took 0.390s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.03251159848231408 Acc: 0.9884982638888888\n",
      "val Loss: 0.0059803081676363945 Acc: 0.998046875\n",
      "New best validation loss: 0.0059803081676363945\n",
      "Epoch 12 of 500 took 0.359s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.029837195347580645 Acc: 0.9874131944444444\n",
      "val Loss: 0.021960739977657795 Acc: 0.994140625\n",
      "Epoch 13 of 500 took 0.437s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.03560559834457106 Acc: 0.9876302083333334\n",
      "val Loss: 0.03962438739836216 Acc: 0.982421875\n",
      "Epoch 14 of 500 took 0.496s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.036375952470633716 Acc: 0.9867621527777778\n",
      "val Loss: 0.0077455295249819756 Acc: 0.99609375\n",
      "Epoch 15 of 500 took 0.522s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.026389057385838695 Acc: 0.9913194444444444\n",
      "val Loss: 0.009569485671818256 Acc: 0.99609375\n",
      "Epoch 16 of 500 took 0.601s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.021023191201190155 Acc: 0.9921875\n",
      "val Loss: 0.009080246090888977 Acc: 0.99609375\n",
      "Epoch 17 of 500 took 0.447s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.018988623852945037 Acc: 0.9932725694444444\n",
      "val Loss: 0.007491741329431534 Acc: 0.99609375\n",
      "Epoch    18: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 18 of 500 took 0.313s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.02377150859683752 Acc: 0.9921875\n",
      "val Loss: 0.007293949835002422 Acc: 0.99609375\n",
      "Epoch 19 of 500 took 0.319s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.0182740974964367 Acc: 0.9939236111111112\n",
      "val Loss: 0.005716101266443729 Acc: 0.99609375\n",
      "New best validation loss: 0.005716101266443729\n",
      "Epoch 20 of 500 took 0.284s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.018334668388383255 Acc: 0.9932725694444444\n",
      "val Loss: 0.013200490735471249 Acc: 0.99609375\n",
      "Epoch 21 of 500 took 0.265s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.01749215244005124 Acc: 0.9945746527777778\n",
      "val Loss: 0.010092905722558498 Acc: 0.99609375\n",
      "Epoch 22 of 500 took 0.332s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.012277611272616519 Acc: 0.9956597222222222\n",
      "val Loss: 0.009606940671801567 Acc: 0.99609375\n",
      "Epoch 23 of 500 took 0.289s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.01822900503045983 Acc: 0.9943576388888888\n",
      "val Loss: 0.006816527806222439 Acc: 0.998046875\n",
      "Epoch 24 of 500 took 0.332s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.01638372464933329 Acc: 0.9937065972222222\n",
      "val Loss: 0.012988830916583538 Acc: 0.99609375\n",
      "Epoch 25 of 500 took 0.346s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.016638846343590155 Acc: 0.9937065972222222\n",
      "val Loss: 0.008987325243651867 Acc: 0.99609375\n",
      "Epoch    26: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 26 of 500 took 0.347s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.0135444775223732 Acc: 0.9950086805555556\n",
      "val Loss: 0.008021607995033264 Acc: 0.99609375\n",
      "Epoch 27 of 500 took 0.351s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.014486573740012117 Acc: 0.9954427083333334\n",
      "val Loss: 0.007341011427342892 Acc: 0.99609375\n",
      "Epoch 28 of 500 took 0.377s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.01397892160134183 Acc: 0.9952256944444444\n",
      "val Loss: 0.0076589081436395645 Acc: 0.99609375\n",
      "Epoch 29 of 500 took 0.366s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.013554713792271085 Acc: 0.9956597222222222\n",
      "val Loss: 0.0068068718537688255 Acc: 0.99609375\n",
      "Epoch 30 of 500 took 0.352s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.01187789315978686 Acc: 0.9969618055555556\n",
      "val Loss: 0.008246251381933689 Acc: 0.99609375\n",
      "Epoch 31 of 500 took 0.368s\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val loss: 0.005716\n",
      "ACCURACY TEST_0 FINAL : 99.349 %\n",
      "ACCURACY TEST_1 FINAL : 100.000 %\n",
      "CURRENT DATASET :  7\n",
      "(5305, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5232290528300736 Acc: 0.8396267361111112\n",
      "val Loss: 0.008106105960905552 Acc: 0.998046875\n",
      "New best validation loss: 0.008106105960905552\n",
      "Epoch 1 of 500 took 0.321s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.040773938616944685 Acc: 0.9867621527777778\n",
      "val Loss: 0.002423609606921673 Acc: 1.0\n",
      "New best validation loss: 0.002423609606921673\n",
      "Epoch 2 of 500 took 0.374s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.0319834402244952 Acc: 0.9904513888888888\n",
      "val Loss: 0.005627085454761982 Acc: 1.0\n",
      "Epoch 3 of 500 took 0.361s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.02038856911369496 Acc: 0.9926215277777778\n",
      "val Loss: 0.002323143184185028 Acc: 1.0\n",
      "New best validation loss: 0.002323143184185028\n",
      "Epoch 4 of 500 took 0.360s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.016751427048196394 Acc: 0.994140625\n",
      "val Loss: 0.0015228977426886559 Acc: 1.0\n",
      "New best validation loss: 0.0015228977426886559\n",
      "Epoch 5 of 500 took 0.348s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.013082833288030492 Acc: 0.9958767361111112\n",
      "val Loss: 0.001919410191476345 Acc: 1.0\n",
      "Epoch 6 of 500 took 0.333s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.012257136404514313 Acc: 0.9958767361111112\n",
      "val Loss: 0.0017130319029092789 Acc: 1.0\n",
      "Epoch 7 of 500 took 0.351s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.012217939676096043 Acc: 0.9967447916666666\n",
      "val Loss: 0.0011855997145175934 Acc: 1.0\n",
      "New best validation loss: 0.0011855997145175934\n",
      "Epoch 8 of 500 took 0.364s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.008381076674494479 Acc: 0.9978298611111112\n",
      "val Loss: 0.0010079331696033478 Acc: 1.0\n",
      "New best validation loss: 0.0010079331696033478\n",
      "Epoch 9 of 500 took 0.346s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.012651481303489871 Acc: 0.9954427083333334\n",
      "val Loss: 0.0009026313200592995 Acc: 1.0\n",
      "New best validation loss: 0.0009026313200592995\n",
      "Epoch 10 of 500 took 0.367s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00675918808620837 Acc: 0.9973958333333334\n",
      "val Loss: 0.0018557505682110786 Acc: 1.0\n",
      "Epoch 11 of 500 took 0.287s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.006723435854332315 Acc: 0.9984809027777778\n",
      "val Loss: 0.0010678134858608246 Acc: 1.0\n",
      "Epoch 12 of 500 took 0.307s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.004643710692309671 Acc: 0.9984809027777778\n",
      "val Loss: 0.0007445067167282104 Acc: 1.0\n",
      "New best validation loss: 0.0007445067167282104\n",
      "Epoch 13 of 500 took 0.320s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00503947420252694 Acc: 0.9982638888888888\n",
      "val Loss: 0.0007576681673526764 Acc: 1.0\n",
      "Epoch 14 of 500 took 0.408s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.006526922082735432 Acc: 0.9971788194444444\n",
      "val Loss: 0.00010394304990768433 Acc: 1.0\n",
      "New best validation loss: 0.00010394304990768433\n",
      "Epoch 15 of 500 took 0.303s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.006239873822778463 Acc: 0.9986979166666666\n",
      "val Loss: 0.0005474500358104706 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.298s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.004765202756971121 Acc: 0.9986979166666666\n",
      "val Loss: 0.0007523773238062859 Acc: 1.0\n",
      "Epoch 17 of 500 took 0.307s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.006555327421261204 Acc: 0.9989149305555556\n",
      "val Loss: 0.00033816322684288025 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.294s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.004710531172653039 Acc: 0.9984809027777778\n",
      "val Loss: 0.00045955367386341095 Acc: 1.0\n",
      "Epoch 19 of 500 took 0.301s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.004550282584710253 Acc: 0.9982638888888888\n",
      "val Loss: 0.0006106607615947723 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.318s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.005367926011482875 Acc: 0.9984809027777778\n",
      "val Loss: 0.00020520761609077454 Acc: 1.0\n",
      "Epoch    21: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 21 of 500 took 0.302s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.004240452415413327 Acc: 0.9989149305555556\n",
      "val Loss: 0.0002398137003183365 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.305s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.004001696076658037 Acc: 0.9986979166666666\n",
      "val Loss: 0.00018303282558918 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.302s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.003654071440299352 Acc: 0.9991319444444444\n",
      "val Loss: 0.0002058856189250946 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.302s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.004116238301826848 Acc: 0.9984809027777778\n",
      "val Loss: 0.0002163313329219818 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.536s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.003747638211482101 Acc: 0.9993489583333334\n",
      "val Loss: 0.0002849157899618149 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.412s\n",
      "\n",
      "Training complete in 0m 9s\n",
      "Best val loss: 0.000104\n",
      "ACCURACY TEST_0 FINAL : 99.969 %\n",
      "ACCURACY TEST_1 FINAL : 100.000 %\n",
      "CURRENT DATASET :  8\n",
      "(5314, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.4213251063807143 Acc: 0.8743489583333334\n",
      "val Loss: 0.001506664790213108 Acc: 1.0\n",
      "New best validation loss: 0.001506664790213108\n",
      "Epoch 1 of 500 took 0.529s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.037618919275701046 Acc: 0.9878472222222222\n",
      "val Loss: 0.002489500679075718 Acc: 1.0\n",
      "Epoch 2 of 500 took 0.404s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.023982882861875825 Acc: 0.9924045138888888\n",
      "val Loss: 0.0018867673352360725 Acc: 1.0\n",
      "Epoch 3 of 500 took 0.316s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.016042462808804378 Acc: 0.9945746527777778\n",
      "val Loss: 0.0007739458233118057 Acc: 1.0\n",
      "New best validation loss: 0.0007739458233118057\n",
      "Epoch 4 of 500 took 0.316s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.010289435274899006 Acc: 0.9971788194444444\n",
      "val Loss: 0.0007990403100848198 Acc: 1.0\n",
      "Epoch 5 of 500 took 0.304s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.01371320378449228 Acc: 0.9967447916666666\n",
      "val Loss: 0.000484732910990715 Acc: 1.0\n",
      "New best validation loss: 0.000484732910990715\n",
      "Epoch 6 of 500 took 0.312s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.009692031372752454 Acc: 0.9978298611111112\n",
      "val Loss: 0.00044377148151397705 Acc: 1.0\n",
      "New best validation loss: 0.00044377148151397705\n",
      "Epoch 7 of 500 took 0.309s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.008895671978178952 Acc: 0.9971788194444444\n",
      "val Loss: 0.0002065887674689293 Acc: 1.0\n",
      "New best validation loss: 0.0002065887674689293\n",
      "Epoch 8 of 500 took 0.318s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.006389438485105832 Acc: 0.9984809027777778\n",
      "val Loss: 0.00022559892386198044 Acc: 1.0\n",
      "Epoch 9 of 500 took 0.298s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.008057308279805712 Acc: 0.9973958333333334\n",
      "val Loss: 0.000190073624253273 Acc: 1.0\n",
      "New best validation loss: 0.000190073624253273\n",
      "Epoch 10 of 500 took 0.314s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.006332440560476648 Acc: 0.9982638888888888\n",
      "val Loss: 0.00030633434653282166 Acc: 1.0\n",
      "Epoch 11 of 500 took 0.300s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.007120551593187783 Acc: 0.9973958333333334\n",
      "val Loss: 0.00020901206880807877 Acc: 1.0\n",
      "Epoch 12 of 500 took 0.318s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.003933178985284435 Acc: 0.9993489583333334\n",
      "val Loss: 0.0001842193305492401 Acc: 1.0\n",
      "New best validation loss: 0.0001842193305492401\n",
      "Epoch 13 of 500 took 0.349s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.005725125316530466 Acc: 0.9976128472222222\n",
      "val Loss: 0.00011509936302900314 Acc: 1.0\n",
      "New best validation loss: 0.00011509936302900314\n",
      "Epoch 14 of 500 took 0.363s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.003906961271746291 Acc: 0.9989149305555556\n",
      "val Loss: 4.929676651954651e-05 Acc: 1.0\n",
      "New best validation loss: 4.929676651954651e-05\n",
      "Epoch 15 of 500 took 0.340s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.004220139338738388 Acc: 0.9989149305555556\n",
      "val Loss: 0.00013186782598495483 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.379s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.004677329108946853 Acc: 0.9984809027777778\n",
      "val Loss: 6.174296140670776e-05 Acc: 1.0\n",
      "Epoch 17 of 500 took 0.320s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.005734247569408681 Acc: 0.9991319444444444\n",
      "val Loss: 6.93080946803093e-05 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.302s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.003624443482193682 Acc: 0.9991319444444444\n",
      "val Loss: 0.00016926415264606476 Acc: 1.0\n",
      "Epoch 19 of 500 took 0.349s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.005164861523856719 Acc: 0.998046875\n",
      "val Loss: 0.00014801695942878723 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.358s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0041673388332128525 Acc: 0.9986979166666666\n",
      "val Loss: 4.712492227554321e-05 Acc: 1.0\n",
      "New best validation loss: 4.712492227554321e-05\n",
      "Epoch 21 of 500 took 0.411s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.003452491894778278 Acc: 0.9986979166666666\n",
      "val Loss: 0.00011289119720458984 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.353s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.0030845020794206196 Acc: 0.9986979166666666\n",
      "val Loss: 3.82009893655777e-05 Acc: 1.0\n",
      "New best validation loss: 3.82009893655777e-05\n",
      "Epoch 23 of 500 took 0.343s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.002837908764680227 Acc: 0.9986979166666666\n",
      "val Loss: 4.215538501739502e-05 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.323s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.0031830622918075984 Acc: 0.9986979166666666\n",
      "val Loss: 4.5515596866607666e-05 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.306s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.003017679891652531 Acc: 0.9993489583333334\n",
      "val Loss: 4.3983571231365204e-05 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.310s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.001781667789651288 Acc: 0.9997829861111112\n",
      "val Loss: 5.1563605666160583e-05 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.308s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.0024094700088931453 Acc: 0.9993489583333334\n",
      "val Loss: 3.192201256752014e-05 Acc: 1.0\n",
      "New best validation loss: 3.192201256752014e-05\n",
      "Epoch 28 of 500 took 0.346s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.003462039658592807 Acc: 0.9993489583333334\n",
      "val Loss: 0.00012497976422309875 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.358s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0015353684624036152 Acc: 0.9995659722222222\n",
      "val Loss: 2.6596710085868835e-05 Acc: 1.0\n",
      "New best validation loss: 2.6596710085868835e-05\n",
      "Epoch 30 of 500 took 0.353s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.0034020298367573153 Acc: 0.9984809027777778\n",
      "val Loss: 5.5487267673015594e-05 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.373s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.0014160918589267465 Acc: 0.9997829861111112\n",
      "val Loss: 3.7468038499355316e-05 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.362s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0016476200997001594 Acc: 0.9993489583333334\n",
      "val Loss: 2.9340386390686035e-05 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.364s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.0018531856023603016 Acc: 0.9995659722222222\n",
      "val Loss: 1.8211081624031067e-05 Acc: 1.0\n",
      "New best validation loss: 1.8211081624031067e-05\n",
      "Epoch 34 of 500 took 0.356s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00231515947315428 Acc: 0.9993489583333334\n",
      "val Loss: 2.248212695121765e-05 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.335s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0022343572022186387 Acc: 0.9995659722222222\n",
      "val Loss: 2.7857720851898193e-05 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.268s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.0009394069719645712 Acc: 1.0\n",
      "val Loss: 2.989359200000763e-05 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.308s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.0009682040351132551 Acc: 1.0\n",
      "val Loss: 2.1534040570259094e-05 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.302s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.002011342543280787 Acc: 0.9991319444444444\n",
      "val Loss: 1.839175820350647e-05 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.275s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.0018077539280056953 Acc: 0.9993489583333334\n",
      "val Loss: 4.2166560888290405e-05 Acc: 1.0\n",
      "Epoch    40: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 40 of 500 took 0.289s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0028250484416882196 Acc: 0.9993489583333334\n",
      "val Loss: 2.9906630516052246e-05 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.522s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00219981972542074 Acc: 0.9991319444444444\n",
      "val Loss: 1.9144266843795776e-05 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.374s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.0016877703989545505 Acc: 0.9995659722222222\n",
      "val Loss: 1.7153099179267883e-05 Acc: 1.0\n",
      "New best validation loss: 1.7153099179267883e-05\n",
      "Epoch 43 of 500 took 0.321s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0014491406165891224 Acc: 0.9995659722222222\n",
      "val Loss: 1.4768913388252258e-05 Acc: 1.0\n",
      "New best validation loss: 1.4768913388252258e-05\n",
      "Epoch 44 of 500 took 0.479s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.0010916964254445499 Acc: 0.9997829861111112\n",
      "val Loss: 1.325272023677826e-05 Acc: 1.0\n",
      "New best validation loss: 1.325272023677826e-05\n",
      "Epoch 45 of 500 took 0.721s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.000769974249932501 Acc: 1.0\n",
      "val Loss: 1.2986361980438232e-05 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.524s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0006607270075215234 Acc: 0.9997829861111112\n",
      "val Loss: 1.4018267393112183e-05 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.315s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.0006256161464585199 Acc: 1.0\n",
      "val Loss: 1.4137476682662964e-05 Acc: 1.0\n",
      "Epoch 48 of 500 took 0.312s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.000540765519771311 Acc: 1.0\n",
      "val Loss: 1.5117228031158447e-05 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.320s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.002092580311000347 Acc: 0.9991319444444444\n",
      "val Loss: 1.5404075384140015e-05 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.348s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.0004983730614185333 Acc: 1.0\n",
      "val Loss: 1.4338642358779907e-05 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.308s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0009582946076989174 Acc: 0.9995659722222222\n",
      "val Loss: 1.2934207916259766e-05 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.327s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0014123287465837267 Acc: 0.9997829861111112\n",
      "val Loss: 1.2587755918502808e-05 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.326s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0009406962328486972 Acc: 0.9997829861111112\n",
      "val Loss: 9.611248970031738e-06 Acc: 1.0\n",
      "New best validation loss: 9.611248970031738e-06\n",
      "Epoch 54 of 500 took 0.334s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.0011091063626938397 Acc: 0.9993489583333334\n",
      "val Loss: 1.0652467608451843e-05 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.340s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0013835042094190915 Acc: 0.9993489583333334\n",
      "val Loss: 1.2684613466262817e-05 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.349s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0012533811645375357 Acc: 0.9995659722222222\n",
      "val Loss: 1.2662261724472046e-05 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.328s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.0013814270496368408 Acc: 0.9995659722222222\n",
      "val Loss: 1.0598450899124146e-05 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.370s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0019295760430395603 Acc: 0.9993489583333334\n",
      "val Loss: 8.542090654373169e-06 Acc: 1.0\n",
      "New best validation loss: 8.542090654373169e-06\n",
      "Epoch 59 of 500 took 0.359s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0014226750677658452 Acc: 0.9993489583333334\n",
      "val Loss: 1.2263655662536621e-05 Acc: 1.0\n",
      "Epoch 60 of 500 took 0.368s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.0005819305984510316 Acc: 1.0\n",
      "val Loss: 1.1749565601348877e-05 Acc: 1.0\n",
      "Epoch 61 of 500 took 0.356s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.00044430730243523914 Acc: 1.0\n",
      "val Loss: 1.0406598448753357e-05 Acc: 1.0\n",
      "Epoch 62 of 500 took 0.344s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.0005022527443038092 Acc: 1.0\n",
      "val Loss: 8.367002010345459e-06 Acc: 1.0\n",
      "Epoch 63 of 500 took 0.351s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.0008063670247793198 Acc: 0.9997829861111112\n",
      "val Loss: 9.875744581222534e-06 Acc: 1.0\n",
      "Epoch 64 of 500 took 0.309s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0006789414005147086 Acc: 0.9997829861111112\n",
      "val Loss: 1.4530494809150696e-05 Acc: 1.0\n",
      "Epoch 65 of 500 took 0.319s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.0017528778666423426 Acc: 0.9993489583333334\n",
      "val Loss: 1.6046687960624695e-05 Acc: 1.0\n",
      "Epoch 66 of 500 took 0.319s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.0005257921293377876 Acc: 1.0\n",
      "val Loss: 1.6264617443084717e-05 Acc: 1.0\n",
      "Epoch 67 of 500 took 0.296s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.0007681343704462051 Acc: 1.0\n",
      "val Loss: 1.56499445438385e-05 Acc: 1.0\n",
      "Epoch 68 of 500 took 0.303s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0019299075938761234 Acc: 0.9991319444444444\n",
      "val Loss: 1.706741750240326e-05 Acc: 1.0\n",
      "Epoch    69: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 69 of 500 took 0.368s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0006074197590351105 Acc: 0.9997829861111112\n",
      "val Loss: 1.158192753791809e-05 Acc: 1.0\n",
      "Epoch 70 of 500 took 0.328s\n",
      "\n",
      "Training complete in 0m 24s\n",
      "Best val loss: 0.000009\n",
      "ACCURACY TEST_0 FINAL : 99.938 %\n",
      "ACCURACY TEST_1 FINAL : 99.969 %\n",
      "CURRENT DATASET :  9\n",
      "(5313, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5544769085115857 Acc: 0.828125\n",
      "val Loss: 0.040617081336677074 Acc: 0.986328125\n",
      "New best validation loss: 0.040617081336677074\n",
      "Epoch 1 of 500 took 0.301s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.09536540632446606 Acc: 0.9661458333333334\n",
      "val Loss: 0.01033190730959177 Acc: 0.99609375\n",
      "New best validation loss: 0.01033190730959177\n",
      "Epoch 2 of 500 took 0.323s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.06260660176889764 Acc: 0.9776475694444444\n",
      "val Loss: 0.01650145649909973 Acc: 0.99609375\n",
      "Epoch 3 of 500 took 0.310s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.04954666333893935 Acc: 0.9839409722222222\n",
      "val Loss: 0.013694376684725285 Acc: 0.998046875\n",
      "Epoch 4 of 500 took 0.320s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.04270915769868427 Acc: 0.984375\n",
      "val Loss: 0.0069938888773322105 Acc: 0.998046875\n",
      "New best validation loss: 0.0069938888773322105\n",
      "Epoch 5 of 500 took 0.328s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.03796977022041877 Acc: 0.9869791666666666\n",
      "val Loss: 0.007030662149190903 Acc: 0.998046875\n",
      "Epoch 6 of 500 took 0.373s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.029867999255657196 Acc: 0.9895833333333334\n",
      "val Loss: 0.007660822011530399 Acc: 0.998046875\n",
      "Epoch 7 of 500 took 0.340s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.030778983607888222 Acc: 0.9904513888888888\n",
      "val Loss: 0.003861762583255768 Acc: 0.998046875\n",
      "New best validation loss: 0.003861762583255768\n",
      "Epoch 8 of 500 took 0.357s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.021750338944709964 Acc: 0.9932725694444444\n",
      "val Loss: 0.006577850319445133 Acc: 0.998046875\n",
      "Epoch 9 of 500 took 0.304s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.020103825566669304 Acc: 0.9928385416666666\n",
      "val Loss: 0.005670872516930103 Acc: 0.998046875\n",
      "Epoch 10 of 500 took 0.359s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.02046514581888914 Acc: 0.9937065972222222\n",
      "val Loss: 0.003221244551241398 Acc: 0.998046875\n",
      "New best validation loss: 0.003221244551241398\n",
      "Epoch 11 of 500 took 0.305s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.017798610186825197 Acc: 0.9932725694444444\n",
      "val Loss: 0.002680467441678047 Acc: 0.998046875\n",
      "New best validation loss: 0.002680467441678047\n",
      "Epoch 12 of 500 took 0.315s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.01708139670598838 Acc: 0.9950086805555556\n",
      "val Loss: 0.0058471206575632095 Acc: 0.998046875\n",
      "Epoch 13 of 500 took 0.485s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.02172882409973277 Acc: 0.9911024305555556\n",
      "val Loss: 0.00248543918132782 Acc: 0.998046875\n",
      "New best validation loss: 0.00248543918132782\n",
      "Epoch 14 of 500 took 0.300s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.013514613577475151 Acc: 0.9950086805555556\n",
      "val Loss: 0.003970962017774582 Acc: 0.998046875\n",
      "Epoch 15 of 500 took 0.547s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.01846931129693985 Acc: 0.9924045138888888\n",
      "val Loss: 0.0027094641700387 Acc: 0.998046875\n",
      "Epoch 16 of 500 took 0.564s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.01329883493276106 Acc: 0.9947916666666666\n",
      "val Loss: 0.0027197711169719696 Acc: 0.998046875\n",
      "Epoch 17 of 500 took 0.483s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.012527697305712435 Acc: 0.99609375\n",
      "val Loss: 0.0031294431537389755 Acc: 0.998046875\n",
      "Epoch 18 of 500 took 0.389s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.012460621901684336 Acc: 0.9967447916666666\n",
      "val Loss: 0.0028722239658236504 Acc: 0.998046875\n",
      "Epoch 19 of 500 took 0.316s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.01699682164730297 Acc: 0.9932725694444444\n",
      "val Loss: 0.000428246334195137 Acc: 1.0\n",
      "New best validation loss: 0.000428246334195137\n",
      "Epoch 20 of 500 took 0.300s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.012912524760597281 Acc: 0.9952256944444444\n",
      "val Loss: 0.004295580089092255 Acc: 0.998046875\n",
      "Epoch 21 of 500 took 0.400s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.014742765316946639 Acc: 0.994140625\n",
      "val Loss: 0.00232890248298645 Acc: 0.998046875\n",
      "Epoch 22 of 500 took 0.371s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.009750587813970115 Acc: 0.99609375\n",
      "val Loss: 0.0022448059171438217 Acc: 0.998046875\n",
      "Epoch 23 of 500 took 0.377s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.009798025764111016 Acc: 0.9967447916666666\n",
      "val Loss: 0.003663867712020874 Acc: 0.998046875\n",
      "Epoch 24 of 500 took 0.370s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.010917607436163558 Acc: 0.99609375\n",
      "val Loss: 0.0036802738904953003 Acc: 0.998046875\n",
      "Epoch 25 of 500 took 0.374s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.009260326830877198 Acc: 0.9967447916666666\n",
      "val Loss: 0.0011215023696422577 Acc: 1.0\n",
      "Epoch    26: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 26 of 500 took 0.360s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.008733634526530901 Acc: 0.9973958333333334\n",
      "val Loss: 0.0018145572394132614 Acc: 0.998046875\n",
      "Epoch 27 of 500 took 0.405s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.009128214791417122 Acc: 0.9971788194444444\n",
      "val Loss: 0.002014562487602234 Acc: 0.998046875\n",
      "Epoch 28 of 500 took 0.371s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.008031273105492195 Acc: 0.9965277777777778\n",
      "val Loss: 0.0029192939400672913 Acc: 0.998046875\n",
      "Epoch 29 of 500 took 0.420s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00943234438697497 Acc: 0.9969618055555556\n",
      "val Loss: 0.0030800625681877136 Acc: 0.998046875\n",
      "Epoch 30 of 500 took 0.420s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.008040941837761138 Acc: 0.9969618055555556\n",
      "val Loss: 0.0035370830446481705 Acc: 0.998046875\n",
      "Epoch 31 of 500 took 0.377s\n",
      "\n",
      "Training complete in 0m 12s\n",
      "Best val loss: 0.000428\n",
      "ACCURACY TEST_0 FINAL : 98.264 %\n",
      "ACCURACY TEST_1 FINAL : 99.008 %\n",
      "CURRENT DATASET :  10\n",
      "(5308, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5768165344165431 Acc: 0.8233506944444444\n",
      "val Loss: 0.12798637617379427 Acc: 0.966796875\n",
      "New best validation loss: 0.12798637617379427\n",
      "Epoch 1 of 500 took 0.380s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.1315078909198443 Acc: 0.9574652777777778\n",
      "val Loss: 0.08718930929899216 Acc: 0.974609375\n",
      "New best validation loss: 0.08718930929899216\n",
      "Epoch 2 of 500 took 0.378s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.08756438352995449 Acc: 0.9724392361111112\n",
      "val Loss: 0.08319990243762732 Acc: 0.974609375\n",
      "New best validation loss: 0.08319990243762732\n",
      "Epoch 3 of 500 took 0.370s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.08345336591204007 Acc: 0.9700520833333334\n",
      "val Loss: 0.0639610756188631 Acc: 0.98046875\n",
      "New best validation loss: 0.0639610756188631\n",
      "Epoch 4 of 500 took 0.366s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.07923193731241757 Acc: 0.9739583333333334\n",
      "val Loss: 0.06791930925101042 Acc: 0.9765625\n",
      "Epoch 5 of 500 took 0.381s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.07350041427546078 Acc: 0.9769965277777778\n",
      "val Loss: 0.06843559257686138 Acc: 0.974609375\n",
      "Epoch 6 of 500 took 0.362s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.05768984597590235 Acc: 0.9806857638888888\n",
      "val Loss: 0.08071251958608627 Acc: 0.974609375\n",
      "Epoch 7 of 500 took 0.356s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.05602262758960327 Acc: 0.9809027777777778\n",
      "val Loss: 0.060569532215595245 Acc: 0.978515625\n",
      "New best validation loss: 0.060569532215595245\n",
      "Epoch 8 of 500 took 0.366s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.05253965511090226 Acc: 0.9817708333333334\n",
      "val Loss: 0.047340163961052895 Acc: 0.984375\n",
      "New best validation loss: 0.047340163961052895\n",
      "Epoch 9 of 500 took 0.392s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.04607919758806626 Acc: 0.9850260416666666\n",
      "val Loss: 0.05825289338827133 Acc: 0.982421875\n",
      "Epoch 10 of 500 took 0.366s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.04583007309378849 Acc: 0.984375\n",
      "val Loss: 0.05547942826524377 Acc: 0.98046875\n",
      "Epoch 11 of 500 took 0.371s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.04507031964345111 Acc: 0.9839409722222222\n",
      "val Loss: 0.05527111794799566 Acc: 0.978515625\n",
      "Epoch 12 of 500 took 0.434s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.043277892801496715 Acc: 0.9854600694444444\n",
      "val Loss: 0.06703460775315762 Acc: 0.98046875\n",
      "Epoch 13 of 500 took 0.378s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.037910902613980904 Acc: 0.9865451388888888\n",
      "val Loss: 0.03727566823363304 Acc: 0.986328125\n",
      "New best validation loss: 0.03727566823363304\n",
      "Epoch 14 of 500 took 0.403s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.032932022069063455 Acc: 0.9900173611111112\n",
      "val Loss: 0.05161881726235151 Acc: 0.986328125\n",
      "Epoch 15 of 500 took 0.359s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.03608819030018316 Acc: 0.9867621527777778\n",
      "val Loss: 0.03531626611948013 Acc: 0.986328125\n",
      "New best validation loss: 0.03531626611948013\n",
      "Epoch 16 of 500 took 0.321s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.04068309684387512 Acc: 0.9856770833333334\n",
      "val Loss: 0.03731188178062439 Acc: 0.986328125\n",
      "Epoch 17 of 500 took 0.339s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.03671302987883488 Acc: 0.9876302083333334\n",
      "val Loss: 0.03735892055556178 Acc: 0.986328125\n",
      "Epoch 18 of 500 took 0.328s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.03306897931421796 Acc: 0.9898003472222222\n",
      "val Loss: 0.06100043887272477 Acc: 0.982421875\n",
      "Epoch 19 of 500 took 0.363s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.028237723279744387 Acc: 0.9900173611111112\n",
      "val Loss: 0.031845737248659134 Acc: 0.986328125\n",
      "New best validation loss: 0.031845737248659134\n",
      "Epoch 20 of 500 took 0.560s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0373826397375928 Acc: 0.9867621527777778\n",
      "val Loss: 0.04139187792316079 Acc: 0.984375\n",
      "Epoch 21 of 500 took 0.327s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.027041403628471825 Acc: 0.9911024305555556\n",
      "val Loss: 0.043426232412457466 Acc: 0.98828125\n",
      "Epoch 22 of 500 took 0.351s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.025258866293976705 Acc: 0.9915364583333334\n",
      "val Loss: 0.044567293487489223 Acc: 0.986328125\n",
      "Epoch 23 of 500 took 0.502s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.026927314284774993 Acc: 0.9906684027777778\n",
      "val Loss: 0.03252786863595247 Acc: 0.990234375\n",
      "Epoch 24 of 500 took 0.550s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.030824407159040373 Acc: 0.990234375\n",
      "val Loss: 0.054447037633508444 Acc: 0.974609375\n",
      "Epoch 25 of 500 took 0.414s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.024075738620013 Acc: 0.9913194444444444\n",
      "val Loss: 0.019702918827533722 Acc: 0.9921875\n",
      "New best validation loss: 0.019702918827533722\n",
      "Epoch 26 of 500 took 0.316s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.018580968388252787 Acc: 0.994140625\n",
      "val Loss: 0.03281910438090563 Acc: 0.990234375\n",
      "Epoch 27 of 500 took 0.349s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.02167691911260287 Acc: 0.9928385416666666\n",
      "val Loss: 0.03040455747395754 Acc: 0.98828125\n",
      "Epoch 28 of 500 took 0.292s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.021515583102073934 Acc: 0.9926215277777778\n",
      "val Loss: 0.02863513771444559 Acc: 0.990234375\n",
      "Epoch 29 of 500 took 0.378s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.027218893998199038 Acc: 0.9917534722222222\n",
      "val Loss: 0.02714914595708251 Acc: 0.990234375\n",
      "Epoch 30 of 500 took 0.377s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.02665211306884885 Acc: 0.9924045138888888\n",
      "val Loss: 0.06952312868088484 Acc: 0.978515625\n",
      "Epoch 31 of 500 took 0.378s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.02904658971561326 Acc: 0.9895833333333334\n",
      "val Loss: 0.022578016854822636 Acc: 0.990234375\n",
      "Epoch    32: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 32 of 500 took 0.373s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.02588964683107204 Acc: 0.9917534722222222\n",
      "val Loss: 0.03085558256134391 Acc: 0.990234375\n",
      "Epoch 33 of 500 took 0.388s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.020316584372065134 Acc: 0.9934895833333334\n",
      "val Loss: 0.0325026442296803 Acc: 0.98828125\n",
      "Epoch 34 of 500 took 0.387s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.02042739698663354 Acc: 0.9937065972222222\n",
      "val Loss: 0.032606656197458506 Acc: 0.990234375\n",
      "Epoch 35 of 500 took 0.401s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.017943381228380732 Acc: 0.994140625\n",
      "val Loss: 0.028282425366342068 Acc: 0.990234375\n",
      "Epoch 36 of 500 took 0.429s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.015239219905601608 Acc: 0.9945746527777778\n",
      "val Loss: 0.026160493027418852 Acc: 0.98828125\n",
      "Epoch 37 of 500 took 0.380s\n",
      "\n",
      "Training complete in 0m 14s\n",
      "Best val loss: 0.019703\n",
      "ACCURACY TEST_0 FINAL : 98.915 %\n",
      "ACCURACY TEST_1 FINAL : 98.109 %\n",
      "CURRENT DATASET :  11\n",
      "(5305, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.816408740149604 Acc: 0.7764756944444444\n",
      "val Loss: 0.19080586172640324 Acc: 0.962890625\n",
      "New best validation loss: 0.19080586172640324\n",
      "Epoch 1 of 500 took 0.407s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.2644086968567636 Acc: 0.9162326388888888\n",
      "val Loss: 0.1132761100307107 Acc: 0.96484375\n",
      "New best validation loss: 0.1132761100307107\n",
      "Epoch 2 of 500 took 0.385s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.2068051521976789 Acc: 0.9296875\n",
      "val Loss: 0.10699828527867794 Acc: 0.96484375\n",
      "New best validation loss: 0.10699828527867794\n",
      "Epoch 3 of 500 took 0.385s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.18201038986444473 Acc: 0.9392361111111112\n",
      "val Loss: 0.08050252310931683 Acc: 0.96875\n",
      "New best validation loss: 0.08050252310931683\n",
      "Epoch 4 of 500 took 0.384s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.1631914008822706 Acc: 0.9366319444444444\n",
      "val Loss: 0.09166098572313786 Acc: 0.970703125\n",
      "Epoch 5 of 500 took 0.414s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.16146757577856383 Acc: 0.9427083333333334\n",
      "val Loss: 0.07347153127193451 Acc: 0.970703125\n",
      "New best validation loss: 0.07347153127193451\n",
      "Epoch 6 of 500 took 0.385s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.13590512797236443 Acc: 0.94921875\n",
      "val Loss: 0.07298036012798548 Acc: 0.966796875\n",
      "New best validation loss: 0.07298036012798548\n",
      "Epoch 7 of 500 took 0.401s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.14816071879532602 Acc: 0.9442274305555556\n",
      "val Loss: 0.07047442812472582 Acc: 0.9765625\n",
      "New best validation loss: 0.07047442812472582\n",
      "Epoch 8 of 500 took 0.392s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.12957436425818336 Acc: 0.9507378472222222\n",
      "val Loss: 0.06590619776397943 Acc: 0.98046875\n",
      "New best validation loss: 0.06590619776397943\n",
      "Epoch 9 of 500 took 0.396s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.1348069239821699 Acc: 0.9498697916666666\n",
      "val Loss: 0.06708121951669455 Acc: 0.9765625\n",
      "Epoch 10 of 500 took 0.397s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.12270060554146767 Acc: 0.9535590277777778\n",
      "val Loss: 0.06599046755582094 Acc: 0.9765625\n",
      "Epoch 11 of 500 took 0.374s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.1194139996336566 Acc: 0.9498697916666666\n",
      "val Loss: 0.06671863701194525 Acc: 0.9765625\n",
      "Epoch 12 of 500 took 0.467s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.11089213813344638 Acc: 0.9555121527777778\n",
      "val Loss: 0.05930148623883724 Acc: 0.9765625\n",
      "New best validation loss: 0.05930148623883724\n",
      "Epoch 13 of 500 took 0.382s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.1085568242188957 Acc: 0.9576822916666666\n",
      "val Loss: 0.05723533220589161 Acc: 0.978515625\n",
      "New best validation loss: 0.05723533220589161\n",
      "Epoch 14 of 500 took 0.378s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.10342820030119684 Acc: 0.9613715277777778\n",
      "val Loss: 0.05158679746091366 Acc: 0.984375\n",
      "New best validation loss: 0.05158679746091366\n",
      "Epoch 15 of 500 took 0.385s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.09454917949106958 Acc: 0.962890625\n",
      "val Loss: 0.058559125289320946 Acc: 0.98046875\n",
      "Epoch 16 of 500 took 0.377s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.10099719671739472 Acc: 0.9598524305555556\n",
      "val Loss: 0.053705763071775436 Acc: 0.982421875\n",
      "Epoch 17 of 500 took 0.396s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.09561896241373485 Acc: 0.9611545138888888\n",
      "val Loss: 0.04790354799479246 Acc: 0.984375\n",
      "New best validation loss: 0.04790354799479246\n",
      "Epoch 18 of 500 took 0.396s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.08662578877475527 Acc: 0.96484375\n",
      "val Loss: 0.059673892334103584 Acc: 0.978515625\n",
      "Epoch 19 of 500 took 0.394s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.09278752075301276 Acc: 0.96484375\n",
      "val Loss: 0.07359989732503891 Acc: 0.966796875\n",
      "Epoch 20 of 500 took 0.589s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.09446250605914328 Acc: 0.9644097222222222\n",
      "val Loss: 0.04628578573465347 Acc: 0.982421875\n",
      "New best validation loss: 0.04628578573465347\n",
      "Epoch 21 of 500 took 0.492s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.09299985236591762 Acc: 0.962890625\n",
      "val Loss: 0.04202387202531099 Acc: 0.982421875\n",
      "New best validation loss: 0.04202387202531099\n",
      "Epoch 22 of 500 took 0.669s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.08079558693700367 Acc: 0.9680989583333334\n",
      "val Loss: 0.0533167514950037 Acc: 0.974609375\n",
      "Epoch 23 of 500 took 0.500s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.07827616131140126 Acc: 0.9689670138888888\n",
      "val Loss: 0.045599937438964844 Acc: 0.984375\n",
      "Epoch 24 of 500 took 0.405s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.07866558680931728 Acc: 0.9691840277777778\n",
      "val Loss: 0.046287829987704754 Acc: 0.982421875\n",
      "Epoch 25 of 500 took 0.390s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.06774275501569112 Acc: 0.9717881944444444\n",
      "val Loss: 0.04414201807230711 Acc: 0.984375\n",
      "Epoch 26 of 500 took 0.388s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.06298984421624078 Acc: 0.9774305555555556\n",
      "val Loss: 0.04879464302212 Acc: 0.98046875\n",
      "Epoch 27 of 500 took 0.381s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.06795831624832419 Acc: 0.9733072916666666\n",
      "val Loss: 0.05137211922556162 Acc: 0.9765625\n",
      "Epoch    28: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 28 of 500 took 0.379s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.0600046060151524 Acc: 0.9778645833333334\n",
      "val Loss: 0.0379349859431386 Acc: 0.98828125\n",
      "New best validation loss: 0.0379349859431386\n",
      "Epoch 29 of 500 took 0.387s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.06325034362574418 Acc: 0.9752604166666666\n",
      "val Loss: 0.041839309968054295 Acc: 0.98828125\n",
      "Epoch 30 of 500 took 0.342s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.06305836761991183 Acc: 0.9754774305555556\n",
      "val Loss: 0.04084046557545662 Acc: 0.990234375\n",
      "Epoch 31 of 500 took 0.313s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.058925458437038794 Acc: 0.9765625\n",
      "val Loss: 0.041397846303880215 Acc: 0.984375\n",
      "Epoch 32 of 500 took 0.297s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.05585791232685248 Acc: 0.9772135416666666\n",
      "val Loss: 0.04043209366500378 Acc: 0.990234375\n",
      "Epoch 33 of 500 took 0.311s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.05614897350056304 Acc: 0.9776475694444444\n",
      "val Loss: 0.039579929783940315 Acc: 0.984375\n",
      "Epoch 34 of 500 took 0.314s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.05761662839601437 Acc: 0.9776475694444444\n",
      "val Loss: 0.04943071771413088 Acc: 0.98046875\n",
      "Epoch    35: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 35 of 500 took 0.339s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0577022580222951 Acc: 0.9769965277777778\n",
      "val Loss: 0.044747074134647846 Acc: 0.986328125\n",
      "Epoch 36 of 500 took 0.370s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.05102541163149807 Acc: 0.9802517361111112\n",
      "val Loss: 0.04012518376111984 Acc: 0.986328125\n",
      "Epoch 37 of 500 took 0.303s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.0544767225575116 Acc: 0.9776475694444444\n",
      "val Loss: 0.03949161246418953 Acc: 0.986328125\n",
      "Epoch 38 of 500 took 0.298s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.056799899890191026 Acc: 0.9772135416666666\n",
      "val Loss: 0.038436371833086014 Acc: 0.986328125\n",
      "Epoch 39 of 500 took 0.305s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.05576698295772076 Acc: 0.9769965277777778\n",
      "val Loss: 0.04186659771949053 Acc: 0.986328125\n",
      "Epoch 40 of 500 took 0.323s\n",
      "\n",
      "Training complete in 0m 16s\n",
      "Best val loss: 0.037935\n",
      "ACCURACY TEST_0 FINAL : 94.569 %\n",
      "ACCURACY TEST_1 FINAL : 95.840 %\n",
      "CURRENT DATASET :  12\n",
      "(5309, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.4473554843829738 Acc: 0.857421875\n",
      "val Loss: 0.009829620830714703 Acc: 0.994140625\n",
      "New best validation loss: 0.009829620830714703\n",
      "Epoch 1 of 500 took 0.434s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.04278997776822911 Acc: 0.9856770833333334\n",
      "val Loss: 0.006435885094106197 Acc: 1.0\n",
      "New best validation loss: 0.006435885094106197\n",
      "Epoch 2 of 500 took 0.609s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.03284118748787376 Acc: 0.990234375\n",
      "val Loss: 0.0055071329697966576 Acc: 1.0\n",
      "New best validation loss: 0.0055071329697966576\n",
      "Epoch 3 of 500 took 0.395s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.024469879041943286 Acc: 0.9908854166666666\n",
      "val Loss: 0.003750941716134548 Acc: 1.0\n",
      "New best validation loss: 0.003750941716134548\n",
      "Epoch 4 of 500 took 0.399s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.018119109484056633 Acc: 0.9945746527777778\n",
      "val Loss: 0.004081989638507366 Acc: 1.0\n",
      "Epoch 5 of 500 took 0.396s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.017672311876797013 Acc: 0.994140625\n",
      "val Loss: 0.0018182527273893356 Acc: 1.0\n",
      "New best validation loss: 0.0018182527273893356\n",
      "Epoch 6 of 500 took 0.427s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.014350591382632652 Acc: 0.994140625\n",
      "val Loss: 0.0019448064267635345 Acc: 1.0\n",
      "Epoch 7 of 500 took 0.413s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.012898240548868975 Acc: 0.9958767361111112\n",
      "val Loss: 0.0023138681426644325 Acc: 1.0\n",
      "Epoch 8 of 500 took 0.384s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.010784687163929144 Acc: 0.9963107638888888\n",
      "val Loss: 0.0044312914833426476 Acc: 1.0\n",
      "Epoch 9 of 500 took 0.420s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.011339783771998353 Acc: 0.9965277777777778\n",
      "val Loss: 0.0021458640694618225 Acc: 1.0\n",
      "Epoch 10 of 500 took 0.380s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.009634462392164601 Acc: 0.9973958333333334\n",
      "val Loss: 0.0014301417395472527 Acc: 1.0\n",
      "New best validation loss: 0.0014301417395472527\n",
      "Epoch 11 of 500 took 0.405s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.008482662650446096 Acc: 0.9978298611111112\n",
      "val Loss: 0.0010907184332609177 Acc: 1.0\n",
      "New best validation loss: 0.0010907184332609177\n",
      "Epoch 12 of 500 took 0.388s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.006257476285099983 Acc: 0.9989149305555556\n",
      "val Loss: 0.0007529500871896744 Acc: 1.0\n",
      "New best validation loss: 0.0007529500871896744\n",
      "Epoch 13 of 500 took 0.389s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.0075083655926088495 Acc: 0.9982638888888888\n",
      "val Loss: 0.0009447941556572914 Acc: 1.0\n",
      "Epoch 14 of 500 took 0.386s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.008863858361211088 Acc: 0.998046875\n",
      "val Loss: 0.0011334186419844627 Acc: 1.0\n",
      "Epoch 15 of 500 took 0.379s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.006424721847805712 Acc: 0.9982638888888888\n",
      "val Loss: 0.00040124915540218353 Acc: 1.0\n",
      "New best validation loss: 0.00040124915540218353\n",
      "Epoch 16 of 500 took 0.411s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.008159739637954367 Acc: 0.998046875\n",
      "val Loss: 0.00035325903445482254 Acc: 1.0\n",
      "New best validation loss: 0.00035325903445482254\n",
      "Epoch 17 of 500 took 0.565s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.009583936952468421 Acc: 0.998046875\n",
      "val Loss: 0.0012115631252527237 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.420s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.005533099588420656 Acc: 0.9984809027777778\n",
      "val Loss: 0.0005086809396743774 Acc: 1.0\n",
      "Epoch 19 of 500 took 0.604s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.004727847201542722 Acc: 0.9984809027777778\n",
      "val Loss: 0.0013132402673363686 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.710s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0041679938116835225 Acc: 0.9991319444444444\n",
      "val Loss: 0.0010791728273034096 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.487s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.005386061500757933 Acc: 0.9982638888888888\n",
      "val Loss: 0.00018379557877779007 Acc: 1.0\n",
      "New best validation loss: 0.00018379557877779007\n",
      "Epoch 22 of 500 took 0.451s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.003679091524746683 Acc: 0.9993489583333334\n",
      "val Loss: 0.002608800306916237 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.381s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.004657528984049956 Acc: 0.9986979166666666\n",
      "val Loss: 0.0019043898209929466 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.383s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.0039503814963003 Acc: 0.9989149305555556\n",
      "val Loss: 0.00020656175911426544 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.380s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.004775015637278557 Acc: 0.9986979166666666\n",
      "val Loss: 0.00014575012028217316 Acc: 1.0\n",
      "New best validation loss: 0.00014575012028217316\n",
      "Epoch 26 of 500 took 0.449s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.0045427606544560855 Acc: 0.998046875\n",
      "val Loss: 8.540228009223938e-05 Acc: 1.0\n",
      "New best validation loss: 8.540228009223938e-05\n",
      "Epoch 27 of 500 took 0.393s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.005714901464266909 Acc: 0.9978298611111112\n",
      "val Loss: 9.600259363651276e-05 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.386s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.005111868700219525 Acc: 0.9986979166666666\n",
      "val Loss: 0.0002001579850912094 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.383s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0023159123957157135 Acc: 0.9995659722222222\n",
      "val Loss: 0.00019577331840991974 Acc: 1.0\n",
      "Epoch 30 of 500 took 0.384s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.005435721224380864 Acc: 0.9982638888888888\n",
      "val Loss: 0.00013432279229164124 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.415s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.005001763761457469 Acc: 0.9986979166666666\n",
      "val Loss: 0.0001284293830394745 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.403s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.003276560093379683 Acc: 0.9986979166666666\n",
      "val Loss: 0.0002851579338312149 Acc: 1.0\n",
      "Epoch    33: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 33 of 500 took 0.393s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.0035343394718236392 Acc: 0.9991319444444444\n",
      "val Loss: 0.00016165897250175476 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.399s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.003293330263760355 Acc: 0.9993489583333334\n",
      "val Loss: 0.00011359993368387222 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.388s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0020679013493160405 Acc: 0.9993489583333334\n",
      "val Loss: 0.0001668417826294899 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.384s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.002481516140202681 Acc: 0.9993489583333334\n",
      "val Loss: 0.00014711171388626099 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.389s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.003507269908570581 Acc: 0.998046875\n",
      "val Loss: 0.00012588594108819962 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.384s\n",
      "\n",
      "Training complete in 0m 16s\n",
      "Best val loss: 0.000085\n",
      "ACCURACY TEST_0 FINAL : 99.380 %\n",
      "ACCURACY TEST_1 FINAL : 99.224 %\n",
      "CURRENT DATASET :  13\n",
      "(5313, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5699084285232756 Acc: 0.8357204861111112\n",
      "val Loss: 0.08761351183056831 Acc: 0.966796875\n",
      "New best validation loss: 0.08761351183056831\n",
      "Epoch 1 of 500 took 0.275s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.11623110063374043 Acc: 0.9578993055555556\n",
      "val Loss: 0.056703558191657066 Acc: 0.974609375\n",
      "New best validation loss: 0.056703558191657066\n",
      "Epoch 2 of 500 took 0.272s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.09990049339830875 Acc: 0.9607204861111112\n",
      "val Loss: 0.05134409386664629 Acc: 0.978515625\n",
      "New best validation loss: 0.05134409386664629\n",
      "Epoch 3 of 500 took 0.288s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.08578806246320407 Acc: 0.9680989583333334\n",
      "val Loss: 0.047346875071525574 Acc: 0.98046875\n",
      "New best validation loss: 0.047346875071525574\n",
      "Epoch 4 of 500 took 0.273s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.07650553476479319 Acc: 0.9713541666666666\n",
      "val Loss: 0.050591789186000824 Acc: 0.98046875\n",
      "Epoch 5 of 500 took 0.271s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.0752934461666478 Acc: 0.9704861111111112\n",
      "val Loss: 0.05158371897414327 Acc: 0.9765625\n",
      "Epoch 6 of 500 took 0.322s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.07120062866144711 Acc: 0.974609375\n",
      "val Loss: 0.06459855940192938 Acc: 0.970703125\n",
      "Epoch 7 of 500 took 0.291s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.05789074105107122 Acc: 0.9782986111111112\n",
      "val Loss: 0.04648547060787678 Acc: 0.9765625\n",
      "New best validation loss: 0.04648547060787678\n",
      "Epoch 8 of 500 took 0.289s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.0605912312037415 Acc: 0.9776475694444444\n",
      "val Loss: 0.045871621929109097 Acc: 0.98046875\n",
      "New best validation loss: 0.045871621929109097\n",
      "Epoch 9 of 500 took 0.282s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.05959285733600458 Acc: 0.9782986111111112\n",
      "val Loss: 0.039070386439561844 Acc: 0.978515625\n",
      "New best validation loss: 0.039070386439561844\n",
      "Epoch 10 of 500 took 0.346s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.054212898222936526 Acc: 0.9798177083333334\n",
      "val Loss: 0.028551680967211723 Acc: 0.98828125\n",
      "New best validation loss: 0.028551680967211723\n",
      "Epoch 11 of 500 took 0.300s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.04170676496707731 Acc: 0.986328125\n",
      "val Loss: 0.029689280316233635 Acc: 0.986328125\n",
      "Epoch 12 of 500 took 0.273s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.044484408365355596 Acc: 0.9841579861111112\n",
      "val Loss: 0.02964689675718546 Acc: 0.986328125\n",
      "Epoch 13 of 500 took 0.276s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.04413079201347298 Acc: 0.9819878472222222\n",
      "val Loss: 0.0291752303019166 Acc: 0.984375\n",
      "Epoch 14 of 500 took 0.296s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.043461657129228115 Acc: 0.9835069444444444\n",
      "val Loss: 0.02575310878455639 Acc: 0.98828125\n",
      "New best validation loss: 0.02575310878455639\n",
      "Epoch 15 of 500 took 0.296s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.037022312792638935 Acc: 0.9856770833333334\n",
      "val Loss: 0.029541531577706337 Acc: 0.986328125\n",
      "Epoch 16 of 500 took 0.289s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.041072908168037735 Acc: 0.9832899305555556\n",
      "val Loss: 0.026898622512817383 Acc: 0.98828125\n",
      "Epoch 17 of 500 took 0.276s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.03454130743112829 Acc: 0.9871961805555556\n",
      "val Loss: 0.02607270237058401 Acc: 0.98828125\n",
      "Epoch 18 of 500 took 0.286s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.037508787483804755 Acc: 0.9858940972222222\n",
      "val Loss: 0.020382702350616455 Acc: 0.9921875\n",
      "New best validation loss: 0.020382702350616455\n",
      "Epoch 19 of 500 took 0.413s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.036187191804250084 Acc: 0.98828125\n",
      "val Loss: 0.014348658733069897 Acc: 0.994140625\n",
      "New best validation loss: 0.014348658733069897\n",
      "Epoch 20 of 500 took 0.403s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.03295582915759749 Acc: 0.9878472222222222\n",
      "val Loss: 0.011553795076906681 Acc: 0.998046875\n",
      "New best validation loss: 0.011553795076906681\n",
      "Epoch 21 of 500 took 0.373s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.0277053609283434 Acc: 0.9904513888888888\n",
      "val Loss: 0.0178906861692667 Acc: 0.994140625\n",
      "Epoch 22 of 500 took 0.651s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.030656412036882505 Acc: 0.9869791666666666\n",
      "val Loss: 0.019998510368168354 Acc: 0.990234375\n",
      "Epoch 23 of 500 took 0.456s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.028545539101792708 Acc: 0.9891493055555556\n",
      "val Loss: 0.01716447900980711 Acc: 0.994140625\n",
      "Epoch 24 of 500 took 0.326s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.027511954307556152 Acc: 0.9908854166666666\n",
      "val Loss: 0.01838522870093584 Acc: 0.994140625\n",
      "Epoch 25 of 500 took 0.279s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.03485196808146106 Acc: 0.986328125\n",
      "val Loss: 0.016333951614797115 Acc: 0.994140625\n",
      "Epoch 26 of 500 took 0.288s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.02823890031625827 Acc: 0.9887152777777778\n",
      "val Loss: 0.017008217051625252 Acc: 0.994140625\n",
      "Epoch    27: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 27 of 500 took 0.276s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.025504352887057595 Acc: 0.9917534722222222\n",
      "val Loss: 0.017167141661047935 Acc: 0.994140625\n",
      "Epoch 28 of 500 took 0.276s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.024526883382350206 Acc: 0.9904513888888888\n",
      "val Loss: 0.01695869117975235 Acc: 0.994140625\n",
      "Epoch 29 of 500 took 0.284s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.01982706728287869 Acc: 0.9934895833333334\n",
      "val Loss: 0.013180660083889961 Acc: 0.99609375\n",
      "Epoch 30 of 500 took 0.283s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.029011399019509554 Acc: 0.9893663194444444\n",
      "val Loss: 0.019156542606651783 Acc: 0.9921875\n",
      "Epoch 31 of 500 took 0.287s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.02299595468988021 Acc: 0.9915364583333334\n",
      "val Loss: 0.010139227844774723 Acc: 0.99609375\n",
      "New best validation loss: 0.010139227844774723\n",
      "Epoch 32 of 500 took 0.285s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.025946381812294323 Acc: 0.9900173611111112\n",
      "val Loss: 0.0135221341624856 Acc: 0.99609375\n",
      "Epoch 33 of 500 took 0.289s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.025202674842956994 Acc: 0.9911024305555556\n",
      "val Loss: 0.01174995768815279 Acc: 0.99609375\n",
      "Epoch 34 of 500 took 0.338s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.022282410309546523 Acc: 0.9915364583333334\n",
      "val Loss: 0.014807239174842834 Acc: 0.994140625\n",
      "Epoch 35 of 500 took 0.291s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.022032236059506733 Acc: 0.9915364583333334\n",
      "val Loss: 0.01724623516201973 Acc: 0.994140625\n",
      "Epoch 36 of 500 took 0.271s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.01953664396165146 Acc: 0.9930555555555556\n",
      "val Loss: 0.01614031381905079 Acc: 0.994140625\n",
      "Epoch 37 of 500 took 0.277s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.017558041339119274 Acc: 0.9943576388888888\n",
      "val Loss: 0.015614542178809643 Acc: 0.994140625\n",
      "Epoch    38: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 38 of 500 took 0.327s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.0175714994677239 Acc: 0.9937065972222222\n",
      "val Loss: 0.014356307685375214 Acc: 0.994140625\n",
      "Epoch 39 of 500 took 0.443s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.021458073519170284 Acc: 0.9911024305555556\n",
      "val Loss: 0.014762197621166706 Acc: 0.994140625\n",
      "Epoch 40 of 500 took 0.341s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.02406424180501037 Acc: 0.9919704861111112\n",
      "val Loss: 0.013465619646012783 Acc: 0.99609375\n",
      "Epoch 41 of 500 took 0.356s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.0198332452111774 Acc: 0.9932725694444444\n",
      "val Loss: 0.011915009468793869 Acc: 0.998046875\n",
      "Epoch 42 of 500 took 0.353s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.025379026877797313 Acc: 0.9915364583333334\n",
      "val Loss: 0.014243585988879204 Acc: 0.99609375\n",
      "Epoch 43 of 500 took 0.357s\n",
      "\n",
      "Training complete in 0m 14s\n",
      "Best val loss: 0.010139\n",
      "ACCURACY TEST_0 FINAL : 82.269 %\n",
      "ACCURACY TEST_1 FINAL : 88.175 %\n",
      "CURRENT DATASET :  14\n",
      "(5306, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.638948865648773 Acc: 0.8057725694444444\n",
      "val Loss: 0.037033605854958296 Acc: 0.98828125\n",
      "New best validation loss: 0.037033605854958296\n",
      "Epoch 1 of 500 took 0.370s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.10224143974483013 Acc: 0.96484375\n",
      "val Loss: 0.012828390579670668 Acc: 0.998046875\n",
      "New best validation loss: 0.012828390579670668\n",
      "Epoch 2 of 500 took 0.357s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.06283490028646257 Acc: 0.978515625\n",
      "val Loss: 0.019838751759380102 Acc: 0.994140625\n",
      "Epoch 3 of 500 took 0.367s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.050434433648155794 Acc: 0.9817708333333334\n",
      "val Loss: 0.008083916269242764 Acc: 1.0\n",
      "New best validation loss: 0.008083916269242764\n",
      "Epoch 4 of 500 took 0.375s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.04170477307505078 Acc: 0.9848090277777778\n",
      "val Loss: 0.006163435056805611 Acc: 1.0\n",
      "New best validation loss: 0.006163435056805611\n",
      "Epoch 5 of 500 took 0.401s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.030675176220635574 Acc: 0.9878472222222222\n",
      "val Loss: 0.010487424209713936 Acc: 0.99609375\n",
      "Epoch 6 of 500 took 0.363s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.032796521567636065 Acc: 0.9887152777777778\n",
      "val Loss: 0.005363005213439465 Acc: 1.0\n",
      "New best validation loss: 0.005363005213439465\n",
      "Epoch 7 of 500 took 0.365s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.03234387023581399 Acc: 0.9911024305555556\n",
      "val Loss: 0.007975866086781025 Acc: 0.998046875\n",
      "Epoch 8 of 500 took 0.398s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.0305679091769788 Acc: 0.9887152777777778\n",
      "val Loss: 0.00480391550809145 Acc: 0.998046875\n",
      "New best validation loss: 0.00480391550809145\n",
      "Epoch 9 of 500 took 0.362s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.02504809180067645 Acc: 0.9904513888888888\n",
      "val Loss: 0.004787209909409285 Acc: 0.998046875\n",
      "New best validation loss: 0.004787209909409285\n",
      "Epoch 10 of 500 took 0.367s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.02059107232424948 Acc: 0.9919704861111112\n",
      "val Loss: 0.004569308366626501 Acc: 1.0\n",
      "New best validation loss: 0.004569308366626501\n",
      "Epoch 11 of 500 took 0.354s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.017922789013634127 Acc: 0.994140625\n",
      "val Loss: 0.005232787225395441 Acc: 0.998046875\n",
      "Epoch 12 of 500 took 0.375s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.02097430323354072 Acc: 0.9921875\n",
      "val Loss: 0.0032555274665355682 Acc: 1.0\n",
      "New best validation loss: 0.0032555274665355682\n",
      "Epoch 13 of 500 took 0.417s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.016378514986071322 Acc: 0.9939236111111112\n",
      "val Loss: 0.003834404982626438 Acc: 1.0\n",
      "Epoch 14 of 500 took 0.371s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.014241978940036561 Acc: 0.9967447916666666\n",
      "val Loss: 0.006074398756027222 Acc: 0.998046875\n",
      "Epoch 15 of 500 took 0.370s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.018188917491998937 Acc: 0.9928385416666666\n",
      "val Loss: 0.004825983662158251 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.363s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.014385796333145764 Acc: 0.9950086805555556\n",
      "val Loss: 0.0035373070277273655 Acc: 1.0\n",
      "Epoch 17 of 500 took 0.355s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.013737653589083089 Acc: 0.9950086805555556\n",
      "val Loss: 0.003214465454220772 Acc: 1.0\n",
      "New best validation loss: 0.003214465454220772\n",
      "Epoch 18 of 500 took 0.493s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.013744142268680863 Acc: 0.9954427083333334\n",
      "val Loss: 0.0026178043335676193 Acc: 1.0\n",
      "New best validation loss: 0.0026178043335676193\n",
      "Epoch 19 of 500 took 0.381s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.017731283687882952 Acc: 0.9932725694444444\n",
      "val Loss: 0.004815195221453905 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.563s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.010203616667745842 Acc: 0.9969618055555556\n",
      "val Loss: 0.002016334794461727 Acc: 1.0\n",
      "New best validation loss: 0.002016334794461727\n",
      "Epoch 21 of 500 took 0.551s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00772916070289082 Acc: 0.9976128472222222\n",
      "val Loss: 0.002668466418981552 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.310s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.012245284600390328 Acc: 0.9952256944444444\n",
      "val Loss: 0.0018953774124383926 Acc: 1.0\n",
      "New best validation loss: 0.0018953774124383926\n",
      "Epoch 23 of 500 took 0.328s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.009691280157615742 Acc: 0.9965277777777778\n",
      "val Loss: 0.0040422766469419 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.325s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.011583528170982996 Acc: 0.9958767361111112\n",
      "val Loss: 0.0013251779600977898 Acc: 1.0\n",
      "New best validation loss: 0.0013251779600977898\n",
      "Epoch 25 of 500 took 0.310s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.007460463792085648 Acc: 0.998046875\n",
      "val Loss: 0.0019310591742396355 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.326s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.010847903477648893 Acc: 0.9965277777777778\n",
      "val Loss: 0.0012102443724870682 Acc: 1.0\n",
      "New best validation loss: 0.0012102443724870682\n",
      "Epoch 27 of 500 took 0.322s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.009619134271310436 Acc: 0.9969618055555556\n",
      "val Loss: 0.0021925223991274834 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.324s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.010503206298583083 Acc: 0.9963107638888888\n",
      "val Loss: 0.00320351030677557 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.343s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.006860711767027776 Acc: 0.998046875\n",
      "val Loss: 0.0012526577338576317 Acc: 1.0\n",
      "Epoch 30 of 500 took 0.321s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.011319769003118077 Acc: 0.9963107638888888\n",
      "val Loss: 0.0009689964354038239 Acc: 1.0\n",
      "New best validation loss: 0.0009689964354038239\n",
      "Epoch 31 of 500 took 0.327s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.010118968681328826 Acc: 0.9969618055555556\n",
      "val Loss: 0.0008351374417543411 Acc: 1.0\n",
      "New best validation loss: 0.0008351374417543411\n",
      "Epoch 32 of 500 took 0.345s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.008507854848479232 Acc: 0.9969618055555556\n",
      "val Loss: 0.004139445722103119 Acc: 0.998046875\n",
      "Epoch 33 of 500 took 0.346s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.008183055609050725 Acc: 0.9969618055555556\n",
      "val Loss: 0.001865551806986332 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.349s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.008170021335697837 Acc: 0.9976128472222222\n",
      "val Loss: 0.001070191152393818 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.379s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0071358455655475455 Acc: 0.9978298611111112\n",
      "val Loss: 0.00089230015873909 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.420s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.006838043841222922 Acc: 0.9978298611111112\n",
      "val Loss: 0.0012771273031830788 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.355s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.006487119218541516 Acc: 0.9984809027777778\n",
      "val Loss: 0.0007485160604119301 Acc: 1.0\n",
      "New best validation loss: 0.0007485160604119301\n",
      "Epoch 38 of 500 took 0.362s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00664681118602554 Acc: 0.998046875\n",
      "val Loss: 0.001199822872877121 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.356s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.005479813449912601 Acc: 0.9976128472222222\n",
      "val Loss: 0.001517103984951973 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.362s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.004671764249602954 Acc: 0.998046875\n",
      "val Loss: 0.00167123693972826 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.349s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.004100490568412675 Acc: 0.9986979166666666\n",
      "val Loss: 0.001241263933479786 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.374s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.006289896555244923 Acc: 0.9976128472222222\n",
      "val Loss: 0.0011127078905701637 Acc: 1.0\n",
      "Epoch 43 of 500 took 0.366s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00487948012434774 Acc: 0.9986979166666666\n",
      "val Loss: 0.0006484799087047577 Acc: 1.0\n",
      "New best validation loss: 0.0006484799087047577\n",
      "Epoch 44 of 500 took 0.362s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.005767404205269284 Acc: 0.9984809027777778\n",
      "val Loss: 0.0016612755134701729 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.356s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0038287478706075084 Acc: 0.9991319444444444\n",
      "val Loss: 0.0018254760652780533 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.368s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.006678161858063605 Acc: 0.9973958333333334\n",
      "val Loss: 0.002825832925736904 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.360s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.004393637387288941 Acc: 0.9986979166666666\n",
      "val Loss: 0.0005732281133532524 Acc: 1.0\n",
      "New best validation loss: 0.0005732281133532524\n",
      "Epoch 48 of 500 took 0.380s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.005460719422747691 Acc: 0.9984809027777778\n",
      "val Loss: 0.001062997616827488 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.458s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.0039130812510848045 Acc: 0.9986979166666666\n",
      "val Loss: 0.002781528979539871 Acc: 0.998046875\n",
      "Epoch 50 of 500 took 0.424s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.004578564212554031 Acc: 0.9986979166666666\n",
      "val Loss: 0.0007572462782263756 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.374s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0040740690504511195 Acc: 0.9989149305555556\n",
      "val Loss: 0.0018317783251404762 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.369s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0035932747543685967 Acc: 0.9984809027777778\n",
      "val Loss: 0.0005130069330334663 Acc: 1.0\n",
      "New best validation loss: 0.0005130069330334663\n",
      "Epoch 53 of 500 took 0.381s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.005451789798421992 Acc: 0.998046875\n",
      "val Loss: 0.001672595739364624 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.395s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.0046029661575125325 Acc: 0.9989149305555556\n",
      "val Loss: 0.00042392127215862274 Acc: 1.0\n",
      "New best validation loss: 0.00042392127215862274\n",
      "Epoch 55 of 500 took 0.387s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.005193029582086537 Acc: 0.998046875\n",
      "val Loss: 0.0007528802379965782 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.379s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.006318165299793084 Acc: 0.998046875\n",
      "val Loss: 0.00035943277180194855 Acc: 1.0\n",
      "New best validation loss: 0.00035943277180194855\n",
      "Epoch 57 of 500 took 0.401s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.0042406716383993626 Acc: 0.9986979166666666\n",
      "val Loss: 0.00043405313044786453 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.575s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.005767021897352404 Acc: 0.9976128472222222\n",
      "val Loss: 0.0006767828017473221 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.408s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0029351055725581115 Acc: 0.9993489583333334\n",
      "val Loss: 0.00025181379169225693 Acc: 1.0\n",
      "New best validation loss: 0.00025181379169225693\n",
      "Epoch 60 of 500 took 0.629s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.004508055720685257 Acc: 0.9989149305555556\n",
      "val Loss: 0.0004773717373609543 Acc: 1.0\n",
      "Epoch 61 of 500 took 0.634s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.002447965658373303 Acc: 0.9991319444444444\n",
      "val Loss: 0.00033005978912115097 Acc: 1.0\n",
      "Epoch 62 of 500 took 0.479s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.0016526829244361983 Acc: 0.9995659722222222\n",
      "val Loss: 0.0003963243216276169 Acc: 1.0\n",
      "Epoch 63 of 500 took 0.408s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.002770626244859563 Acc: 0.9991319444444444\n",
      "val Loss: 0.0006669377908110619 Acc: 1.0\n",
      "Epoch 64 of 500 took 0.388s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0034585462676154245 Acc: 0.9986979166666666\n",
      "val Loss: 0.0005398159846663475 Acc: 1.0\n",
      "Epoch 65 of 500 took 0.394s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.0031847370684974724 Acc: 0.9986979166666666\n",
      "val Loss: 0.0008513396605849266 Acc: 1.0\n",
      "Epoch    66: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 66 of 500 took 0.383s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.003576102304375834 Acc: 0.9986979166666666\n",
      "val Loss: 0.0010401709005236626 Acc: 1.0\n",
      "Epoch 67 of 500 took 0.376s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.0027486771966020265 Acc: 0.9986979166666666\n",
      "val Loss: 0.000821269117295742 Acc: 1.0\n",
      "Epoch 68 of 500 took 0.381s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0030775999443398584 Acc: 0.9984809027777778\n",
      "val Loss: 0.000561470165848732 Acc: 1.0\n",
      "Epoch 69 of 500 took 0.380s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.002424755444129308 Acc: 0.9995659722222222\n",
      "val Loss: 0.000537605956196785 Acc: 1.0\n",
      "Epoch 70 of 500 took 0.366s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.002771468833088875 Acc: 0.9989149305555556\n",
      "val Loss: 0.00043652020394802094 Acc: 1.0\n",
      "Epoch 71 of 500 took 0.381s\n",
      "\n",
      "Training complete in 0m 27s\n",
      "Best val loss: 0.000252\n",
      "ACCURACY TEST_0 FINAL : 98.790 %\n",
      "ACCURACY TEST_1 FINAL : 99.845 %\n",
      "CURRENT DATASET :  15\n",
      "(5309, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.6604012673099836 Acc: 0.7810329861111112\n",
      "val Loss: 0.08695568889379501 Acc: 0.974609375\n",
      "New best validation loss: 0.08695568889379501\n",
      "Epoch 1 of 500 took 0.384s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.17561826979120573 Acc: 0.9296875\n",
      "val Loss: 0.0920461555942893 Acc: 0.953125\n",
      "Epoch 2 of 500 took 0.283s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.11814938982327779 Acc: 0.9535590277777778\n",
      "val Loss: 0.03934463020414114 Acc: 0.990234375\n",
      "New best validation loss: 0.03934463020414114\n",
      "Epoch 3 of 500 took 0.293s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.09435194585886267 Acc: 0.9637586805555556\n",
      "val Loss: 0.030354732647538185 Acc: 0.99609375\n",
      "New best validation loss: 0.030354732647538185\n",
      "Epoch 4 of 500 took 0.296s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.08913084947400624 Acc: 0.9652777777777778\n",
      "val Loss: 0.02604141365736723 Acc: 0.994140625\n",
      "New best validation loss: 0.02604141365736723\n",
      "Epoch 5 of 500 took 0.290s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.07478409426079856 Acc: 0.97265625\n",
      "val Loss: 0.027076391503214836 Acc: 0.990234375\n",
      "Epoch 6 of 500 took 0.294s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.07618434333966838 Acc: 0.9678819444444444\n",
      "val Loss: 0.02124653197824955 Acc: 0.9921875\n",
      "New best validation loss: 0.02124653197824955\n",
      "Epoch 7 of 500 took 0.297s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.064209652133286 Acc: 0.9737413194444444\n",
      "val Loss: 0.014796324074268341 Acc: 0.998046875\n",
      "New best validation loss: 0.014796324074268341\n",
      "Epoch 8 of 500 took 0.368s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.059823679013384715 Acc: 0.9767795138888888\n",
      "val Loss: 0.015161040239036083 Acc: 0.99609375\n",
      "Epoch 9 of 500 took 0.355s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.06254762659470241 Acc: 0.9769965277777778\n",
      "val Loss: 0.013247341848909855 Acc: 0.998046875\n",
      "New best validation loss: 0.013247341848909855\n",
      "Epoch 10 of 500 took 0.358s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.05056833972533544 Acc: 0.9837239583333334\n",
      "val Loss: 0.013408311642706394 Acc: 0.998046875\n",
      "Epoch 11 of 500 took 0.437s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.04638079429666201 Acc: 0.9832899305555556\n",
      "val Loss: 0.009699148125946522 Acc: 1.0\n",
      "New best validation loss: 0.009699148125946522\n",
      "Epoch 12 of 500 took 0.353s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.042926508829825454 Acc: 0.982421875\n",
      "val Loss: 0.008303561247885227 Acc: 1.0\n",
      "New best validation loss: 0.008303561247885227\n",
      "Epoch 13 of 500 took 0.356s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.04560581098000208 Acc: 0.9828559027777778\n",
      "val Loss: 0.009680401533842087 Acc: 0.99609375\n",
      "Epoch 14 of 500 took 0.304s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.04208076196826167 Acc: 0.9830729166666666\n",
      "val Loss: 0.016005895100533962 Acc: 0.990234375\n",
      "Epoch 15 of 500 took 0.299s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.03977819987469249 Acc: 0.9850260416666666\n",
      "val Loss: 0.012373785488307476 Acc: 0.994140625\n",
      "Epoch 16 of 500 took 0.304s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.035624969026280776 Acc: 0.9854600694444444\n",
      "val Loss: 0.01999327354133129 Acc: 0.990234375\n",
      "Epoch 17 of 500 took 0.333s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.03509825519803497 Acc: 0.9874131944444444\n",
      "val Loss: 0.012201866135001183 Acc: 0.9921875\n",
      "Epoch 18 of 500 took 0.292s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.030377925373613834 Acc: 0.9893663194444444\n",
      "val Loss: 0.006083804182708263 Acc: 1.0\n",
      "New best validation loss: 0.006083804182708263\n",
      "Epoch 19 of 500 took 0.308s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.03001397310031785 Acc: 0.9898003472222222\n",
      "val Loss: 0.005730127915740013 Acc: 1.0\n",
      "New best validation loss: 0.005730127915740013\n",
      "Epoch 20 of 500 took 0.304s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.026953138928446505 Acc: 0.9895833333333334\n",
      "val Loss: 0.011449133977293968 Acc: 0.994140625\n",
      "Epoch 21 of 500 took 0.306s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.030177406190584104 Acc: 0.9880642361111112\n",
      "val Loss: 0.005906620062887669 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.317s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.02978670648816559 Acc: 0.9871961805555556\n",
      "val Loss: 0.004353556782007217 Acc: 1.0\n",
      "New best validation loss: 0.004353556782007217\n",
      "Epoch 23 of 500 took 0.385s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.030113811139017344 Acc: 0.9898003472222222\n",
      "val Loss: 0.02210601046681404 Acc: 0.9921875\n",
      "Epoch 24 of 500 took 0.472s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.027721083774748776 Acc: 0.9915364583333334\n",
      "val Loss: 0.005124080926179886 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.479s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.027625461833344564 Acc: 0.9898003472222222\n",
      "val Loss: 0.010208453983068466 Acc: 0.994140625\n",
      "Epoch 26 of 500 took 0.619s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.025778665259066556 Acc: 0.9904513888888888\n",
      "val Loss: 0.003668263554573059 Acc: 1.0\n",
      "New best validation loss: 0.003668263554573059\n",
      "Epoch 27 of 500 took 0.422s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.026088776894741587 Acc: 0.9911024305555556\n",
      "val Loss: 0.0030215363949537277 Acc: 1.0\n",
      "New best validation loss: 0.0030215363949537277\n",
      "Epoch 28 of 500 took 0.433s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.02255388695953621 Acc: 0.9921875\n",
      "val Loss: 0.003225516527891159 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.694s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.02166962928863035 Acc: 0.9921875\n",
      "val Loss: 0.003019619733095169 Acc: 1.0\n",
      "New best validation loss: 0.003019619733095169\n",
      "Epoch 30 of 500 took 0.668s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.024840146406657167 Acc: 0.9915364583333334\n",
      "val Loss: 0.005053938366472721 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.529s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.021970854709959693 Acc: 0.9934895833333334\n",
      "val Loss: 0.0025116754695773125 Acc: 1.0\n",
      "New best validation loss: 0.0025116754695773125\n",
      "Epoch 32 of 500 took 0.384s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.024215206400387816 Acc: 0.9904513888888888\n",
      "val Loss: 0.0048756711184978485 Acc: 0.99609375\n",
      "Epoch 33 of 500 took 0.378s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.016811414776990812 Acc: 0.9937065972222222\n",
      "val Loss: 0.0024189986288547516 Acc: 1.0\n",
      "New best validation loss: 0.0024189986288547516\n",
      "Epoch 34 of 500 took 0.434s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.02124966893138157 Acc: 0.9917534722222222\n",
      "val Loss: 0.014695383608341217 Acc: 0.9921875\n",
      "Epoch 35 of 500 took 0.382s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.029572209653755028 Acc: 0.990234375\n",
      "val Loss: 0.0036477483808994293 Acc: 0.998046875\n",
      "Epoch 36 of 500 took 0.385s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.0266523210124837 Acc: 0.9906684027777778\n",
      "val Loss: 0.0030660703778266907 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.369s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.022235178699096043 Acc: 0.9913194444444444\n",
      "val Loss: 0.0024827467277646065 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.380s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.015794084562609594 Acc: 0.9943576388888888\n",
      "val Loss: 0.002977401949465275 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.376s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.016295177551607292 Acc: 0.9939236111111112\n",
      "val Loss: 0.0066947415471076965 Acc: 0.99609375\n",
      "Epoch    40: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 40 of 500 took 0.371s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.012349581449396081 Acc: 0.9947916666666666\n",
      "val Loss: 0.004570726305246353 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.390s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.015085965446713898 Acc: 0.9943576388888888\n",
      "val Loss: 0.003085292875766754 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.381s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.01632763719600108 Acc: 0.9932725694444444\n",
      "val Loss: 0.004142558202147484 Acc: 1.0\n",
      "Epoch 43 of 500 took 0.368s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.017326407703674503 Acc: 0.9939236111111112\n",
      "val Loss: 0.002879609353840351 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.384s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.014964397479262617 Acc: 0.9945746527777778\n",
      "val Loss: 0.002480347640812397 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.371s\n",
      "\n",
      "Training complete in 0m 17s\n",
      "Best val loss: 0.002419\n",
      "ACCURACY TEST_0 FINAL : 90.997 %\n",
      "ACCURACY TEST_1 FINAL : 93.913 %\n",
      "CURRENT DATASET :  16\n",
      "(5312, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.6930473041203287 Acc: 0.7641059027777778\n",
      "val Loss: 0.07079634256660938 Acc: 0.98046875\n",
      "New best validation loss: 0.07079634256660938\n",
      "Epoch 1 of 500 took 0.386s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.1594103616144922 Acc: 0.9401041666666666\n",
      "val Loss: 0.03850978799164295 Acc: 0.986328125\n",
      "New best validation loss: 0.03850978799164295\n",
      "Epoch 2 of 500 took 0.384s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.11387643300824696 Acc: 0.9594184027777778\n",
      "val Loss: 0.03205144219100475 Acc: 0.98828125\n",
      "New best validation loss: 0.03205144219100475\n",
      "Epoch 3 of 500 took 0.393s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.090022973716259 Acc: 0.9641927083333334\n",
      "val Loss: 0.02252014260739088 Acc: 0.994140625\n",
      "New best validation loss: 0.02252014260739088\n",
      "Epoch 4 of 500 took 0.380s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.07345027497245206 Acc: 0.9733072916666666\n",
      "val Loss: 0.023340945597738028 Acc: 0.9921875\n",
      "Epoch 5 of 500 took 0.371s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.06347646771205796 Acc: 0.9769965277777778\n",
      "val Loss: 0.020907630678266287 Acc: 0.99609375\n",
      "New best validation loss: 0.020907630678266287\n",
      "Epoch 6 of 500 took 0.347s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.07285013753506872 Acc: 0.9717881944444444\n",
      "val Loss: 0.018114879727363586 Acc: 0.99609375\n",
      "New best validation loss: 0.018114879727363586\n",
      "Epoch 7 of 500 took 0.371s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.06342825935118729 Acc: 0.9756944444444444\n",
      "val Loss: 0.01780099980533123 Acc: 0.99609375\n",
      "New best validation loss: 0.01780099980533123\n",
      "Epoch 8 of 500 took 0.382s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.057191443319121994 Acc: 0.9778645833333334\n",
      "val Loss: 0.016313609201461077 Acc: 0.998046875\n",
      "New best validation loss: 0.016313609201461077\n",
      "Epoch 9 of 500 took 0.425s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.048931958774725594 Acc: 0.9817708333333334\n",
      "val Loss: 0.014141736552119255 Acc: 0.99609375\n",
      "New best validation loss: 0.014141736552119255\n",
      "Epoch 10 of 500 took 0.402s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.04859723740567764 Acc: 0.9819878472222222\n",
      "val Loss: 0.013086161576211452 Acc: 0.99609375\n",
      "New best validation loss: 0.013086161576211452\n",
      "Epoch 11 of 500 took 0.389s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.042463792798419796 Acc: 0.9837239583333334\n",
      "val Loss: 0.011845000088214874 Acc: 0.998046875\n",
      "New best validation loss: 0.011845000088214874\n",
      "Epoch 12 of 500 took 0.281s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.03978044353425503 Acc: 0.9856770833333334\n",
      "val Loss: 0.006199786439538002 Acc: 0.998046875\n",
      "New best validation loss: 0.006199786439538002\n",
      "Epoch 13 of 500 took 0.296s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.031438058242201805 Acc: 0.9871961805555556\n",
      "val Loss: 0.011084933765232563 Acc: 0.998046875\n",
      "Epoch 14 of 500 took 0.283s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.029674295749929216 Acc: 0.9887152777777778\n",
      "val Loss: 0.00990923773497343 Acc: 0.998046875\n",
      "Epoch 15 of 500 took 0.337s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.027982444916334417 Acc: 0.9891493055555556\n",
      "val Loss: 0.008774654008448124 Acc: 0.998046875\n",
      "Epoch 16 of 500 took 0.371s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.03202990344208148 Acc: 0.9880642361111112\n",
      "val Loss: 0.009228275157511234 Acc: 0.998046875\n",
      "Epoch 17 of 500 took 0.363s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.02463970235031512 Acc: 0.9904513888888888\n",
      "val Loss: 0.008280367590487003 Acc: 0.99609375\n",
      "Epoch 18 of 500 took 0.511s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.029066085815429688 Acc: 0.9887152777777778\n",
      "val Loss: 0.010742918588221073 Acc: 0.998046875\n",
      "Epoch    19: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 19 of 500 took 0.347s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.022644370846036408 Acc: 0.9932725694444444\n",
      "val Loss: 0.007961221039295197 Acc: 0.99609375\n",
      "Epoch 20 of 500 took 0.292s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.020238311909553077 Acc: 0.9926215277777778\n",
      "val Loss: 0.007766564376652241 Acc: 0.998046875\n",
      "Epoch 21 of 500 took 0.516s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.025453890311635204 Acc: 0.9926215277777778\n",
      "val Loss: 0.008457211777567863 Acc: 0.998046875\n",
      "Epoch 22 of 500 took 0.543s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.02091027268519004 Acc: 0.9926215277777778\n",
      "val Loss: 0.007783087901771069 Acc: 0.998046875\n",
      "Epoch 23 of 500 took 0.449s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.020288088514159124 Acc: 0.9930555555555556\n",
      "val Loss: 0.0075694965198636055 Acc: 0.998046875\n",
      "Epoch 24 of 500 took 0.310s\n",
      "\n",
      "Training complete in 0m 9s\n",
      "Best val loss: 0.006200\n",
      "ACCURACY TEST_0 FINAL : 96.122 %\n",
      "ACCURACY TEST_1 FINAL : 99.349 %\n",
      "AVERAGE ACCURACY TEST 0 96.979\n",
      "AVERAGE ACCURACY TEST 1 97.691\n",
      "TEST 0 SO FAR:  [[99.41066997518611, 99.69021065675341, 92.44348095385568, 100.0, 99.81383803909401, 98.72789326714242, 99.34903905765654, 99.96901146575767, 99.93800371977682, 98.26356589147287, 98.91540130151844, 94.56859093730603, 99.37984496124031, 82.26906385616863, 98.78957169459963, 90.99658491151816, 96.12162581445858]]\n",
      "TEST 1 SO FAR:  [[100.0, 99.25488978578082, 96.3975155279503, 99.9689633767846, 100.0, 91.692498450093, 100.0, 100.0, 99.9689633767846, 99.00836690424543, 98.10852713178295, 95.83980130394288, 99.22432516289172, 88.17504655493482, 99.84500929944204, 93.91304347826087, 99.34903905765654]]\n",
      "CURRENT AVERAGE :  97.33507017394282\n",
      "CURRENT DATASET :  0\n",
      "(5309, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5061133280396461 Acc: 0.8448350694444444\n",
      "val Loss: 0.037275790236890316 Acc: 0.9921875\n",
      "New best validation loss: 0.037275790236890316\n",
      "Epoch 1 of 500 took 0.376s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.07627329799450105 Acc: 0.9709201388888888\n",
      "val Loss: 0.031323411501944065 Acc: 0.98828125\n",
      "New best validation loss: 0.031323411501944065\n",
      "Epoch 2 of 500 took 0.365s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.048947307798597545 Acc: 0.9852430555555556\n",
      "val Loss: 0.013725949916988611 Acc: 0.99609375\n",
      "New best validation loss: 0.013725949916988611\n",
      "Epoch 3 of 500 took 0.368s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.03569022716126508 Acc: 0.9874131944444444\n",
      "val Loss: 0.013636202085763216 Acc: 0.99609375\n",
      "New best validation loss: 0.013636202085763216\n",
      "Epoch 4 of 500 took 0.369s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.028746766969561577 Acc: 0.9911024305555556\n",
      "val Loss: 0.005845061037689447 Acc: 0.998046875\n",
      "New best validation loss: 0.005845061037689447\n",
      "Epoch 5 of 500 took 0.384s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.02392365090135071 Acc: 0.9915364583333334\n",
      "val Loss: 0.0049948617815971375 Acc: 0.998046875\n",
      "New best validation loss: 0.0049948617815971375\n",
      "Epoch 6 of 500 took 0.367s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.02445127706353863 Acc: 0.9924045138888888\n",
      "val Loss: 0.0036364365369081497 Acc: 1.0\n",
      "New best validation loss: 0.0036364365369081497\n",
      "Epoch 7 of 500 took 0.374s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.0219308756188386 Acc: 0.9917534722222222\n",
      "val Loss: 0.0013924399390816689 Acc: 1.0\n",
      "New best validation loss: 0.0013924399390816689\n",
      "Epoch 8 of 500 took 0.439s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.017775887830389872 Acc: 0.9932725694444444\n",
      "val Loss: 0.0026012882590293884 Acc: 1.0\n",
      "Epoch 9 of 500 took 0.379s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.013629934750497341 Acc: 0.9956597222222222\n",
      "val Loss: 0.0015121214091777802 Acc: 1.0\n",
      "Epoch 10 of 500 took 0.436s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.011762872959176699 Acc: 0.99609375\n",
      "val Loss: 0.0009423661977052689 Acc: 1.0\n",
      "New best validation loss: 0.0009423661977052689\n",
      "Epoch 11 of 500 took 0.288s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.012316082449009022 Acc: 0.9947916666666666\n",
      "val Loss: 0.0013901153579354286 Acc: 1.0\n",
      "Epoch 12 of 500 took 0.284s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.009657424305462174 Acc: 0.9973958333333334\n",
      "val Loss: 0.0007664822041988373 Acc: 1.0\n",
      "New best validation loss: 0.0007664822041988373\n",
      "Epoch 13 of 500 took 0.286s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.010681391538431248 Acc: 0.99609375\n",
      "val Loss: 0.0005410891026258469 Acc: 1.0\n",
      "New best validation loss: 0.0005410891026258469\n",
      "Epoch 14 of 500 took 0.287s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.01056736521422863 Acc: 0.9967447916666666\n",
      "val Loss: 0.0011811330914497375 Acc: 1.0\n",
      "Epoch 15 of 500 took 0.281s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.011392435990273952 Acc: 0.9963107638888888\n",
      "val Loss: 0.0007463609799742699 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.288s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.008322459749049611 Acc: 0.9976128472222222\n",
      "val Loss: 0.00031991396099328995 Acc: 1.0\n",
      "New best validation loss: 0.00031991396099328995\n",
      "Epoch 17 of 500 took 0.284s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.010580123143477572 Acc: 0.9958767361111112\n",
      "val Loss: 0.00036911480128765106 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.286s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.006321175334354241 Acc: 0.9982638888888888\n",
      "val Loss: 0.00036898721009492874 Acc: 1.0\n",
      "Epoch 19 of 500 took 0.318s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.009971046302881505 Acc: 0.9971788194444444\n",
      "val Loss: 0.0004000850021839142 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.297s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.006171892397105694 Acc: 0.9978298611111112\n",
      "val Loss: 0.00038482435047626495 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.302s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.006999885766870446 Acc: 0.9982638888888888\n",
      "val Loss: 0.00089276023209095 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.307s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00878322036522958 Acc: 0.9958767361111112\n",
      "val Loss: 0.00027315132319927216 Acc: 1.0\n",
      "New best validation loss: 0.00027315132319927216\n",
      "Epoch 23 of 500 took 0.301s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00407400954928663 Acc: 0.9986979166666666\n",
      "val Loss: 0.0003873063251376152 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.303s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.0031762851091722646 Acc: 0.9989149305555556\n",
      "val Loss: 0.00018654577434062958 Acc: 1.0\n",
      "New best validation loss: 0.00018654577434062958\n",
      "Epoch 25 of 500 took 0.309s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.004812921707828839 Acc: 0.9986979166666666\n",
      "val Loss: 0.00017382018268108368 Acc: 1.0\n",
      "New best validation loss: 0.00017382018268108368\n",
      "Epoch 26 of 500 took 0.323s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.004020330289171802 Acc: 0.9989149305555556\n",
      "val Loss: 0.0007262770086526871 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.357s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.0036959496533705127 Acc: 0.9991319444444444\n",
      "val Loss: 9.392481297254562e-05 Acc: 1.0\n",
      "New best validation loss: 9.392481297254562e-05\n",
      "Epoch 28 of 500 took 0.294s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.0029096013038522666 Acc: 0.9991319444444444\n",
      "val Loss: 0.00010086130350828171 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.348s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0030774985853996542 Acc: 0.9993489583333334\n",
      "val Loss: 8.079688996076584e-05 Acc: 1.0\n",
      "New best validation loss: 8.079688996076584e-05\n",
      "Epoch 30 of 500 took 0.392s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.002609398112528854 Acc: 0.9986979166666666\n",
      "val Loss: 0.00010327808558940887 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.380s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.005148074020528131 Acc: 0.9986979166666666\n",
      "val Loss: 0.00023014657199382782 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.441s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.005269040870997641 Acc: 0.9986979166666666\n",
      "val Loss: 0.00013978499919176102 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.375s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00287284500276049 Acc: 0.9993489583333334\n",
      "val Loss: 0.00010193046182394028 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.366s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.0032543007077442277 Acc: 0.9989149305555556\n",
      "val Loss: 9.347870945930481e-05 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.437s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.003372375439438555 Acc: 0.9989149305555556\n",
      "val Loss: 8.190609514713287e-05 Acc: 1.0\n",
      "Epoch    36: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 36 of 500 took 0.469s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.003278380259871483 Acc: 0.9986979166666666\n",
      "val Loss: 7.170438766479492e-05 Acc: 1.0\n",
      "New best validation loss: 7.170438766479492e-05\n",
      "Epoch 37 of 500 took 0.496s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.0024902387004759577 Acc: 0.9995659722222222\n",
      "val Loss: 7.747020572423935e-05 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.797s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.002300163006616963 Acc: 0.9991319444444444\n",
      "val Loss: 8.710287511348724e-05 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.533s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.002122853882610798 Acc: 0.9995659722222222\n",
      "val Loss: 7.942132651805878e-05 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.385s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.002501208361031281 Acc: 0.9993489583333334\n",
      "val Loss: 8.707307279109955e-05 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.389s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.003956508874479268 Acc: 0.9989149305555556\n",
      "val Loss: 8.160807192325592e-05 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.376s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.001254985471152597 Acc: 1.0\n",
      "val Loss: 8.033681660890579e-05 Acc: 1.0\n",
      "Epoch    43: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 43 of 500 took 0.370s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0020892653200361463 Acc: 0.9991319444444444\n",
      "val Loss: 6.48321583867073e-05 Acc: 1.0\n",
      "New best validation loss: 6.48321583867073e-05\n",
      "Epoch 44 of 500 took 0.365s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.0027329218573868275 Acc: 0.9984809027777778\n",
      "val Loss: 7.415935397148132e-05 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.365s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0022257406574984393 Acc: 0.9989149305555556\n",
      "val Loss: 7.175374776124954e-05 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.366s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.002026153521405326 Acc: 0.9991319444444444\n",
      "val Loss: 5.614664405584335e-05 Acc: 1.0\n",
      "New best validation loss: 5.614664405584335e-05\n",
      "Epoch 47 of 500 took 0.368s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.002113737165927887 Acc: 0.9993489583333334\n",
      "val Loss: 8.177384734153748e-05 Acc: 1.0\n",
      "Epoch 48 of 500 took 0.367s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.0030274158861074182 Acc: 0.9991319444444444\n",
      "val Loss: 7.414817810058594e-05 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.369s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.0024354619801872307 Acc: 0.9993489583333334\n",
      "val Loss: 6.803497672080994e-05 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.380s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.0012123885874946911 Acc: 0.9997829861111112\n",
      "val Loss: 7.81528651714325e-05 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.363s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.001836093556549814 Acc: 0.9993489583333334\n",
      "val Loss: 5.838833749294281e-05 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.387s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0024439735441572135 Acc: 0.9989149305555556\n",
      "val Loss: 6.4055435359478e-05 Acc: 1.0\n",
      "Epoch    53: reducing learning rate of group 0 to 1.8686e-05.\n",
      "Epoch 53 of 500 took 0.355s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0019024147962530453 Acc: 0.9993489583333334\n",
      "val Loss: 6.389524787664413e-05 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.340s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.0017068632878363132 Acc: 0.9995659722222222\n",
      "val Loss: 6.0298480093479156e-05 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.300s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.001842544207142459 Acc: 0.9993489583333334\n",
      "val Loss: 6.926804780960083e-05 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.401s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0009764538456996282 Acc: 0.9997829861111112\n",
      "val Loss: 4.419870674610138e-05 Acc: 1.0\n",
      "New best validation loss: 4.419870674610138e-05\n",
      "Epoch 57 of 500 took 0.365s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.0020854618503815597 Acc: 0.9993489583333334\n",
      "val Loss: 6.416905671358109e-05 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.356s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0017232844709522193 Acc: 0.9993489583333334\n",
      "val Loss: 6.913300603628159e-05 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.380s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0021992229028708404 Acc: 0.9997829861111112\n",
      "val Loss: 6.749853491783142e-05 Acc: 1.0\n",
      "Epoch 60 of 500 took 0.352s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.0018494448934992154 Acc: 0.9995659722222222\n",
      "val Loss: 7.623620331287384e-05 Acc: 1.0\n",
      "Epoch 61 of 500 took 0.376s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.001924860601623853 Acc: 0.9993489583333334\n",
      "val Loss: 4.1231513023376465e-05 Acc: 1.0\n",
      "New best validation loss: 4.1231513023376465e-05\n",
      "Epoch 62 of 500 took 0.367s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.002062869051264392 Acc: 0.9991319444444444\n",
      "val Loss: 6.546173244714737e-05 Acc: 1.0\n",
      "Epoch 63 of 500 took 0.379s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.0012661279696557256 Acc: 0.9997829861111112\n",
      "val Loss: 7.516425102949142e-05 Acc: 1.0\n",
      "Epoch 64 of 500 took 0.370s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0022547117227481473 Acc: 0.9995659722222222\n",
      "val Loss: 5.7054683566093445e-05 Acc: 1.0\n",
      "Epoch 65 of 500 took 0.434s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.001888683686653773 Acc: 0.9993489583333334\n",
      "val Loss: 6.402749568223953e-05 Acc: 1.0\n",
      "Epoch 66 of 500 took 0.421s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.0019375314522120687 Acc: 0.9991319444444444\n",
      "val Loss: 6.557349115610123e-05 Acc: 1.0\n",
      "Epoch 67 of 500 took 0.381s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.002060916740447283 Acc: 0.9995659722222222\n",
      "val Loss: 6.404519081115723e-05 Acc: 1.0\n",
      "Epoch    68: reducing learning rate of group 0 to 3.7372e-06.\n",
      "Epoch 68 of 500 took 0.380s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0025002917585273585 Acc: 0.9991319444444444\n",
      "val Loss: 6.03310763835907e-05 Acc: 1.0\n",
      "Epoch 69 of 500 took 0.384s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.001582851478209098 Acc: 0.9993489583333334\n",
      "val Loss: 6.353016942739487e-05 Acc: 1.0\n",
      "Epoch 70 of 500 took 0.282s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.0033484495037959684 Acc: 0.9986979166666666\n",
      "val Loss: 6.708502769470215e-05 Acc: 1.0\n",
      "Epoch 71 of 500 took 0.255s\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.0024926032767527634 Acc: 0.9993489583333334\n",
      "val Loss: 5.793292075395584e-05 Acc: 1.0\n",
      "Epoch 72 of 500 took 0.263s\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.0015949042927887705 Acc: 0.9993489583333334\n",
      "val Loss: 5.9798359870910645e-05 Acc: 1.0\n",
      "Epoch 73 of 500 took 0.296s\n",
      "\n",
      "Training complete in 0m 27s\n",
      "Best val loss: 0.000041\n",
      "ACCURACY TEST_0 FINAL : 99.411 %\n",
      "ACCURACY TEST_1 FINAL : 100.000 %\n",
      "CURRENT DATASET :  1\n",
      "(5312, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5021778206444449 Acc: 0.845703125\n",
      "val Loss: 0.009363348130136728 Acc: 0.998046875\n",
      "New best validation loss: 0.009363348130136728\n",
      "Epoch 1 of 500 took 0.574s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.044215979158050485 Acc: 0.9839409722222222\n",
      "val Loss: 0.002379337325692177 Acc: 1.0\n",
      "New best validation loss: 0.002379337325692177\n",
      "Epoch 2 of 500 took 0.410s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.03501842212345865 Acc: 0.9878472222222222\n",
      "val Loss: 0.0012436779215931892 Acc: 1.0\n",
      "New best validation loss: 0.0012436779215931892\n",
      "Epoch 3 of 500 took 0.507s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.02353899051538772 Acc: 0.9921875\n",
      "val Loss: 0.0012544598430395126 Acc: 1.0\n",
      "Epoch 4 of 500 took 0.577s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.01693837246340182 Acc: 0.9952256944444444\n",
      "val Loss: 0.000788387842476368 Acc: 1.0\n",
      "New best validation loss: 0.000788387842476368\n",
      "Epoch 5 of 500 took 0.485s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.01220561641578873 Acc: 0.9978298611111112\n",
      "val Loss: 0.0006563803181052208 Acc: 1.0\n",
      "New best validation loss: 0.0006563803181052208\n",
      "Epoch 6 of 500 took 0.324s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.01911637161134018 Acc: 0.9943576388888888\n",
      "val Loss: 0.0005714455619454384 Acc: 1.0\n",
      "New best validation loss: 0.0005714455619454384\n",
      "Epoch 7 of 500 took 0.276s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.013645814886937538 Acc: 0.9952256944444444\n",
      "val Loss: 0.0004330882802605629 Acc: 1.0\n",
      "New best validation loss: 0.0004330882802605629\n",
      "Epoch 8 of 500 took 0.272s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.009193136718951993 Acc: 0.998046875\n",
      "val Loss: 0.000467655248939991 Acc: 1.0\n",
      "Epoch 9 of 500 took 0.290s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.012642637723022036 Acc: 0.9956597222222222\n",
      "val Loss: 0.0003123590722680092 Acc: 1.0\n",
      "New best validation loss: 0.0003123590722680092\n",
      "Epoch 10 of 500 took 0.304s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.013925386127084494 Acc: 0.9952256944444444\n",
      "val Loss: 0.0003107050433754921 Acc: 1.0\n",
      "New best validation loss: 0.0003107050433754921\n",
      "Epoch 11 of 500 took 0.338s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.007331541325483058 Acc: 0.998046875\n",
      "val Loss: 0.0001996038481593132 Acc: 1.0\n",
      "New best validation loss: 0.0001996038481593132\n",
      "Epoch 12 of 500 took 0.331s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.009487518368081914 Acc: 0.9965277777777778\n",
      "val Loss: 0.00018030591309070587 Acc: 1.0\n",
      "New best validation loss: 0.00018030591309070587\n",
      "Epoch 13 of 500 took 0.312s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.007722624060180452 Acc: 0.9982638888888888\n",
      "val Loss: 0.0001634908840060234 Acc: 1.0\n",
      "New best validation loss: 0.0001634908840060234\n",
      "Epoch 14 of 500 took 0.342s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.006578013197415405 Acc: 0.9982638888888888\n",
      "val Loss: 0.00012052617967128754 Acc: 1.0\n",
      "New best validation loss: 0.00012052617967128754\n",
      "Epoch 15 of 500 took 0.363s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.007301690574321482 Acc: 0.998046875\n",
      "val Loss: 0.0001429133117198944 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.346s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.006283286234570874 Acc: 0.9984809027777778\n",
      "val Loss: 0.00010963249951601028 Acc: 1.0\n",
      "New best validation loss: 0.00010963249951601028\n",
      "Epoch 17 of 500 took 0.365s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.006979973314123021 Acc: 0.9978298611111112\n",
      "val Loss: 7.69440084695816e-05 Acc: 1.0\n",
      "New best validation loss: 7.69440084695816e-05\n",
      "Epoch 18 of 500 took 0.354s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.005045380650295151 Acc: 0.9986979166666666\n",
      "val Loss: 0.00013071298599243164 Acc: 1.0\n",
      "Epoch 19 of 500 took 0.295s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.004145974396831459 Acc: 0.9989149305555556\n",
      "val Loss: 5.0965696573257446e-05 Acc: 1.0\n",
      "New best validation loss: 5.0965696573257446e-05\n",
      "Epoch 20 of 500 took 0.306s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0029509435925218794 Acc: 0.9991319444444444\n",
      "val Loss: 6.1009079217910767e-05 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.282s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00378722899282972 Acc: 0.9991319444444444\n",
      "val Loss: 4.836171865463257e-05 Acc: 1.0\n",
      "New best validation loss: 4.836171865463257e-05\n",
      "Epoch 22 of 500 took 0.284s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.004140314490844806 Acc: 0.9991319444444444\n",
      "val Loss: 4.847906529903412e-05 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.274s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.008151984359655116 Acc: 0.9973958333333334\n",
      "val Loss: 5.605071783065796e-05 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.275s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.0033335096409751307 Acc: 0.9989149305555556\n",
      "val Loss: 7.728487253189087e-05 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.279s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.004473309912201431 Acc: 0.9991319444444444\n",
      "val Loss: 4.439800977706909e-05 Acc: 1.0\n",
      "New best validation loss: 4.439800977706909e-05\n",
      "Epoch 26 of 500 took 0.310s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.004496550601389673 Acc: 0.9991319444444444\n",
      "val Loss: 6.566382944583893e-05 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.349s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00403977744281292 Acc: 0.9986979166666666\n",
      "val Loss: 6.350874900817871e-05 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.419s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00314769862840573 Acc: 0.9993489583333334\n",
      "val Loss: 3.679841756820679e-05 Acc: 1.0\n",
      "New best validation loss: 3.679841756820679e-05\n",
      "Epoch 29 of 500 took 0.372s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0019317603049178917 Acc: 0.9995659722222222\n",
      "val Loss: 2.8403475880622864e-05 Acc: 1.0\n",
      "New best validation loss: 2.8403475880622864e-05\n",
      "Epoch 30 of 500 took 0.339s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.0027811198184887567 Acc: 0.9991319444444444\n",
      "val Loss: 2.3853033781051636e-05 Acc: 1.0\n",
      "New best validation loss: 2.3853033781051636e-05\n",
      "Epoch 31 of 500 took 0.282s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.005810915078553889 Acc: 0.998046875\n",
      "val Loss: 3.0230730772018433e-05 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.292s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0030681750633650357 Acc: 0.9993489583333334\n",
      "val Loss: 4.262849688529968e-05 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.317s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.003518101138373216 Acc: 0.9991319444444444\n",
      "val Loss: 2.372637391090393e-05 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.346s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.0026779694793124995 Acc: 0.9993489583333334\n",
      "val Loss: 2.5212764739990234e-05 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.347s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.003628441443045934 Acc: 0.9986979166666666\n",
      "val Loss: 2.524256706237793e-05 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.366s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.005893361987546086 Acc: 0.9978298611111112\n",
      "val Loss: 3.694556653499603e-05 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.279s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.0033016340393159124 Acc: 0.9993489583333334\n",
      "val Loss: 5.2595511078834534e-05 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.302s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.002753396104607317 Acc: 0.9991319444444444\n",
      "val Loss: 4.254281520843506e-05 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.292s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.0027094238127271333 Acc: 0.9993489583333334\n",
      "val Loss: 1.6262754797935486e-05 Acc: 1.0\n",
      "New best validation loss: 1.6262754797935486e-05\n",
      "Epoch 40 of 500 took 0.298s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0027098856969839996 Acc: 0.9989149305555556\n",
      "val Loss: 1.5040859580039978e-05 Acc: 1.0\n",
      "New best validation loss: 1.5040859580039978e-05\n",
      "Epoch 41 of 500 took 0.293s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.0018136612553563383 Acc: 0.9995659722222222\n",
      "val Loss: 2.1675601601600647e-05 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.284s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.0029140363136927285 Acc: 0.9993489583333334\n",
      "val Loss: 3.39653342962265e-05 Acc: 1.0\n",
      "Epoch 43 of 500 took 0.299s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0011698875783218278 Acc: 0.9997829861111112\n",
      "val Loss: 1.5774741768836975e-05 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.310s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.0018580914992425176 Acc: 0.9995659722222222\n",
      "val Loss: 9.490177035331726e-06 Acc: 1.0\n",
      "New best validation loss: 9.490177035331726e-06\n",
      "Epoch 45 of 500 took 0.449s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.002222086199455791 Acc: 0.9989149305555556\n",
      "val Loss: 9.179115295410156e-06 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.406s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.001426507615380817 Acc: 0.9995659722222222\n",
      "val Loss: 9.678304195404053e-06 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.381s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.0015006928394238155 Acc: 0.9995659722222222\n",
      "val Loss: 1.2477859854698181e-05 Acc: 1.0\n",
      "Epoch 48 of 500 took 0.576s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.0012865085154771805 Acc: 0.9995659722222222\n",
      "val Loss: 1.4467164874076843e-05 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.698s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.002398482006457117 Acc: 0.9993489583333334\n",
      "val Loss: 1.146271824836731e-05 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.397s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.0019059137751658757 Acc: 0.9995659722222222\n",
      "val Loss: 9.728595614433289e-06 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.365s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0021976475707358783 Acc: 0.9995659722222222\n",
      "val Loss: 9.05059278011322e-06 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.411s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.001652435606552495 Acc: 0.9993489583333334\n",
      "val Loss: 5.0924718379974365e-06 Acc: 1.0\n",
      "New best validation loss: 5.0924718379974365e-06\n",
      "Epoch 53 of 500 took 0.358s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.002960062896211942 Acc: 0.9984809027777778\n",
      "val Loss: 1.449882984161377e-05 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.346s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.0016419338062405586 Acc: 0.9995659722222222\n",
      "val Loss: 6.413087248802185e-06 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.372s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0017163508778644933 Acc: 0.9993489583333334\n",
      "val Loss: 4.293397068977356e-06 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.355s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0008533690124750137 Acc: 1.0\n",
      "val Loss: 4.505738615989685e-06 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.363s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.0016141922420097722 Acc: 0.9995659722222222\n",
      "val Loss: 1.9261613488197327e-05 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.350s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.002334650502436691 Acc: 0.9991319444444444\n",
      "val Loss: 1.2215226888656616e-05 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.358s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.003957013289133708 Acc: 0.9984809027777778\n",
      "val Loss: 5.595386028289795e-06 Acc: 1.0\n",
      "Epoch 60 of 500 took 0.354s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.004274965574343999 Acc: 0.9989149305555556\n",
      "val Loss: 7.402151823043823e-06 Acc: 1.0\n",
      "Epoch 61 of 500 took 0.348s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.001005239991678132 Acc: 0.9997829861111112\n",
      "val Loss: 4.0102750062942505e-06 Acc: 1.0\n",
      "New best validation loss: 4.0102750062942505e-06\n",
      "Epoch 62 of 500 took 0.360s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.0013421525557835896 Acc: 0.9995659722222222\n",
      "val Loss: 3.550201654434204e-06 Acc: 1.0\n",
      "Epoch 63 of 500 took 0.395s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.0013767095903555553 Acc: 0.9997829861111112\n",
      "val Loss: 3.07522714138031e-06 Acc: 1.0\n",
      "Epoch 64 of 500 took 0.359s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0013082831477125485 Acc: 0.9997829861111112\n",
      "val Loss: 1.5154480934143066e-05 Acc: 1.0\n",
      "Epoch 65 of 500 took 0.365s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.0012254271035393078 Acc: 0.9997829861111112\n",
      "val Loss: 3.376975655555725e-06 Acc: 1.0\n",
      "Epoch 66 of 500 took 0.357s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.001125131216314104 Acc: 0.9997829861111112\n",
      "val Loss: 2.8032809495925903e-06 Acc: 1.0\n",
      "New best validation loss: 2.8032809495925903e-06\n",
      "Epoch 67 of 500 took 0.355s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.0013643094441956943 Acc: 0.9995659722222222\n",
      "val Loss: 3.3676624298095703e-06 Acc: 1.0\n",
      "Epoch 68 of 500 took 0.354s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0024052017575336825 Acc: 0.9993489583333334\n",
      "val Loss: 4.991888999938965e-06 Acc: 1.0\n",
      "Epoch 69 of 500 took 0.366s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0023786422486106553 Acc: 0.9993489583333334\n",
      "val Loss: 5.548819899559021e-06 Acc: 1.0\n",
      "Epoch 70 of 500 took 0.377s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.0010352394440107876 Acc: 1.0\n",
      "val Loss: 3.9227306842803955e-06 Acc: 1.0\n",
      "Epoch 71 of 500 took 0.371s\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.002059629600909021 Acc: 0.9995659722222222\n",
      "val Loss: 2.5238841772079468e-06 Acc: 1.0\n",
      "Epoch 72 of 500 took 0.384s\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.0003947361061970393 Acc: 1.0\n",
      "val Loss: 3.475695848464966e-06 Acc: 1.0\n",
      "Epoch 73 of 500 took 0.396s\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.0006198297358221478 Acc: 1.0\n",
      "val Loss: 2.982094883918762e-06 Acc: 1.0\n",
      "Epoch 74 of 500 took 0.382s\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.0019239630653626388 Acc: 0.9995659722222222\n",
      "val Loss: 4.28222119808197e-06 Acc: 1.0\n",
      "Epoch 75 of 500 took 0.379s\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.00090694608580735 Acc: 0.9997829861111112\n",
      "val Loss: 2.382323145866394e-06 Acc: 1.0\n",
      "Epoch 76 of 500 took 0.428s\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.0003945717795027627 Acc: 1.0\n",
      "val Loss: 4.101544618606567e-06 Acc: 1.0\n",
      "Epoch 77 of 500 took 0.419s\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.00047139740652508207 Acc: 1.0\n",
      "val Loss: 2.9318034648895264e-06 Acc: 1.0\n",
      "Epoch 78 of 500 took 0.384s\n",
      "\n",
      "Training complete in 0m 28s\n",
      "Best val loss: 0.000003\n",
      "ACCURACY TEST_0 FINAL : 99.907 %\n",
      "ACCURACY TEST_1 FINAL : 99.783 %\n",
      "CURRENT DATASET :  2\n",
      "(5312, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.7828654067383872 Acc: 0.740234375\n",
      "val Loss: 0.16066768020391464 Acc: 0.939453125\n",
      "New best validation loss: 0.16066768020391464\n",
      "Epoch 1 of 500 took 0.372s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.2318624978264173 Acc: 0.9129774305555556\n",
      "val Loss: 0.07060052081942558 Acc: 0.978515625\n",
      "New best validation loss: 0.07060052081942558\n",
      "Epoch 2 of 500 took 0.399s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.17040538208352196 Acc: 0.935546875\n",
      "val Loss: 0.05182378180325031 Acc: 0.984375\n",
      "New best validation loss: 0.05182378180325031\n",
      "Epoch 3 of 500 took 0.374s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.1257082335650921 Acc: 0.9561631944444444\n",
      "val Loss: 0.050760471262037754 Acc: 0.984375\n",
      "New best validation loss: 0.050760471262037754\n",
      "Epoch 4 of 500 took 0.386s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.12256238775120841 Acc: 0.9565972222222222\n",
      "val Loss: 0.034797326661646366 Acc: 0.986328125\n",
      "New best validation loss: 0.034797326661646366\n",
      "Epoch 5 of 500 took 0.562s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.0900307446718216 Acc: 0.9711371527777778\n",
      "val Loss: 0.029478101525455713 Acc: 0.990234375\n",
      "New best validation loss: 0.029478101525455713\n",
      "Epoch 6 of 500 took 0.414s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.10028182259864277 Acc: 0.96484375\n",
      "val Loss: 0.022052543703466654 Acc: 0.990234375\n",
      "New best validation loss: 0.022052543703466654\n",
      "Epoch 7 of 500 took 0.546s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.07639721025609308 Acc: 0.9754774305555556\n",
      "val Loss: 0.03609005268663168 Acc: 0.986328125\n",
      "Epoch 8 of 500 took 0.640s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.07757273813088734 Acc: 0.9728732638888888\n",
      "val Loss: 0.022016208618879318 Acc: 0.9921875\n",
      "New best validation loss: 0.022016208618879318\n",
      "Epoch 9 of 500 took 0.469s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.07659446717136437 Acc: 0.9733072916666666\n",
      "val Loss: 0.02214502077549696 Acc: 0.990234375\n",
      "Epoch 10 of 500 took 0.386s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.06360200958119498 Acc: 0.9763454861111112\n",
      "val Loss: 0.019124996848404408 Acc: 0.9921875\n",
      "New best validation loss: 0.019124996848404408\n",
      "Epoch 11 of 500 took 0.409s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.05622117076483038 Acc: 0.9798177083333334\n",
      "val Loss: 0.012622850015759468 Acc: 0.994140625\n",
      "New best validation loss: 0.012622850015759468\n",
      "Epoch 12 of 500 took 0.395s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.04880440152353711 Acc: 0.9830729166666666\n",
      "val Loss: 0.010359074920415878 Acc: 0.998046875\n",
      "New best validation loss: 0.010359074920415878\n",
      "Epoch 13 of 500 took 0.412s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.05455649644136429 Acc: 0.9817708333333334\n",
      "val Loss: 0.014201872050762177 Acc: 0.9921875\n",
      "Epoch 14 of 500 took 0.372s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.050884450164934 Acc: 0.9811197916666666\n",
      "val Loss: 0.02735013607889414 Acc: 0.990234375\n",
      "Epoch 15 of 500 took 0.371s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.056139827291998595 Acc: 0.9789496527777778\n",
      "val Loss: 0.011786201037466526 Acc: 0.998046875\n",
      "Epoch 16 of 500 took 0.375s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.050186287301282086 Acc: 0.982421875\n",
      "val Loss: 0.0033556967973709106 Acc: 1.0\n",
      "New best validation loss: 0.0033556967973709106\n",
      "Epoch 17 of 500 took 0.380s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.04657975325567855 Acc: 0.9841579861111112\n",
      "val Loss: 0.006222072057425976 Acc: 0.998046875\n",
      "Epoch 18 of 500 took 0.384s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.04635752520213524 Acc: 0.9828559027777778\n",
      "val Loss: 0.017543240450322628 Acc: 0.994140625\n",
      "Epoch 19 of 500 took 0.376s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.03822334690226449 Acc: 0.9861111111111112\n",
      "val Loss: 0.008544052951037884 Acc: 0.99609375\n",
      "Epoch 20 of 500 took 0.528s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.040390999884241156 Acc: 0.9865451388888888\n",
      "val Loss: 0.003943935036659241 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.380s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.0396906736617287 Acc: 0.9865451388888888\n",
      "val Loss: 0.004756873473525047 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.406s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.03776751634561353 Acc: 0.9861111111111112\n",
      "val Loss: 0.00734187476336956 Acc: 1.0\n",
      "Epoch    23: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 23 of 500 took 0.384s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.03327090365605222 Acc: 0.9889322916666666\n",
      "val Loss: 0.0054179951548576355 Acc: 0.998046875\n",
      "Epoch 24 of 500 took 0.384s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.029828663191033736 Acc: 0.9884982638888888\n",
      "val Loss: 0.0032353391870856285 Acc: 1.0\n",
      "New best validation loss: 0.0032353391870856285\n",
      "Epoch 25 of 500 took 0.388s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.03129975187281767 Acc: 0.9895833333333334\n",
      "val Loss: 0.003613981418311596 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.380s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.02659674325130052 Acc: 0.990234375\n",
      "val Loss: 0.004141582176089287 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.380s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.029155615251511335 Acc: 0.9906684027777778\n",
      "val Loss: 0.003100643865764141 Acc: 1.0\n",
      "New best validation loss: 0.003100643865764141\n",
      "Epoch 28 of 500 took 0.408s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.025418476512034733 Acc: 0.9913194444444444\n",
      "val Loss: 0.005230272188782692 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.391s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.021068683670212824 Acc: 0.9930555555555556\n",
      "val Loss: 0.0028858771547675133 Acc: 1.0\n",
      "New best validation loss: 0.0028858771547675133\n",
      "Epoch 30 of 500 took 0.357s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.020954493071056075 Acc: 0.9926215277777778\n",
      "val Loss: 0.003251264803111553 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.336s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.023081858745879598 Acc: 0.9913194444444444\n",
      "val Loss: 0.003246588632464409 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.362s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.021847365630997553 Acc: 0.9919704861111112\n",
      "val Loss: 0.0034502968192100525 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.332s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.023392097972747352 Acc: 0.9926215277777778\n",
      "val Loss: 0.0035977205261588097 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.309s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.021907042091091473 Acc: 0.9928385416666666\n",
      "val Loss: 0.002441772259771824 Acc: 1.0\n",
      "New best validation loss: 0.002441772259771824\n",
      "Epoch 35 of 500 took 0.424s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.022684511314663622 Acc: 0.9915364583333334\n",
      "val Loss: 0.003027459606528282 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.390s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.02437586182107528 Acc: 0.9937065972222222\n",
      "val Loss: 0.002672952599823475 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.406s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.01859327219426632 Acc: 0.9934895833333334\n",
      "val Loss: 0.0035768812522292137 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.381s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.025572866149660613 Acc: 0.9913194444444444\n",
      "val Loss: 0.003846527077257633 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.373s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.02442083994133605 Acc: 0.9917534722222222\n",
      "val Loss: 0.0021414030343294144 Acc: 1.0\n",
      "New best validation loss: 0.0021414030343294144\n",
      "Epoch 40 of 500 took 0.395s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.023226946747551363 Acc: 0.9913194444444444\n",
      "val Loss: 0.0027058320119976997 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.376s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.02464633284964495 Acc: 0.9915364583333334\n",
      "val Loss: 0.0036280304193496704 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.544s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.019506189196060102 Acc: 0.9934895833333334\n",
      "val Loss: 0.0025481032207608223 Acc: 1.0\n",
      "Epoch 43 of 500 took 0.418s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.017427472345944908 Acc: 0.9943576388888888\n",
      "val Loss: 0.002805582247674465 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.580s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.01402813656669524 Acc: 0.9958767361111112\n",
      "val Loss: 0.0031024841591715813 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.650s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.019817799122797117 Acc: 0.9952256944444444\n",
      "val Loss: 0.002453431487083435 Acc: 1.0\n",
      "Epoch    46: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 46 of 500 took 0.505s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.01939197505513827 Acc: 0.994140625\n",
      "val Loss: 0.002870711497962475 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.406s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.018592517202099163 Acc: 0.9937065972222222\n",
      "val Loss: 0.0016044769436120987 Acc: 1.0\n",
      "New best validation loss: 0.0016044769436120987\n",
      "Epoch 48 of 500 took 0.361s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.019455586456590228 Acc: 0.994140625\n",
      "val Loss: 0.0023982208222150803 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.305s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.021974758607231908 Acc: 0.9921875\n",
      "val Loss: 0.0022259457036852837 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.300s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.017854501596755452 Acc: 0.9939236111111112\n",
      "val Loss: 0.001999019645154476 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.307s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.01550505356863141 Acc: 0.9939236111111112\n",
      "val Loss: 0.002627922222018242 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.318s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.01901435608872109 Acc: 0.9932725694444444\n",
      "val Loss: 0.002057884819805622 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.306s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.019595320595221385 Acc: 0.9937065972222222\n",
      "val Loss: 0.0025770552456378937 Acc: 1.0\n",
      "Epoch    54: reducing learning rate of group 0 to 1.8686e-05.\n",
      "Epoch 54 of 500 took 0.300s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.018792310936583415 Acc: 0.9947916666666666\n",
      "val Loss: 0.0024997591972351074 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.300s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.015489528214351999 Acc: 0.994140625\n",
      "val Loss: 0.002769993618130684 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.299s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.014997361693531275 Acc: 0.9943576388888888\n",
      "val Loss: 0.0023754918947815895 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.299s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.015804052042464416 Acc: 0.9939236111111112\n",
      "val Loss: 0.0017502456903457642 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.302s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.018262226031058364 Acc: 0.9937065972222222\n",
      "val Loss: 0.002344156615436077 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.305s\n",
      "\n",
      "Training complete in 0m 23s\n",
      "Best val loss: 0.001604\n",
      "ACCURACY TEST_0 FINAL : 91.050 %\n",
      "ACCURACY TEST_1 FINAL : 94.658 %\n",
      "CURRENT DATASET :  3\n",
      "(5312, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5312313669257693 Acc: 0.8344184027777778\n",
      "val Loss: 0.04667959222570062 Acc: 0.978515625\n",
      "New best validation loss: 0.04667959222570062\n",
      "Epoch 1 of 500 took 0.369s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.08849550762938128 Acc: 0.9683159722222222\n",
      "val Loss: 0.00865524122491479 Acc: 0.998046875\n",
      "New best validation loss: 0.00865524122491479\n",
      "Epoch 2 of 500 took 0.424s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.05214993024451865 Acc: 0.98046875\n",
      "val Loss: 0.013029860332608223 Acc: 0.99609375\n",
      "Epoch 3 of 500 took 0.356s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.04466737817145056 Acc: 0.9852430555555556\n",
      "val Loss: 0.00608556903898716 Acc: 0.998046875\n",
      "New best validation loss: 0.00608556903898716\n",
      "Epoch 4 of 500 took 0.373s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.033335857248554625 Acc: 0.9893663194444444\n",
      "val Loss: 0.005987836513668299 Acc: 0.998046875\n",
      "New best validation loss: 0.005987836513668299\n",
      "Epoch 5 of 500 took 0.368s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.02560825113000141 Acc: 0.9919704861111112\n",
      "val Loss: 0.002990586683154106 Acc: 1.0\n",
      "New best validation loss: 0.002990586683154106\n",
      "Epoch 6 of 500 took 0.344s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.02048993529751897 Acc: 0.9952256944444444\n",
      "val Loss: 0.004077784717082977 Acc: 0.998046875\n",
      "Epoch 7 of 500 took 0.422s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.0227012491474549 Acc: 0.9928385416666666\n",
      "val Loss: 0.002515442669391632 Acc: 1.0\n",
      "New best validation loss: 0.002515442669391632\n",
      "Epoch 8 of 500 took 0.293s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.016274484960983198 Acc: 0.9950086805555556\n",
      "val Loss: 0.001804920844733715 Acc: 1.0\n",
      "New best validation loss: 0.001804920844733715\n",
      "Epoch 9 of 500 took 0.297s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.014389284369018342 Acc: 0.9952256944444444\n",
      "val Loss: 0.0023003844544291496 Acc: 1.0\n",
      "Epoch 10 of 500 took 0.302s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.01563251546273629 Acc: 0.9937065972222222\n",
      "val Loss: 0.0011619357392191887 Acc: 1.0\n",
      "New best validation loss: 0.0011619357392191887\n",
      "Epoch 11 of 500 took 0.298s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.02194703623859419 Acc: 0.9915364583333334\n",
      "val Loss: 0.0012006154283881187 Acc: 1.0\n",
      "Epoch 12 of 500 took 0.358s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.01870336973418792 Acc: 0.9934895833333334\n",
      "val Loss: 0.0006104139611124992 Acc: 1.0\n",
      "New best validation loss: 0.0006104139611124992\n",
      "Epoch 13 of 500 took 0.392s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.013128694716013141 Acc: 0.9952256944444444\n",
      "val Loss: 0.0007745036855340004 Acc: 1.0\n",
      "Epoch 14 of 500 took 0.470s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.011060544651829533 Acc: 0.9969618055555556\n",
      "val Loss: 0.0012011127546429634 Acc: 1.0\n",
      "Epoch 15 of 500 took 0.371s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.01064024099873172 Acc: 0.9976128472222222\n",
      "val Loss: 0.0006156433373689651 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.382s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.01081122737377882 Acc: 0.9969618055555556\n",
      "val Loss: 0.0008576028048992157 Acc: 1.0\n",
      "Epoch 17 of 500 took 0.376s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.01199260369564096 Acc: 0.99609375\n",
      "val Loss: 0.0008677346631884575 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.378s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.010010414239433076 Acc: 0.9967447916666666\n",
      "val Loss: 0.0010269880294799805 Acc: 1.0\n",
      "Epoch    19: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 19 of 500 took 0.376s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.011767144832346175 Acc: 0.99609375\n",
      "val Loss: 0.0005020350217819214 Acc: 1.0\n",
      "New best validation loss: 0.0005020350217819214\n",
      "Epoch 20 of 500 took 0.328s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.005490353900111384 Acc: 0.9989149305555556\n",
      "val Loss: 0.0004958342760801315 Acc: 1.0\n",
      "New best validation loss: 0.0004958342760801315\n",
      "Epoch 21 of 500 took 0.308s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.008929801639169455 Acc: 0.9973958333333334\n",
      "val Loss: 0.0004963967949151993 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.309s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.005668909340682957 Acc: 0.9982638888888888\n",
      "val Loss: 0.0005599278956651688 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.445s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.006929357536137104 Acc: 0.9982638888888888\n",
      "val Loss: 0.0005523506551980972 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.422s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.007369345209250848 Acc: 0.9976128472222222\n",
      "val Loss: 0.0004653641954064369 Acc: 1.0\n",
      "New best validation loss: 0.0004653641954064369\n",
      "Epoch 25 of 500 took 0.504s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.007454751783774959 Acc: 0.9971788194444444\n",
      "val Loss: 0.0004385337233543396 Acc: 1.0\n",
      "New best validation loss: 0.0004385337233543396\n",
      "Epoch 26 of 500 took 0.561s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.008793230272001691 Acc: 0.9978298611111112\n",
      "val Loss: 0.0004451591521501541 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.442s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.008101865028341612 Acc: 0.9978298611111112\n",
      "val Loss: 0.0004595071077346802 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.310s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.006465751600141327 Acc: 0.9973958333333334\n",
      "val Loss: 0.00045938417315483093 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.338s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.006522133842938476 Acc: 0.9982638888888888\n",
      "val Loss: 0.0003413567319512367 Acc: 1.0\n",
      "New best validation loss: 0.0003413567319512367\n",
      "Epoch 30 of 500 took 0.392s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.006298394045896 Acc: 0.9982638888888888\n",
      "val Loss: 0.00041060708463191986 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.342s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.006652903122206529 Acc: 0.998046875\n",
      "val Loss: 0.0003220047801733017 Acc: 1.0\n",
      "New best validation loss: 0.0003220047801733017\n",
      "Epoch 32 of 500 took 0.306s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.005710160152779685 Acc: 0.998046875\n",
      "val Loss: 0.0003056572750210762 Acc: 1.0\n",
      "New best validation loss: 0.0003056572750210762\n",
      "Epoch 33 of 500 took 0.322s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.004422969909177886 Acc: 0.9984809027777778\n",
      "val Loss: 0.00027882400900125504 Acc: 1.0\n",
      "New best validation loss: 0.00027882400900125504\n",
      "Epoch 34 of 500 took 0.317s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.009605720742709108 Acc: 0.9976128472222222\n",
      "val Loss: 0.00022028759121894836 Acc: 1.0\n",
      "New best validation loss: 0.00022028759121894836\n",
      "Epoch 35 of 500 took 0.309s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.006750786263081763 Acc: 0.9984809027777778\n",
      "val Loss: 0.00021883100271224976 Acc: 1.0\n",
      "New best validation loss: 0.00021883100271224976\n",
      "Epoch 36 of 500 took 0.302s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.004740230325195525 Acc: 0.9984809027777778\n",
      "val Loss: 0.0003424389287829399 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.325s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.007873433021207651 Acc: 0.9976128472222222\n",
      "val Loss: 0.00022506806999444962 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.301s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.006298498043583499 Acc: 0.9982638888888888\n",
      "val Loss: 0.00019052252173423767 Acc: 1.0\n",
      "New best validation loss: 0.00019052252173423767\n",
      "Epoch 39 of 500 took 0.312s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.006543311756104231 Acc: 0.9982638888888888\n",
      "val Loss: 0.00023158453404903412 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.314s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.004337642445332474 Acc: 0.9984809027777778\n",
      "val Loss: 0.00016655214130878448 Acc: 1.0\n",
      "New best validation loss: 0.00016655214130878448\n",
      "Epoch 41 of 500 took 0.313s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.005953974711398284 Acc: 0.9982638888888888\n",
      "val Loss: 0.00015093665570020676 Acc: 1.0\n",
      "New best validation loss: 0.00015093665570020676\n",
      "Epoch 42 of 500 took 0.313s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.005966006881660885 Acc: 0.9982638888888888\n",
      "val Loss: 0.00022238213568925858 Acc: 1.0\n",
      "Epoch 43 of 500 took 0.307s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.006194235239591863 Acc: 0.9984809027777778\n",
      "val Loss: 0.0002336287871003151 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.306s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.004830121528357267 Acc: 0.9991319444444444\n",
      "val Loss: 0.00021839048713445663 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.345s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0047143202068077195 Acc: 0.9984809027777778\n",
      "val Loss: 0.00020770356059074402 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.304s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.005517390504893329 Acc: 0.9982638888888888\n",
      "val Loss: 0.0002781189978122711 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.301s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.005319372750818729 Acc: 0.998046875\n",
      "val Loss: 0.0002061557024717331 Acc: 1.0\n",
      "Epoch    48: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 48 of 500 took 0.307s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.005290645950784286 Acc: 0.9984809027777778\n",
      "val Loss: 0.0001952359452843666 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.300s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.006628507489545478 Acc: 0.9976128472222222\n",
      "val Loss: 0.0001659877598285675 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.310s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.003063987216187848 Acc: 0.9991319444444444\n",
      "val Loss: 0.0001345425844192505 Acc: 1.0\n",
      "New best validation loss: 0.0001345425844192505\n",
      "Epoch 51 of 500 took 0.318s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.003710907521761126 Acc: 0.9991319444444444\n",
      "val Loss: 0.0001591639593243599 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.308s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.004473882416884105 Acc: 0.9991319444444444\n",
      "val Loss: 0.00015135668218135834 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.364s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.00366667958183421 Acc: 0.9989149305555556\n",
      "val Loss: 0.00012995954602956772 Acc: 1.0\n",
      "New best validation loss: 0.00012995954602956772\n",
      "Epoch 54 of 500 took 0.316s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.005186213232162926 Acc: 0.9986979166666666\n",
      "val Loss: 0.00014461949467658997 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.309s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0042532869718141025 Acc: 0.9982638888888888\n",
      "val Loss: 0.00013464689254760742 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.300s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.005337259732186794 Acc: 0.9982638888888888\n",
      "val Loss: 0.00013266317546367645 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.307s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.005094492394063208 Acc: 0.9984809027777778\n",
      "val Loss: 0.00016602873802185059 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.302s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.004630729349123107 Acc: 0.9986979166666666\n",
      "val Loss: 0.00016665924340486526 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.303s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.005759228331347306 Acc: 0.9984809027777778\n",
      "val Loss: 0.00013053417205810547 Acc: 1.0\n",
      "Epoch    60: reducing learning rate of group 0 to 1.8686e-05.\n",
      "Epoch 60 of 500 took 0.313s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.004381960516588556 Acc: 0.9986979166666666\n",
      "val Loss: 0.00018164608627557755 Acc: 1.0\n",
      "Epoch 61 of 500 took 0.345s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.005277378639827172 Acc: 0.9984809027777778\n",
      "val Loss: 0.0001601036638021469 Acc: 1.0\n",
      "Epoch 62 of 500 took 0.300s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.003991053957078192 Acc: 0.9989149305555556\n",
      "val Loss: 0.0001510409638285637 Acc: 1.0\n",
      "Epoch 63 of 500 took 0.320s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.0071792205174763995 Acc: 0.9971788194444444\n",
      "val Loss: 0.00018075015395879745 Acc: 1.0\n",
      "Epoch 64 of 500 took 0.312s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.004218340540925662 Acc: 0.9991319444444444\n",
      "val Loss: 0.00014015194028615952 Acc: 1.0\n",
      "Epoch 65 of 500 took 0.389s\n",
      "\n",
      "Training complete in 0m 22s\n",
      "Best val loss: 0.000130\n",
      "ACCURACY TEST_0 FINAL : 100.000 %\n",
      "ACCURACY TEST_1 FINAL : 99.969 %\n",
      "CURRENT DATASET :  4\n",
      "(5308, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.4910748509897126 Acc: 0.8530815972222222\n",
      "val Loss: 0.018343274481594563 Acc: 0.990234375\n",
      "New best validation loss: 0.018343274481594563\n",
      "Epoch 1 of 500 took 0.356s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.048199055095513664 Acc: 0.984375\n",
      "val Loss: 0.0030399439856410027 Acc: 1.0\n",
      "New best validation loss: 0.0030399439856410027\n",
      "Epoch 2 of 500 took 0.522s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.0301588780971037 Acc: 0.9908854166666666\n",
      "val Loss: 0.0024162065237760544 Acc: 1.0\n",
      "New best validation loss: 0.0024162065237760544\n",
      "Epoch 3 of 500 took 0.330s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.019159701549344592 Acc: 0.9947916666666666\n",
      "val Loss: 0.0018257275223731995 Acc: 1.0\n",
      "New best validation loss: 0.0018257275223731995\n",
      "Epoch 4 of 500 took 0.348s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.013095090683135722 Acc: 0.9967447916666666\n",
      "val Loss: 0.0015206728130578995 Acc: 1.0\n",
      "New best validation loss: 0.0015206728130578995\n",
      "Epoch 5 of 500 took 0.616s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.016686254180967808 Acc: 0.9934895833333334\n",
      "val Loss: 0.0007819728925824165 Acc: 1.0\n",
      "New best validation loss: 0.0007819728925824165\n",
      "Epoch 6 of 500 took 0.672s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.014846465912544064 Acc: 0.9952256944444444\n",
      "val Loss: 0.0011134548112750053 Acc: 1.0\n",
      "Epoch 7 of 500 took 0.405s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.012070316096974744 Acc: 0.9956597222222222\n",
      "val Loss: 0.0005735624581575394 Acc: 1.0\n",
      "New best validation loss: 0.0005735624581575394\n",
      "Epoch 8 of 500 took 0.422s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00923243842812048 Acc: 0.9973958333333334\n",
      "val Loss: 0.0005401186645030975 Acc: 1.0\n",
      "New best validation loss: 0.0005401186645030975\n",
      "Epoch 9 of 500 took 0.392s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.006414848069349925 Acc: 0.9984809027777778\n",
      "val Loss: 0.00043904688209295273 Acc: 1.0\n",
      "New best validation loss: 0.00043904688209295273\n",
      "Epoch 10 of 500 took 0.443s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.007979076407435868 Acc: 0.9973958333333334\n",
      "val Loss: 0.00039826612919569016 Acc: 1.0\n",
      "New best validation loss: 0.00039826612919569016\n",
      "Epoch 11 of 500 took 0.375s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.007483409458978308 Acc: 0.998046875\n",
      "val Loss: 0.0004039201885461807 Acc: 1.0\n",
      "Epoch 12 of 500 took 0.377s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.006380718874020709 Acc: 0.9989149305555556\n",
      "val Loss: 0.0003224574029445648 Acc: 1.0\n",
      "New best validation loss: 0.0003224574029445648\n",
      "Epoch 13 of 500 took 0.375s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.005339134691490067 Acc: 0.9986979166666666\n",
      "val Loss: 0.00026520155370235443 Acc: 1.0\n",
      "New best validation loss: 0.00026520155370235443\n",
      "Epoch 14 of 500 took 0.383s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.006022668133179347 Acc: 0.9982638888888888\n",
      "val Loss: 0.0002616560086607933 Acc: 1.0\n",
      "New best validation loss: 0.0002616560086607933\n",
      "Epoch 15 of 500 took 0.396s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.005723043241434627 Acc: 0.9982638888888888\n",
      "val Loss: 0.00017520878463983536 Acc: 1.0\n",
      "New best validation loss: 0.00017520878463983536\n",
      "Epoch 16 of 500 took 0.383s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.004213311968164312 Acc: 0.9991319444444444\n",
      "val Loss: 0.00014567654579877853 Acc: 1.0\n",
      "New best validation loss: 0.00014567654579877853\n",
      "Epoch 17 of 500 took 0.390s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.007408359346704351 Acc: 0.998046875\n",
      "val Loss: 0.00014465302228927612 Acc: 1.0\n",
      "New best validation loss: 0.00014465302228927612\n",
      "Epoch 18 of 500 took 0.360s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.004382122980637683 Acc: 0.9991319444444444\n",
      "val Loss: 0.00014131329953670502 Acc: 1.0\n",
      "New best validation loss: 0.00014131329953670502\n",
      "Epoch 19 of 500 took 0.375s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.0038045192033880288 Acc: 0.9989149305555556\n",
      "val Loss: 0.0001440746709704399 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.381s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0031699087574250167 Acc: 0.9995659722222222\n",
      "val Loss: 0.0001731719821691513 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.400s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.0031588218795756498 Acc: 0.9991319444444444\n",
      "val Loss: 0.00010754261165857315 Acc: 1.0\n",
      "New best validation loss: 0.00010754261165857315\n",
      "Epoch 22 of 500 took 0.372s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.005264282847444217 Acc: 0.9986979166666666\n",
      "val Loss: 9.991973638534546e-05 Acc: 1.0\n",
      "New best validation loss: 9.991973638534546e-05\n",
      "Epoch 23 of 500 took 0.382s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.005068023378650348 Acc: 0.9982638888888888\n",
      "val Loss: 8.275266736745834e-05 Acc: 1.0\n",
      "New best validation loss: 8.275266736745834e-05\n",
      "Epoch 24 of 500 took 0.376s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.002327625329295794 Acc: 0.9995659722222222\n",
      "val Loss: 9.393971413373947e-05 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.369s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.005427307604501645 Acc: 0.9982638888888888\n",
      "val Loss: 8.633360266685486e-05 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.375s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.0024356929999258784 Acc: 0.9993489583333334\n",
      "val Loss: 5.6473538279533386e-05 Acc: 1.0\n",
      "New best validation loss: 5.6473538279533386e-05\n",
      "Epoch 27 of 500 took 0.388s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.0028711195724705854 Acc: 0.9995659722222222\n",
      "val Loss: 6.540119647979736e-05 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.376s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.0023830163603027663 Acc: 0.9995659722222222\n",
      "val Loss: 5.63841313123703e-05 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.370s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00444665892670552 Acc: 0.9984809027777778\n",
      "val Loss: 8.59452411532402e-05 Acc: 1.0\n",
      "Epoch 30 of 500 took 0.382s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.0039064267960687475 Acc: 0.9991319444444444\n",
      "val Loss: 7.865205407142639e-05 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.399s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.002376419957727194 Acc: 0.9995659722222222\n",
      "val Loss: 4.6994537115097046e-05 Acc: 1.0\n",
      "New best validation loss: 4.6994537115097046e-05\n",
      "Epoch 32 of 500 took 0.385s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0021418792506059012 Acc: 0.9995659722222222\n",
      "val Loss: 3.5801902413368225e-05 Acc: 1.0\n",
      "New best validation loss: 3.5801902413368225e-05\n",
      "Epoch 33 of 500 took 0.460s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.0036128006047672695 Acc: 0.9989149305555556\n",
      "val Loss: 5.3821131587028503e-05 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.418s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.002895439819743236 Acc: 0.9984809027777778\n",
      "val Loss: 2.5505200028419495e-05 Acc: 1.0\n",
      "New best validation loss: 2.5505200028419495e-05\n",
      "Epoch 35 of 500 took 0.393s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0023390366695821285 Acc: 0.9993489583333334\n",
      "val Loss: 3.999285399913788e-05 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.391s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.0032193177483148044 Acc: 0.9991319444444444\n",
      "val Loss: 3.721565008163452e-05 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.378s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.0016920591394106548 Acc: 0.9997829861111112\n",
      "val Loss: 2.6142224669456482e-05 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.395s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.0014375243853363725 Acc: 0.9997829861111112\n",
      "val Loss: 2.625584602355957e-05 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.562s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.003637721555100547 Acc: 0.9984809027777778\n",
      "val Loss: 3.084726631641388e-05 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.449s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0022298896478282083 Acc: 0.9995659722222222\n",
      "val Loss: 2.956576645374298e-05 Acc: 1.0\n",
      "Epoch    41: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 41 of 500 took 0.599s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.002105632124261724 Acc: 0.9991319444444444\n",
      "val Loss: 2.2290274500846863e-05 Acc: 1.0\n",
      "New best validation loss: 2.2290274500846863e-05\n",
      "Epoch 42 of 500 took 0.592s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.002527599740359518 Acc: 0.9991319444444444\n",
      "val Loss: 2.039596438407898e-05 Acc: 1.0\n",
      "New best validation loss: 2.039596438407898e-05\n",
      "Epoch 43 of 500 took 0.346s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0020568978248371016 Acc: 0.9991319444444444\n",
      "val Loss: 2.6084482669830322e-05 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.384s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.001923877021504773 Acc: 0.9993489583333334\n",
      "val Loss: 2.566911280155182e-05 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.417s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0011585173714492056 Acc: 0.9997829861111112\n",
      "val Loss: 2.2085383534431458e-05 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.348s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0011658329102728101 Acc: 0.9997829861111112\n",
      "val Loss: 1.8863007426261902e-05 Acc: 1.0\n",
      "New best validation loss: 1.8863007426261902e-05\n",
      "Epoch 47 of 500 took 0.307s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.001818738774292999 Acc: 0.9995659722222222\n",
      "val Loss: 1.9842758774757385e-05 Acc: 1.0\n",
      "Epoch 48 of 500 took 0.302s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.0021711687246958413 Acc: 0.9993489583333334\n",
      "val Loss: 2.7876347303390503e-05 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.316s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.00267944588429398 Acc: 0.9991319444444444\n",
      "val Loss: 2.166256308555603e-05 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.310s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.0012884512543678284 Acc: 0.9997829861111112\n",
      "val Loss: 1.9233673810958862e-05 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.305s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0011235798916055097 Acc: 0.9997829861111112\n",
      "val Loss: 1.6337260603904724e-05 Acc: 1.0\n",
      "New best validation loss: 1.6337260603904724e-05\n",
      "Epoch 52 of 500 took 0.299s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0007421730293167962 Acc: 1.0\n",
      "val Loss: 1.8075108528137207e-05 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.310s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.00166730261925194 Acc: 0.9995659722222222\n",
      "val Loss: 1.7298385500907898e-05 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.320s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.0023319561344881854 Acc: 0.9993489583333334\n",
      "val Loss: 1.99880450963974e-05 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.298s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0006241821166541842 Acc: 1.0\n",
      "val Loss: 1.8209218978881836e-05 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.317s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0009130021143290731 Acc: 1.0\n",
      "val Loss: 1.842901110649109e-05 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.564s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.0021172877815034655 Acc: 0.9991319444444444\n",
      "val Loss: 1.6435980796813965e-05 Acc: 1.0\n",
      "Epoch    58: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 58 of 500 took 0.389s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0012763782611323728 Acc: 0.9995659722222222\n",
      "val Loss: 1.4619901776313782e-05 Acc: 1.0\n",
      "New best validation loss: 1.4619901776313782e-05\n",
      "Epoch 59 of 500 took 0.391s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0017253336393170888 Acc: 0.9993489583333334\n",
      "val Loss: 1.8831342458724976e-05 Acc: 1.0\n",
      "Epoch 60 of 500 took 0.447s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.0012866399354404872 Acc: 0.9995659722222222\n",
      "val Loss: 1.8790364265441895e-05 Acc: 1.0\n",
      "Epoch 61 of 500 took 0.404s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.0009758612141013145 Acc: 0.9997829861111112\n",
      "val Loss: 1.942366361618042e-05 Acc: 1.0\n",
      "Epoch 62 of 500 took 0.385s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.0014675728355844815 Acc: 0.9995659722222222\n",
      "val Loss: 1.8738210201263428e-05 Acc: 1.0\n",
      "Epoch 63 of 500 took 0.389s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.0012479724569453134 Acc: 0.9997829861111112\n",
      "val Loss: 1.6771256923675537e-05 Acc: 1.0\n",
      "Epoch 64 of 500 took 0.390s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0008818120178249148 Acc: 0.9995659722222222\n",
      "val Loss: 1.706555485725403e-05 Acc: 1.0\n",
      "Epoch    65: reducing learning rate of group 0 to 1.8686e-05.\n",
      "Epoch 65 of 500 took 0.401s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.0013968532180620565 Acc: 0.9995659722222222\n",
      "val Loss: 1.7603859305381775e-05 Acc: 1.0\n",
      "Epoch 66 of 500 took 0.329s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.0011299238022830752 Acc: 0.9997829861111112\n",
      "val Loss: 1.634657382965088e-05 Acc: 1.0\n",
      "Epoch 67 of 500 took 0.311s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.0018508082462681665 Acc: 0.9995659722222222\n",
      "val Loss: 1.6707926988601685e-05 Acc: 1.0\n",
      "Epoch 68 of 500 took 0.318s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0017967674260338147 Acc: 0.9991319444444444\n",
      "val Loss: 1.6905367374420166e-05 Acc: 1.0\n",
      "Epoch 69 of 500 took 0.307s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0013530549800230397 Acc: 0.9997829861111112\n",
      "val Loss: 1.8734484910964966e-05 Acc: 1.0\n",
      "Epoch 70 of 500 took 0.299s\n",
      "\n",
      "Training complete in 0m 27s\n",
      "Best val loss: 0.000015\n",
      "ACCURACY TEST_0 FINAL : 99.876 %\n",
      "ACCURACY TEST_1 FINAL : 100.000 %\n",
      "CURRENT DATASET :  5\n",
      "(5313, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.6578444076908959 Acc: 0.7894965277777778\n",
      "val Loss: 0.13897528685629368 Acc: 0.953125\n",
      "New best validation loss: 0.13897528685629368\n",
      "Epoch 1 of 500 took 0.307s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.19281621567077106 Acc: 0.9361979166666666\n",
      "val Loss: 0.06865377724170685 Acc: 0.978515625\n",
      "New best validation loss: 0.06865377724170685\n",
      "Epoch 2 of 500 took 0.319s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.1311398690773381 Acc: 0.9539930555555556\n",
      "val Loss: 0.06113454978913069 Acc: 0.982421875\n",
      "New best validation loss: 0.06113454978913069\n",
      "Epoch 3 of 500 took 0.358s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.1370498248272472 Acc: 0.9546440972222222\n",
      "val Loss: 0.06240262370556593 Acc: 0.982421875\n",
      "Epoch 4 of 500 took 0.375s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.10732168538702859 Acc: 0.962890625\n",
      "val Loss: 0.05424086842685938 Acc: 0.98828125\n",
      "New best validation loss: 0.05424086842685938\n",
      "Epoch 5 of 500 took 0.318s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.09487677158580886 Acc: 0.9665798611111112\n",
      "val Loss: 0.047826855443418026 Acc: 0.986328125\n",
      "New best validation loss: 0.047826855443418026\n",
      "Epoch 6 of 500 took 0.307s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.09965384917126761 Acc: 0.9613715277777778\n",
      "val Loss: 0.04436154570430517 Acc: 0.98828125\n",
      "New best validation loss: 0.04436154570430517\n",
      "Epoch 7 of 500 took 0.314s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.08557289631830321 Acc: 0.96875\n",
      "val Loss: 0.04247005470097065 Acc: 0.98828125\n",
      "New best validation loss: 0.04247005470097065\n",
      "Epoch 8 of 500 took 0.311s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.08072181749675009 Acc: 0.9709201388888888\n",
      "val Loss: 0.041188656352460384 Acc: 0.98828125\n",
      "New best validation loss: 0.041188656352460384\n",
      "Epoch 9 of 500 took 0.520s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.07296472063495053 Acc: 0.9737413194444444\n",
      "val Loss: 0.04152911342680454 Acc: 0.98828125\n",
      "Epoch 10 of 500 took 0.393s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.07839086424145433 Acc: 0.9713541666666666\n",
      "val Loss: 0.03818054962903261 Acc: 0.990234375\n",
      "New best validation loss: 0.03818054962903261\n",
      "Epoch 11 of 500 took 0.534s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.07110741155015098 Acc: 0.974609375\n",
      "val Loss: 0.030308383516967297 Acc: 0.990234375\n",
      "New best validation loss: 0.030308383516967297\n",
      "Epoch 12 of 500 took 0.602s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.06342947907331917 Acc: 0.9798177083333334\n",
      "val Loss: 0.027578228153288364 Acc: 0.990234375\n",
      "New best validation loss: 0.027578228153288364\n",
      "Epoch 13 of 500 took 0.486s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.05780674072189464 Acc: 0.9776475694444444\n",
      "val Loss: 0.027205816470086575 Acc: 0.990234375\n",
      "New best validation loss: 0.027205816470086575\n",
      "Epoch 14 of 500 took 0.381s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.05758268510301908 Acc: 0.9800347222222222\n",
      "val Loss: 0.03162808855995536 Acc: 0.990234375\n",
      "Epoch 15 of 500 took 0.459s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.05662826386590799 Acc: 0.9782986111111112\n",
      "val Loss: 0.03420265391469002 Acc: 0.98828125\n",
      "Epoch 16 of 500 took 0.378s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.04906423483043909 Acc: 0.9837239583333334\n",
      "val Loss: 0.02434175554662943 Acc: 0.9921875\n",
      "New best validation loss: 0.02434175554662943\n",
      "Epoch 17 of 500 took 0.389s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.05985247498999039 Acc: 0.9791666666666666\n",
      "val Loss: 0.02723765093833208 Acc: 0.990234375\n",
      "Epoch 18 of 500 took 0.379s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.05964521277281973 Acc: 0.9776475694444444\n",
      "val Loss: 0.028496010694652796 Acc: 0.98828125\n",
      "Epoch 19 of 500 took 0.376s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.05360573592285315 Acc: 0.9809027777777778\n",
      "val Loss: 0.0278805922716856 Acc: 0.990234375\n",
      "Epoch 20 of 500 took 0.392s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.048592007615500026 Acc: 0.9813368055555556\n",
      "val Loss: 0.026277626864612103 Acc: 0.98828125\n",
      "Epoch 21 of 500 took 0.366s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.05414615198969841 Acc: 0.9815538194444444\n",
      "val Loss: 0.02048857184126973 Acc: 0.9921875\n",
      "New best validation loss: 0.02048857184126973\n",
      "Epoch 22 of 500 took 0.385s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.04441081334112419 Acc: 0.984375\n",
      "val Loss: 0.025634380988776684 Acc: 0.98828125\n",
      "Epoch 23 of 500 took 0.372s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.03854456186915437 Acc: 0.9861111111111112\n",
      "val Loss: 0.021590164862573147 Acc: 0.9921875\n",
      "Epoch 24 of 500 took 0.400s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.04171306515733401 Acc: 0.9854600694444444\n",
      "val Loss: 0.023294860497117043 Acc: 0.990234375\n",
      "Epoch 25 of 500 took 0.377s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.043352475493318506 Acc: 0.9848090277777778\n",
      "val Loss: 0.018019314855337143 Acc: 0.994140625\n",
      "New best validation loss: 0.018019314855337143\n",
      "Epoch 26 of 500 took 0.388s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.040902624631093606 Acc: 0.9861111111111112\n",
      "val Loss: 0.02789351809769869 Acc: 0.986328125\n",
      "Epoch 27 of 500 took 0.374s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.04356849348793427 Acc: 0.9850260416666666\n",
      "val Loss: 0.01936667412519455 Acc: 0.990234375\n",
      "Epoch 28 of 500 took 0.426s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.03542071208357811 Acc: 0.9867621527777778\n",
      "val Loss: 0.01489551505073905 Acc: 0.994140625\n",
      "New best validation loss: 0.01489551505073905\n",
      "Epoch 29 of 500 took 0.376s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.02687871844197313 Acc: 0.9906684027777778\n",
      "val Loss: 0.020897801965475082 Acc: 0.990234375\n",
      "Epoch 30 of 500 took 0.376s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.03195318817678425 Acc: 0.9887152777777778\n",
      "val Loss: 0.014522908255457878 Acc: 0.99609375\n",
      "New best validation loss: 0.014522908255457878\n",
      "Epoch 31 of 500 took 0.370s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.02663788256338901 Acc: 0.9913194444444444\n",
      "val Loss: 0.009546231478452682 Acc: 0.99609375\n",
      "New best validation loss: 0.009546231478452682\n",
      "Epoch 32 of 500 took 0.378s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0378776386173235 Acc: 0.9874131944444444\n",
      "val Loss: 0.013625551480799913 Acc: 0.994140625\n",
      "Epoch 33 of 500 took 0.437s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.03422459333928095 Acc: 0.9884982638888888\n",
      "val Loss: 0.015091718174517155 Acc: 0.994140625\n",
      "Epoch 34 of 500 took 0.374s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.034096305827713676 Acc: 0.9878472222222222\n",
      "val Loss: 0.02171863429248333 Acc: 0.98828125\n",
      "Epoch 35 of 500 took 0.372s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.03484556353133586 Acc: 0.9895833333333334\n",
      "val Loss: 0.021499960217624903 Acc: 0.9921875\n",
      "Epoch 36 of 500 took 0.378s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.032171106742074095 Acc: 0.9884982638888888\n",
      "val Loss: 0.011589671019464731 Acc: 0.998046875\n",
      "Epoch 37 of 500 took 0.368s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.02860697627895408 Acc: 0.9893663194444444\n",
      "val Loss: 0.011467525735497475 Acc: 0.998046875\n",
      "Epoch    38: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 38 of 500 took 0.475s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.022552252954079047 Acc: 0.9926215277777778\n",
      "val Loss: 0.011974794790148735 Acc: 0.998046875\n",
      "Epoch 39 of 500 took 0.380s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.019266036959985893 Acc: 0.9943576388888888\n",
      "val Loss: 0.012103775050491095 Acc: 0.99609375\n",
      "Epoch 40 of 500 took 0.376s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.020784476668470435 Acc: 0.9934895833333334\n",
      "val Loss: 0.01648155553266406 Acc: 0.990234375\n",
      "Epoch 41 of 500 took 0.396s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.01761321330236064 Acc: 0.9939236111111112\n",
      "val Loss: 0.012880626134574413 Acc: 0.99609375\n",
      "Epoch 42 of 500 took 0.377s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.017254227461914223 Acc: 0.9939236111111112\n",
      "val Loss: 0.013957572169601917 Acc: 0.994140625\n",
      "Epoch 43 of 500 took 0.365s\n",
      "\n",
      "Training complete in 0m 17s\n",
      "Best val loss: 0.009546\n",
      "ACCURACY TEST_0 FINAL : 98.759 %\n",
      "ACCURACY TEST_1 FINAL : 93.583 %\n",
      "CURRENT DATASET :  6\n",
      "(5311, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.7202131549517313 Acc: 0.771484375\n",
      "val Loss: 0.06885759718716145 Acc: 0.970703125\n",
      "New best validation loss: 0.06885759718716145\n",
      "Epoch 1 of 500 took 0.364s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.1589712496432993 Acc: 0.943359375\n",
      "val Loss: 0.022711435332894325 Acc: 0.99609375\n",
      "New best validation loss: 0.022711435332894325\n",
      "Epoch 2 of 500 took 0.359s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.10218217886156505 Acc: 0.9661458333333334\n",
      "val Loss: 0.04235351271927357 Acc: 0.98828125\n",
      "Epoch 3 of 500 took 0.567s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.08218430665632089 Acc: 0.9713541666666666\n",
      "val Loss: 0.01466748584061861 Acc: 0.99609375\n",
      "New best validation loss: 0.01466748584061861\n",
      "Epoch 4 of 500 took 0.392s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.0668177908907334 Acc: 0.9761284722222222\n",
      "val Loss: 0.02170779276639223 Acc: 0.9921875\n",
      "Epoch 5 of 500 took 0.638s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.05937993422978454 Acc: 0.9793836805555556\n",
      "val Loss: 0.014471665024757385 Acc: 0.994140625\n",
      "New best validation loss: 0.014471665024757385\n",
      "Epoch 6 of 500 took 0.633s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.060095783012608685 Acc: 0.9793836805555556\n",
      "val Loss: 0.011697676964104176 Acc: 0.99609375\n",
      "New best validation loss: 0.011697676964104176\n",
      "Epoch 7 of 500 took 0.371s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.04882071622543865 Acc: 0.9817708333333334\n",
      "val Loss: 0.0104221785441041 Acc: 0.99609375\n",
      "New best validation loss: 0.0104221785441041\n",
      "Epoch 8 of 500 took 0.370s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.0449102469202545 Acc: 0.9845920138888888\n",
      "val Loss: 0.009202085435390472 Acc: 0.99609375\n",
      "New best validation loss: 0.009202085435390472\n",
      "Epoch 9 of 500 took 0.377s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.04258592571649286 Acc: 0.984375\n",
      "val Loss: 0.010236795991659164 Acc: 0.99609375\n",
      "Epoch 10 of 500 took 0.375s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.04397291017489301 Acc: 0.9848090277777778\n",
      "val Loss: 0.016510987654328346 Acc: 0.994140625\n",
      "Epoch 11 of 500 took 0.376s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.029175162315368652 Acc: 0.9908854166666666\n",
      "val Loss: 0.018234385177493095 Acc: 0.9921875\n",
      "Epoch 12 of 500 took 0.436s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.03044014134340816 Acc: 0.9904513888888888\n",
      "val Loss: 0.03488971758633852 Acc: 0.982421875\n",
      "Epoch 13 of 500 took 0.380s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.033265587149394885 Acc: 0.9880642361111112\n",
      "val Loss: 0.02717243880033493 Acc: 0.982421875\n",
      "Epoch 14 of 500 took 0.368s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.03445603708840079 Acc: 0.9878472222222222\n",
      "val Loss: 0.022939862683415413 Acc: 0.986328125\n",
      "Epoch    15: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 15 of 500 took 0.384s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.022414181588424578 Acc: 0.9924045138888888\n",
      "val Loss: 0.006653782911598682 Acc: 0.998046875\n",
      "New best validation loss: 0.006653782911598682\n",
      "Epoch 16 of 500 took 0.380s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.023195863080521423 Acc: 0.9913194444444444\n",
      "val Loss: 0.01693595014512539 Acc: 0.9921875\n",
      "Epoch 17 of 500 took 0.372s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.027671685649289027 Acc: 0.9906684027777778\n",
      "val Loss: 0.010379636660218239 Acc: 0.99609375\n",
      "Epoch 18 of 500 took 0.385s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.017355059997902975 Acc: 0.9934895833333334\n",
      "val Loss: 0.008115419186651707 Acc: 0.998046875\n",
      "Epoch 19 of 500 took 0.369s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.023547607680989638 Acc: 0.9913194444444444\n",
      "val Loss: 0.01118286419659853 Acc: 0.994140625\n",
      "Epoch 20 of 500 took 0.383s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.02185763930901885 Acc: 0.9926215277777778\n",
      "val Loss: 0.00877534318715334 Acc: 0.99609375\n",
      "Epoch 21 of 500 took 0.385s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.022085344781064324 Acc: 0.9915364583333334\n",
      "val Loss: 0.008325842209160328 Acc: 0.99609375\n",
      "Epoch    22: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 22 of 500 took 0.367s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.01784730480156011 Acc: 0.994140625\n",
      "val Loss: 0.007893770933151245 Acc: 0.99609375\n",
      "Epoch 23 of 500 took 0.419s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.019377724940164223 Acc: 0.9930555555555556\n",
      "val Loss: 0.009161192923784256 Acc: 0.994140625\n",
      "Epoch 24 of 500 took 0.384s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.01437289376432697 Acc: 0.9952256944444444\n",
      "val Loss: 0.009598474949598312 Acc: 0.99609375\n",
      "Epoch 25 of 500 took 0.364s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.01465956297599607 Acc: 0.9952256944444444\n",
      "val Loss: 0.01190304383635521 Acc: 0.994140625\n",
      "Epoch 26 of 500 took 0.388s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.01825096096015639 Acc: 0.9939236111111112\n",
      "val Loss: 0.01155475527048111 Acc: 0.994140625\n",
      "Epoch 27 of 500 took 0.383s\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val loss: 0.006654\n",
      "ACCURACY TEST_0 FINAL : 99.194 %\n",
      "ACCURACY TEST_1 FINAL : 100.000 %\n",
      "CURRENT DATASET :  7\n",
      "(5305, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.4750208862953716 Acc: 0.8513454861111112\n",
      "val Loss: 0.00918596563860774 Acc: 0.99609375\n",
      "New best validation loss: 0.00918596563860774\n",
      "Epoch 1 of 500 took 0.331s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.036177447272671595 Acc: 0.9869791666666666\n",
      "val Loss: 0.002574121579527855 Acc: 1.0\n",
      "New best validation loss: 0.002574121579527855\n",
      "Epoch 2 of 500 took 0.293s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.021414182769755524 Acc: 0.9928385416666666\n",
      "val Loss: 0.0024931365624070168 Acc: 1.0\n",
      "New best validation loss: 0.0024931365624070168\n",
      "Epoch 3 of 500 took 0.287s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.01738886447209451 Acc: 0.9952256944444444\n",
      "val Loss: 0.0047378819435834885 Acc: 1.0\n",
      "Epoch 4 of 500 took 0.296s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.01199742623915275 Acc: 0.9969618055555556\n",
      "val Loss: 0.003051210194826126 Acc: 1.0\n",
      "Epoch 5 of 500 took 0.295s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.014007145331965553 Acc: 0.9965277777777778\n",
      "val Loss: 0.0016738073900341988 Acc: 1.0\n",
      "New best validation loss: 0.0016738073900341988\n",
      "Epoch 6 of 500 took 0.290s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.012659905944019556 Acc: 0.99609375\n",
      "val Loss: 0.0032260529696941376 Acc: 1.0\n",
      "Epoch 7 of 500 took 0.376s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.010384621512558725 Acc: 0.9967447916666666\n",
      "val Loss: 0.0011733444407582283 Acc: 1.0\n",
      "New best validation loss: 0.0011733444407582283\n",
      "Epoch 8 of 500 took 0.361s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.009393477139787542 Acc: 0.9971788194444444\n",
      "val Loss: 0.001291726715862751 Acc: 1.0\n",
      "Epoch 9 of 500 took 0.418s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.0103384620613522 Acc: 0.9969618055555556\n",
      "val Loss: 0.001462082378566265 Acc: 1.0\n",
      "Epoch 10 of 500 took 0.361s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.006448955482078923 Acc: 0.9978298611111112\n",
      "val Loss: 0.0030317651107907295 Acc: 1.0\n",
      "Epoch 11 of 500 took 0.364s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.007331174487868945 Acc: 0.9976128472222222\n",
      "val Loss: 0.0013770954683423042 Acc: 1.0\n",
      "Epoch 12 of 500 took 0.364s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.007207473222580221 Acc: 0.9969618055555556\n",
      "val Loss: 0.00019779056310653687 Acc: 1.0\n",
      "New best validation loss: 0.00019779056310653687\n",
      "Epoch 13 of 500 took 0.365s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00713359404148327 Acc: 0.9982638888888888\n",
      "val Loss: 0.004395500756800175 Acc: 0.998046875\n",
      "Epoch 14 of 500 took 0.427s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.004138156978620423 Acc: 0.9989149305555556\n",
      "val Loss: 0.000571124255657196 Acc: 1.0\n",
      "Epoch 15 of 500 took 0.394s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.0033582207850284046 Acc: 0.9997829861111112\n",
      "val Loss: 0.0004188939929008484 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.483s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.0040982516172031564 Acc: 0.9989149305555556\n",
      "val Loss: 0.0015609469264745712 Acc: 1.0\n",
      "Epoch 17 of 500 took 0.493s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.004623619166927205 Acc: 0.9986979166666666\n",
      "val Loss: 0.00028782710433006287 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.488s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.004070317010498709 Acc: 0.9989149305555556\n",
      "val Loss: 0.00013278424739837646 Acc: 1.0\n",
      "New best validation loss: 0.00013278424739837646\n",
      "Epoch 19 of 500 took 0.301s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.006394403210530679 Acc: 0.9978298611111112\n",
      "val Loss: 0.0004514455795288086 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.324s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.003682471035669247 Acc: 0.9989149305555556\n",
      "val Loss: 0.0009088516235351562 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.307s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.0035979394387039873 Acc: 0.9986979166666666\n",
      "val Loss: 0.00027454085648059845 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.333s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.003992344045804607 Acc: 0.9986979166666666\n",
      "val Loss: 0.0017055431380867958 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.353s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.006004260335531499 Acc: 0.998046875\n",
      "val Loss: 0.00039364490658044815 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.294s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.003834288619044754 Acc: 0.9991319444444444\n",
      "val Loss: 0.00012037437409162521 Acc: 1.0\n",
      "New best validation loss: 0.00012037437409162521\n",
      "Epoch 25 of 500 took 0.291s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.0031204415588743156 Acc: 0.9995659722222222\n",
      "val Loss: 0.00024018436670303345 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.294s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.004003564827144146 Acc: 0.9989149305555556\n",
      "val Loss: 0.00023759622126817703 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.325s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.002911045759295424 Acc: 0.9993489583333334\n",
      "val Loss: 0.0003098323941230774 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.296s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.0030643889783985084 Acc: 0.9993489583333334\n",
      "val Loss: 0.00011150632053613663 Acc: 1.0\n",
      "New best validation loss: 0.00011150632053613663\n",
      "Epoch 29 of 500 took 0.302s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.002202218553672234 Acc: 0.9997829861111112\n",
      "val Loss: 9.042862802743912e-05 Acc: 1.0\n",
      "New best validation loss: 9.042862802743912e-05\n",
      "Epoch 30 of 500 took 0.311s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.002548267443974813 Acc: 0.9993489583333334\n",
      "val Loss: 0.0017804326489567757 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.358s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.0029334010970261362 Acc: 0.9991319444444444\n",
      "val Loss: 0.00013250112533569336 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.315s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00272620583160056 Acc: 0.9991319444444444\n",
      "val Loss: 0.0003774398937821388 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.367s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.002697165020638042 Acc: 0.9991319444444444\n",
      "val Loss: 0.0002464205026626587 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.361s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.0015883323633008534 Acc: 0.9997829861111112\n",
      "val Loss: 0.0002869758754968643 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.378s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0038860964899261794 Acc: 0.9986979166666666\n",
      "val Loss: 0.0006412863731384277 Acc: 1.0\n",
      "Epoch    36: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 36 of 500 took 0.312s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.001850616962959369 Acc: 0.9993489583333334\n",
      "val Loss: 0.00032177288085222244 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.279s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.0010085832845005724 Acc: 1.0\n",
      "val Loss: 0.00043743662536144257 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.305s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.0016857535681790775 Acc: 0.9993489583333334\n",
      "val Loss: 0.0005212333053350449 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.287s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.0014619517347051038 Acc: 0.9995659722222222\n",
      "val Loss: 0.0005558393895626068 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.277s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0016184088567064868 Acc: 0.9997829861111112\n",
      "val Loss: 0.00030236318707466125 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.277s\n",
      "\n",
      "Training complete in 0m 14s\n",
      "Best val loss: 0.000090\n",
      "ACCURACY TEST_0 FINAL : 100.000 %\n",
      "ACCURACY TEST_1 FINAL : 100.000 %\n",
      "CURRENT DATASET :  8\n",
      "(5314, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.42146766723857987 Acc: 0.8684895833333334\n",
      "val Loss: 0.007006760686635971 Acc: 0.998046875\n",
      "New best validation loss: 0.007006760686635971\n",
      "Epoch 1 of 500 took 0.314s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.03651438456856542 Acc: 0.9871961805555556\n",
      "val Loss: 0.0019640428945422173 Acc: 1.0\n",
      "New best validation loss: 0.0019640428945422173\n",
      "Epoch 2 of 500 took 0.310s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.024235329280296963 Acc: 0.9934895833333334\n",
      "val Loss: 0.0035821013152599335 Acc: 1.0\n",
      "Epoch 3 of 500 took 0.298s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.013167374767363071 Acc: 0.9952256944444444\n",
      "val Loss: 0.00133480504155159 Acc: 1.0\n",
      "New best validation loss: 0.00133480504155159\n",
      "Epoch 4 of 500 took 0.316s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.011624105895558992 Acc: 0.9971788194444444\n",
      "val Loss: 0.0009444011375308037 Acc: 1.0\n",
      "New best validation loss: 0.0009444011375308037\n",
      "Epoch 5 of 500 took 0.312s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.011906460651920902 Acc: 0.9952256944444444\n",
      "val Loss: 0.001230308786034584 Acc: 1.0\n",
      "Epoch 6 of 500 took 0.307s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.010974175917605558 Acc: 0.9973958333333334\n",
      "val Loss: 0.0007310602813959122 Acc: 1.0\n",
      "New best validation loss: 0.0007310602813959122\n",
      "Epoch 7 of 500 took 0.357s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.008449216218044361 Acc: 0.998046875\n",
      "val Loss: 0.0006886245682835579 Acc: 1.0\n",
      "New best validation loss: 0.0006886245682835579\n",
      "Epoch 8 of 500 took 0.301s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.004889430995616648 Acc: 0.9989149305555556\n",
      "val Loss: 0.0003625033423304558 Acc: 1.0\n",
      "New best validation loss: 0.0003625033423304558\n",
      "Epoch 9 of 500 took 0.296s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.004346760196818246 Acc: 0.9986979166666666\n",
      "val Loss: 0.0003520278260111809 Acc: 1.0\n",
      "New best validation loss: 0.0003520278260111809\n",
      "Epoch 10 of 500 took 0.315s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.0045668284098307295 Acc: 0.9986979166666666\n",
      "val Loss: 0.0003242865204811096 Acc: 1.0\n",
      "New best validation loss: 0.0003242865204811096\n",
      "Epoch 11 of 500 took 0.379s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.005623092874884605 Acc: 0.9982638888888888\n",
      "val Loss: 0.00019109807908535004 Acc: 1.0\n",
      "New best validation loss: 0.00019109807908535004\n",
      "Epoch 12 of 500 took 0.405s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.0045184749695989825 Acc: 0.9986979166666666\n",
      "val Loss: 0.00018241535872220993 Acc: 1.0\n",
      "New best validation loss: 0.00018241535872220993\n",
      "Epoch 13 of 500 took 0.380s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00483362037791974 Acc: 0.9984809027777778\n",
      "val Loss: 0.00016076117753982544 Acc: 1.0\n",
      "New best validation loss: 0.00016076117753982544\n",
      "Epoch 14 of 500 took 0.316s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.0047622449282142855 Acc: 0.998046875\n",
      "val Loss: 0.0003288956359028816 Acc: 1.0\n",
      "Epoch 15 of 500 took 0.293s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.005309732579108741 Acc: 0.9978298611111112\n",
      "val Loss: 0.0001074494794011116 Acc: 1.0\n",
      "New best validation loss: 0.0001074494794011116\n",
      "Epoch 16 of 500 took 0.418s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.004905315943890148 Acc: 0.9984809027777778\n",
      "val Loss: 0.00021753832697868347 Acc: 1.0\n",
      "Epoch 17 of 500 took 0.548s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.0030931116392215094 Acc: 0.9993489583333334\n",
      "val Loss: 0.00012160744518041611 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.355s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.0059756494334174525 Acc: 0.9978298611111112\n",
      "val Loss: 0.00016204267740249634 Acc: 1.0\n",
      "Epoch 19 of 500 took 0.400s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.0038325757616096074 Acc: 0.9986979166666666\n",
      "val Loss: 5.858577787876129e-05 Acc: 1.0\n",
      "New best validation loss: 5.858577787876129e-05\n",
      "Epoch 20 of 500 took 0.691s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0020497184660699633 Acc: 0.9993489583333334\n",
      "val Loss: 0.00010792259126901627 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.653s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.0036785916632248294 Acc: 0.9984809027777778\n",
      "val Loss: 9.91523265838623e-05 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.467s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.002875771735691362 Acc: 0.9989149305555556\n",
      "val Loss: 0.00014849286526441574 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.428s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.0025677578523755074 Acc: 0.9989149305555556\n",
      "val Loss: 9.132269769906998e-05 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.383s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.001890786923468113 Acc: 0.9995659722222222\n",
      "val Loss: 7.617194205522537e-05 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.311s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.003289409809642368 Acc: 0.9986979166666666\n",
      "val Loss: 9.280070662498474e-05 Acc: 1.0\n",
      "Epoch    26: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 26 of 500 took 0.286s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.002708046076198419 Acc: 0.9989149305555556\n",
      "val Loss: 7.234327495098114e-05 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.349s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.0021641660585171646 Acc: 0.9989149305555556\n",
      "val Loss: 6.953813135623932e-05 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.330s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.0013789642188284132 Acc: 1.0\n",
      "val Loss: 5.441345274448395e-05 Acc: 1.0\n",
      "New best validation loss: 5.441345274448395e-05\n",
      "Epoch 29 of 500 took 0.311s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0021503172918326324 Acc: 0.9995659722222222\n",
      "val Loss: 5.733594298362732e-05 Acc: 1.0\n",
      "Epoch 30 of 500 took 0.360s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.0012820801801151699 Acc: 0.9997829861111112\n",
      "val Loss: 6.008520722389221e-05 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.364s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.0016135288816359309 Acc: 0.9993489583333334\n",
      "val Loss: 5.8805570006370544e-05 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.359s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0017188595504396493 Acc: 0.9997829861111112\n",
      "val Loss: 6.893277168273926e-05 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.474s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.0022940303509434066 Acc: 0.9993489583333334\n",
      "val Loss: 6.112642586231232e-05 Acc: 1.0\n",
      "Epoch 34 of 500 took 0.359s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.002316941765861379 Acc: 0.9993489583333334\n",
      "val Loss: 7.400847971439362e-05 Acc: 1.0\n",
      "Epoch    35: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 35 of 500 took 0.435s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0015184499530328645 Acc: 0.9997829861111112\n",
      "val Loss: 6.534717977046967e-05 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.364s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.001586935172478358 Acc: 0.9997829861111112\n",
      "val Loss: 6.535835564136505e-05 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.358s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.0011246178506149186 Acc: 1.0\n",
      "val Loss: 5.5616721510887146e-05 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.392s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.0025526073036922347 Acc: 0.9991319444444444\n",
      "val Loss: 4.9659982323646545e-05 Acc: 1.0\n",
      "New best validation loss: 4.9659982323646545e-05\n",
      "Epoch 39 of 500 took 0.353s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.0011874392835630311 Acc: 0.9997829861111112\n",
      "val Loss: 5.700811743736267e-05 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.370s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0014414073795908028 Acc: 0.9995659722222222\n",
      "val Loss: 4.486739635467529e-05 Acc: 1.0\n",
      "New best validation loss: 4.486739635467529e-05\n",
      "Epoch 41 of 500 took 0.377s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.001350947397036685 Acc: 0.9997829861111112\n",
      "val Loss: 4.9876049160957336e-05 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.355s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.0026518760973380674 Acc: 0.9993489583333334\n",
      "val Loss: 3.8256868720054626e-05 Acc: 1.0\n",
      "New best validation loss: 3.8256868720054626e-05\n",
      "Epoch 43 of 500 took 0.363s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0021178314669264686 Acc: 0.9991319444444444\n",
      "val Loss: 3.927759826183319e-05 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.358s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.0010523921292689112 Acc: 0.9997829861111112\n",
      "val Loss: 4.136376082897186e-05 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.384s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0013435228417317073 Acc: 0.9997829861111112\n",
      "val Loss: 4.215911030769348e-05 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.356s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0015028745142949952 Acc: 0.9991319444444444\n",
      "val Loss: 3.773905336856842e-05 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.352s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.0012963417296608288 Acc: 0.9995659722222222\n",
      "val Loss: 4.108622670173645e-05 Acc: 1.0\n",
      "Epoch 48 of 500 took 0.360s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.001823552366760042 Acc: 0.9995659722222222\n",
      "val Loss: 3.452040255069733e-05 Acc: 1.0\n",
      "New best validation loss: 3.452040255069733e-05\n",
      "Epoch 49 of 500 took 0.372s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.0021061098927425016 Acc: 0.9995659722222222\n",
      "val Loss: 4.163570702075958e-05 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.368s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.0012128698743051952 Acc: 0.9997829861111112\n",
      "val Loss: 4.198402166366577e-05 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.390s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0011812415387895373 Acc: 1.0\n",
      "val Loss: 3.878399729728699e-05 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.353s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0016492048485411538 Acc: 0.9993489583333334\n",
      "val Loss: 4.330836236476898e-05 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.348s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0014904432723091708 Acc: 0.9993489583333334\n",
      "val Loss: 4.4947490096092224e-05 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.369s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.001542588902844323 Acc: 0.9995659722222222\n",
      "val Loss: 3.944896161556244e-05 Acc: 1.0\n",
      "Epoch    55: reducing learning rate of group 0 to 1.8686e-05.\n",
      "Epoch 55 of 500 took 0.508s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0016145123582747248 Acc: 0.9995659722222222\n",
      "val Loss: 4.5843422412872314e-05 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.496s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0009497550005714098 Acc: 1.0\n",
      "val Loss: 4.0762126445770264e-05 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.405s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.0018852203049593503 Acc: 0.9995659722222222\n",
      "val Loss: 4.096515476703644e-05 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.719s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0018177744932472706 Acc: 0.9993489583333334\n",
      "val Loss: 4.320964217185974e-05 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.596s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0016754850124319394 Acc: 0.9993489583333334\n",
      "val Loss: 4.800036549568176e-05 Acc: 1.0\n",
      "Epoch 60 of 500 took 0.366s\n",
      "\n",
      "Training complete in 0m 23s\n",
      "Best val loss: 0.000035\n",
      "ACCURACY TEST_0 FINAL : 99.969 %\n",
      "ACCURACY TEST_1 FINAL : 99.845 %\n",
      "CURRENT DATASET :  9\n",
      "(5313, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.4250187944206927 Acc: 0.8604600694444444\n",
      "val Loss: 0.0241253599524498 Acc: 0.994140625\n",
      "New best validation loss: 0.0241253599524498\n",
      "Epoch 1 of 500 took 0.396s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.0760223190817568 Acc: 0.9715711805555556\n",
      "val Loss: 0.01182815432548523 Acc: 0.998046875\n",
      "New best validation loss: 0.01182815432548523\n",
      "Epoch 2 of 500 took 0.426s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.06403456887023316 Acc: 0.9767795138888888\n",
      "val Loss: 0.005812064744532108 Acc: 1.0\n",
      "New best validation loss: 0.005812064744532108\n",
      "Epoch 3 of 500 took 0.382s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.04430772643536329 Acc: 0.9835069444444444\n",
      "val Loss: 0.004692866466939449 Acc: 1.0\n",
      "New best validation loss: 0.004692866466939449\n",
      "Epoch 4 of 500 took 0.382s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.036099407304492265 Acc: 0.9869791666666666\n",
      "val Loss: 0.004494752734899521 Acc: 1.0\n",
      "New best validation loss: 0.004494752734899521\n",
      "Epoch 5 of 500 took 0.388s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.0341113857511017 Acc: 0.9871961805555556\n",
      "val Loss: 0.006344323046505451 Acc: 1.0\n",
      "Epoch 6 of 500 took 0.375s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.03087372187938955 Acc: 0.9876302083333334\n",
      "val Loss: 0.002612786367535591 Acc: 1.0\n",
      "New best validation loss: 0.002612786367535591\n",
      "Epoch 7 of 500 took 0.389s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.02411521619392766 Acc: 0.9913194444444444\n",
      "val Loss: 0.0015519363805651665 Acc: 1.0\n",
      "New best validation loss: 0.0015519363805651665\n",
      "Epoch 8 of 500 took 0.378s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.020909387514823012 Acc: 0.9934895833333334\n",
      "val Loss: 0.0015202043578028679 Acc: 1.0\n",
      "New best validation loss: 0.0015202043578028679\n",
      "Epoch 9 of 500 took 0.387s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.025513855481727257 Acc: 0.990234375\n",
      "val Loss: 0.004983747377991676 Acc: 0.998046875\n",
      "Epoch 10 of 500 took 0.359s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.02196603309777048 Acc: 0.9915364583333334\n",
      "val Loss: 0.0012634461745619774 Acc: 1.0\n",
      "New best validation loss: 0.0012634461745619774\n",
      "Epoch 11 of 500 took 0.403s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.019848442688170407 Acc: 0.9919704861111112\n",
      "val Loss: 0.0009945835918188095 Acc: 1.0\n",
      "New best validation loss: 0.0009945835918188095\n",
      "Epoch 12 of 500 took 0.391s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.015896517214261822 Acc: 0.9956597222222222\n",
      "val Loss: 0.0019462406635284424 Acc: 1.0\n",
      "Epoch 13 of 500 took 0.386s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.01852512726974156 Acc: 0.9937065972222222\n",
      "val Loss: 0.0007955711334943771 Acc: 1.0\n",
      "New best validation loss: 0.0007955711334943771\n",
      "Epoch 14 of 500 took 0.390s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.014558319985452626 Acc: 0.9950086805555556\n",
      "val Loss: 0.0006824973970651627 Acc: 1.0\n",
      "New best validation loss: 0.0006824973970651627\n",
      "Epoch 15 of 500 took 0.412s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.013371210493561294 Acc: 0.9947916666666666\n",
      "val Loss: 0.0012728292495012283 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.377s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.0143862991179857 Acc: 0.9945746527777778\n",
      "val Loss: 0.000483502633869648 Acc: 1.0\n",
      "New best validation loss: 0.000483502633869648\n",
      "Epoch 17 of 500 took 0.379s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.015972298259536426 Acc: 0.9947916666666666\n",
      "val Loss: 0.00031255651265382767 Acc: 1.0\n",
      "New best validation loss: 0.00031255651265382767\n",
      "Epoch 18 of 500 took 0.404s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.010704939615809254 Acc: 0.99609375\n",
      "val Loss: 0.00038553494960069656 Acc: 1.0\n",
      "Epoch 19 of 500 took 0.377s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.013036175993167691 Acc: 0.9956597222222222\n",
      "val Loss: 0.0010126829147338867 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.422s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.010272871444208754 Acc: 0.9956597222222222\n",
      "val Loss: 0.0011146478354930878 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.291s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.010458183267878162 Acc: 0.9958767361111112\n",
      "val Loss: 0.0003600809723138809 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.345s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.011232948448095057 Acc: 0.99609375\n",
      "val Loss: 0.0003519318997859955 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.457s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.011499225161969662 Acc: 0.9965277777777778\n",
      "val Loss: 0.0002766931429505348 Acc: 1.0\n",
      "New best validation loss: 0.0002766931429505348\n",
      "Epoch 24 of 500 took 0.384s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.010008173839499554 Acc: 0.9976128472222222\n",
      "val Loss: 0.0004542814567685127 Acc: 1.0\n",
      "Epoch 25 of 500 took 0.390s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.011181938875880506 Acc: 0.9947916666666666\n",
      "val Loss: 0.00029646605253219604 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.386s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.0051798537994424505 Acc: 0.9984809027777778\n",
      "val Loss: 0.00022535677999258041 Acc: 1.0\n",
      "New best validation loss: 0.00022535677999258041\n",
      "Epoch 27 of 500 took 0.387s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.007066359277814627 Acc: 0.9973958333333334\n",
      "val Loss: 0.00019401684403419495 Acc: 1.0\n",
      "New best validation loss: 0.00019401684403419495\n",
      "Epoch 28 of 500 took 0.426s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.008370532964666685 Acc: 0.9965277777777778\n",
      "val Loss: 0.00021134130656719208 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.367s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.007387041062530544 Acc: 0.9971788194444444\n",
      "val Loss: 0.00022625084966421127 Acc: 1.0\n",
      "Epoch 30 of 500 took 0.384s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.007513319090422656 Acc: 0.9971788194444444\n",
      "val Loss: 0.0002405848354101181 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.495s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.01022086116588778 Acc: 0.9965277777777778\n",
      "val Loss: 0.0004975330084562302 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.451s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.006755871543039878 Acc: 0.9978298611111112\n",
      "val Loss: 0.00020358338952064514 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.525s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.010350201537625657 Acc: 0.9956597222222222\n",
      "val Loss: 0.00045271124690771103 Acc: 1.0\n",
      "Epoch    34: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 34 of 500 took 0.662s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00553397461771965 Acc: 0.9984809027777778\n",
      "val Loss: 0.00020164437592029572 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.507s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0070253837750189835 Acc: 0.9976128472222222\n",
      "val Loss: 0.00017398223280906677 Acc: 1.0\n",
      "New best validation loss: 0.00017398223280906677\n",
      "Epoch 36 of 500 took 0.379s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.005647789686918259 Acc: 0.9984809027777778\n",
      "val Loss: 0.0001432504504919052 Acc: 1.0\n",
      "New best validation loss: 0.0001432504504919052\n",
      "Epoch 37 of 500 took 0.379s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.005538833224111133 Acc: 0.9986979166666666\n",
      "val Loss: 0.0001817941665649414 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.372s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.004678220177690188 Acc: 0.998046875\n",
      "val Loss: 0.00021087005734443665 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.396s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.006784949606905381 Acc: 0.9971788194444444\n",
      "val Loss: 0.00020108744502067566 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.372s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.005874756827122635 Acc: 0.9982638888888888\n",
      "val Loss: 0.00015342235565185547 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.378s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.0031943717557522985 Acc: 0.9993489583333334\n",
      "val Loss: 0.00014896318316459656 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.302s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.006212217112382253 Acc: 0.9976128472222222\n",
      "val Loss: 0.00013737287372350693 Acc: 1.0\n",
      "New best validation loss: 0.00013737287372350693\n",
      "Epoch 43 of 500 took 0.304s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.004238214395526383 Acc: 0.9984809027777778\n",
      "val Loss: 0.00012776721268892288 Acc: 1.0\n",
      "New best validation loss: 0.00012776721268892288\n",
      "Epoch 44 of 500 took 0.372s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.004624278439829747 Acc: 0.9982638888888888\n",
      "val Loss: 0.00013130251318216324 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.386s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.005253413536896308 Acc: 0.9982638888888888\n",
      "val Loss: 0.00010826997458934784 Acc: 1.0\n",
      "New best validation loss: 0.00010826997458934784\n",
      "Epoch 46 of 500 took 0.372s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.004800238957007726 Acc: 0.9986979166666666\n",
      "val Loss: 0.00010530836880207062 Acc: 1.0\n",
      "New best validation loss: 0.00010530836880207062\n",
      "Epoch 47 of 500 took 0.652s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.003467261894709534 Acc: 0.9984809027777778\n",
      "val Loss: 0.00010355189442634583 Acc: 1.0\n",
      "New best validation loss: 0.00010355189442634583\n",
      "Epoch 48 of 500 took 0.377s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.003969151837130387 Acc: 0.9984809027777778\n",
      "val Loss: 9.812135249376297e-05 Acc: 1.0\n",
      "New best validation loss: 9.812135249376297e-05\n",
      "Epoch 49 of 500 took 0.380s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.002828391268849373 Acc: 0.9991319444444444\n",
      "val Loss: 0.00011461973190307617 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.370s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.004451352740741438 Acc: 0.9989149305555556\n",
      "val Loss: 0.00012384634464979172 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.360s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0033998341403073734 Acc: 0.9991319444444444\n",
      "val Loss: 9.64682549238205e-05 Acc: 1.0\n",
      "New best validation loss: 9.64682549238205e-05\n",
      "Epoch 52 of 500 took 0.351s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.004793192363447613 Acc: 0.998046875\n",
      "val Loss: 9.743496775627136e-05 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.364s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.002326727948255009 Acc: 0.9997829861111112\n",
      "val Loss: 0.00010050460696220398 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.371s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.005448336454315318 Acc: 0.9982638888888888\n",
      "val Loss: 0.00011831987649202347 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.376s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.004732054658234119 Acc: 0.9982638888888888\n",
      "val Loss: 8.258223533630371e-05 Acc: 1.0\n",
      "New best validation loss: 8.258223533630371e-05\n",
      "Epoch 56 of 500 took 0.371s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0031727166432473394 Acc: 0.9989149305555556\n",
      "val Loss: 8.334405720233917e-05 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.408s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.00296880304813385 Acc: 0.9986979166666666\n",
      "val Loss: 8.471589535474777e-05 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.373s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.005396233975059456 Acc: 0.9982638888888888\n",
      "val Loss: 8.158758282661438e-05 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.361s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0026906182368596396 Acc: 0.9993489583333334\n",
      "val Loss: 7.319450378417969e-05 Acc: 1.0\n",
      "New best validation loss: 7.319450378417969e-05\n",
      "Epoch 60 of 500 took 0.364s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.0034420184998048674 Acc: 0.9986979166666666\n",
      "val Loss: 0.00010339543223381042 Acc: 1.0\n",
      "Epoch 61 of 500 took 0.376s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.003397050727572706 Acc: 0.9986979166666666\n",
      "val Loss: 7.52229243516922e-05 Acc: 1.0\n",
      "Epoch 62 of 500 took 0.373s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.0027134292241599825 Acc: 0.9995659722222222\n",
      "val Loss: 7.170252501964569e-05 Acc: 1.0\n",
      "New best validation loss: 7.170252501964569e-05\n",
      "Epoch 63 of 500 took 0.363s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.0026639199091328513 Acc: 0.9993489583333334\n",
      "val Loss: 5.9060752391815186e-05 Acc: 1.0\n",
      "New best validation loss: 5.9060752391815186e-05\n",
      "Epoch 64 of 500 took 0.354s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.005056070267326302 Acc: 0.998046875\n",
      "val Loss: 5.504116415977478e-05 Acc: 1.0\n",
      "New best validation loss: 5.504116415977478e-05\n",
      "Epoch 65 of 500 took 0.373s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.0018085235108931859 Acc: 0.9997829861111112\n",
      "val Loss: 6.900262087583542e-05 Acc: 1.0\n",
      "Epoch 66 of 500 took 0.400s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.004309573831657569 Acc: 0.9984809027777778\n",
      "val Loss: 8.474569767713547e-05 Acc: 1.0\n",
      "Epoch 67 of 500 took 0.386s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.002990465404258834 Acc: 0.9989149305555556\n",
      "val Loss: 0.00013710185885429382 Acc: 1.0\n",
      "Epoch 68 of 500 took 0.341s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0032833622147639594 Acc: 0.9984809027777778\n",
      "val Loss: 0.00011311471462249756 Acc: 1.0\n",
      "Epoch 69 of 500 took 0.441s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.003440392617550161 Acc: 0.9986979166666666\n",
      "val Loss: 7.482152432203293e-05 Acc: 1.0\n",
      "Epoch 70 of 500 took 0.389s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.0034792054858472613 Acc: 0.9991319444444444\n",
      "val Loss: 7.011648267507553e-05 Acc: 1.0\n",
      "Epoch    71: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 71 of 500 took 0.503s\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.0036795101025038296 Acc: 0.9989149305555556\n",
      "val Loss: 7.486622780561447e-05 Acc: 1.0\n",
      "Epoch 72 of 500 took 0.607s\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.002923453433646096 Acc: 0.9986979166666666\n",
      "val Loss: 7.346272468566895e-05 Acc: 1.0\n",
      "Epoch 73 of 500 took 0.482s\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.0029732508377896417 Acc: 0.9991319444444444\n",
      "val Loss: 6.579514592885971e-05 Acc: 1.0\n",
      "Epoch 74 of 500 took 0.290s\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.0031773456268840367 Acc: 0.9995659722222222\n",
      "val Loss: 6.649177521467209e-05 Acc: 1.0\n",
      "Epoch 75 of 500 took 0.282s\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.004465803193549315 Acc: 0.9989149305555556\n",
      "val Loss: 7.04033300280571e-05 Acc: 1.0\n",
      "Epoch 76 of 500 took 0.281s\n",
      "\n",
      "Training complete in 0m 30s\n",
      "Best val loss: 0.000055\n",
      "ACCURACY TEST_0 FINAL : 99.194 %\n",
      "ACCURACY TEST_1 FINAL : 99.876 %\n",
      "CURRENT DATASET :  10\n",
      "(5308, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5987355675962236 Acc: 0.8157552083333334\n",
      "val Loss: 0.08921594824641943 Acc: 0.96875\n",
      "New best validation loss: 0.08921594824641943\n",
      "Epoch 1 of 500 took 0.299s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.1339077330711815 Acc: 0.9526909722222222\n",
      "val Loss: 0.0688542602583766 Acc: 0.982421875\n",
      "New best validation loss: 0.0688542602583766\n",
      "Epoch 2 of 500 took 0.351s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.09319053983522786 Acc: 0.9698350694444444\n",
      "val Loss: 0.0630919449031353 Acc: 0.984375\n",
      "New best validation loss: 0.0630919449031353\n",
      "Epoch 3 of 500 took 0.282s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.0810103817946381 Acc: 0.9694010416666666\n",
      "val Loss: 0.07224013470113277 Acc: 0.982421875\n",
      "Epoch 4 of 500 took 0.305s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.076044878611962 Acc: 0.9756944444444444\n",
      "val Loss: 0.06594479130581021 Acc: 0.982421875\n",
      "Epoch 5 of 500 took 0.293s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.07239425492783387 Acc: 0.9776475694444444\n",
      "val Loss: 0.06001078383997083 Acc: 0.982421875\n",
      "New best validation loss: 0.06001078383997083\n",
      "Epoch 6 of 500 took 0.298s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.06881566842397054 Acc: 0.9763454861111112\n",
      "val Loss: 0.06308545544743538 Acc: 0.982421875\n",
      "Epoch 7 of 500 took 0.314s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.058101649292641215 Acc: 0.9819878472222222\n",
      "val Loss: 0.04069611057639122 Acc: 0.986328125\n",
      "New best validation loss: 0.04069611057639122\n",
      "Epoch 8 of 500 took 0.297s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.052572914502686925 Acc: 0.9828559027777778\n",
      "val Loss: 0.045693970285356045 Acc: 0.984375\n",
      "Epoch 9 of 500 took 0.293s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.06336756112674873 Acc: 0.9778645833333334\n",
      "val Loss: 0.04119972791522741 Acc: 0.98828125\n",
      "Epoch 10 of 500 took 0.297s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.049172139830059476 Acc: 0.9817708333333334\n",
      "val Loss: 0.03433120809495449 Acc: 0.990234375\n",
      "New best validation loss: 0.03433120809495449\n",
      "Epoch 11 of 500 took 0.299s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.04468136829220586 Acc: 0.9867621527777778\n",
      "val Loss: 0.0387126412242651 Acc: 0.986328125\n",
      "Epoch 12 of 500 took 0.309s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.0419866854014496 Acc: 0.9871961805555556\n",
      "val Loss: 0.041217055171728134 Acc: 0.98828125\n",
      "Epoch 13 of 500 took 0.301s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.04211056118624078 Acc: 0.986328125\n",
      "val Loss: 0.0449604531750083 Acc: 0.986328125\n",
      "Epoch 14 of 500 took 0.395s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.04172563428680102 Acc: 0.9867621527777778\n",
      "val Loss: 0.03772868309170008 Acc: 0.98828125\n",
      "Epoch 15 of 500 took 0.301s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.040843452171732984 Acc: 0.9856770833333334\n",
      "val Loss: 0.03095303801819682 Acc: 0.98828125\n",
      "New best validation loss: 0.03095303801819682\n",
      "Epoch 16 of 500 took 0.310s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.04336992563265893 Acc: 0.9856770833333334\n",
      "val Loss: 0.03972131107002497 Acc: 0.98828125\n",
      "Epoch 17 of 500 took 0.292s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.036915781545556255 Acc: 0.9878472222222222\n",
      "val Loss: 0.04178657289594412 Acc: 0.986328125\n",
      "Epoch 18 of 500 took 0.298s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.03830459429365066 Acc: 0.9869791666666666\n",
      "val Loss: 0.02523257490247488 Acc: 0.9921875\n",
      "New best validation loss: 0.02523257490247488\n",
      "Epoch 19 of 500 took 0.350s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.0315032199335595 Acc: 0.9880642361111112\n",
      "val Loss: 0.020882383920252323 Acc: 0.990234375\n",
      "New best validation loss: 0.020882383920252323\n",
      "Epoch 20 of 500 took 0.368s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.03264624842753013 Acc: 0.9876302083333334\n",
      "val Loss: 0.020250413566827774 Acc: 0.990234375\n",
      "New best validation loss: 0.020250413566827774\n",
      "Epoch 21 of 500 took 0.392s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.03216314884937472 Acc: 0.9871961805555556\n",
      "val Loss: 0.0432873135432601 Acc: 0.986328125\n",
      "Epoch 22 of 500 took 0.387s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.032290844815886684 Acc: 0.9895833333333334\n",
      "val Loss: 0.02966862777248025 Acc: 0.98828125\n",
      "Epoch 23 of 500 took 0.348s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.029082805590911046 Acc: 0.9900173611111112\n",
      "val Loss: 0.04326674249023199 Acc: 0.986328125\n",
      "Epoch 24 of 500 took 0.293s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.025462051750057273 Acc: 0.9895833333333334\n",
      "val Loss: 0.042787852231413126 Acc: 0.986328125\n",
      "Epoch 25 of 500 took 0.278s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.028525559179898765 Acc: 0.9913194444444444\n",
      "val Loss: 0.027455194853246212 Acc: 0.98828125\n",
      "Epoch 26 of 500 took 0.308s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.022704745901541576 Acc: 0.9928385416666666\n",
      "val Loss: 0.023019284941256046 Acc: 0.990234375\n",
      "Epoch    27: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 27 of 500 took 0.308s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.022992521783130035 Acc: 0.9917534722222222\n",
      "val Loss: 0.021327671594917774 Acc: 0.990234375\n",
      "Epoch 28 of 500 took 0.292s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.028427796645296946 Acc: 0.9900173611111112\n",
      "val Loss: 0.021601231768727303 Acc: 0.9921875\n",
      "Epoch 29 of 500 took 0.303s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.025291298878275685 Acc: 0.9908854166666666\n",
      "val Loss: 0.021621272899210453 Acc: 0.990234375\n",
      "Epoch 30 of 500 took 0.304s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.024049475996030703 Acc: 0.9908854166666666\n",
      "val Loss: 0.02892923168838024 Acc: 0.98828125\n",
      "Epoch 31 of 500 took 0.321s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.022302084783506062 Acc: 0.9928385416666666\n",
      "val Loss: 0.027421035338193178 Acc: 0.990234375\n",
      "Epoch 32 of 500 took 0.310s\n",
      "\n",
      "Training complete in 0m 10s\n",
      "Best val loss: 0.020250\n",
      "ACCURACY TEST_0 FINAL : 99.008 %\n",
      "ACCURACY TEST_1 FINAL : 98.512 %\n",
      "CURRENT DATASET :  11\n",
      "(5305, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.7088633759154214 Acc: 0.8012152777777778\n",
      "val Loss: 0.21540841087698936 Acc: 0.955078125\n",
      "New best validation loss: 0.21540841087698936\n",
      "Epoch 1 of 500 took 0.366s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.23987386375665665 Acc: 0.9268663194444444\n",
      "val Loss: 0.1257664319127798 Acc: 0.94921875\n",
      "New best validation loss: 0.1257664319127798\n",
      "Epoch 2 of 500 took 0.334s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.20572179348932373 Acc: 0.9292534722222222\n",
      "val Loss: 0.11962934955954552 Acc: 0.951171875\n",
      "New best validation loss: 0.11962934955954552\n",
      "Epoch 3 of 500 took 0.308s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.17773894634511736 Acc: 0.9370659722222222\n",
      "val Loss: 0.12815002724528313 Acc: 0.955078125\n",
      "Epoch 4 of 500 took 0.446s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.1490614583922757 Acc: 0.9403211805555556\n",
      "val Loss: 0.1085824966430664 Acc: 0.955078125\n",
      "New best validation loss: 0.1085824966430664\n",
      "Epoch 5 of 500 took 0.445s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.15186263703637654 Acc: 0.9424913194444444\n",
      "val Loss: 0.10435080714523792 Acc: 0.953125\n",
      "New best validation loss: 0.10435080714523792\n",
      "Epoch 6 of 500 took 0.322s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.14244617397586504 Acc: 0.9494357638888888\n",
      "val Loss: 0.10139469802379608 Acc: 0.951171875\n",
      "New best validation loss: 0.10139469802379608\n",
      "Epoch 7 of 500 took 0.412s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.1371067456073231 Acc: 0.9496527777777778\n",
      "val Loss: 0.12143135815858841 Acc: 0.9609375\n",
      "Epoch 8 of 500 took 0.743s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.13921441841456625 Acc: 0.9479166666666666\n",
      "val Loss: 0.13314265199005604 Acc: 0.958984375\n",
      "Epoch 9 of 500 took 0.521s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.11615451963411437 Acc: 0.9533420138888888\n",
      "val Loss: 0.08852066658437252 Acc: 0.96484375\n",
      "New best validation loss: 0.08852066658437252\n",
      "Epoch 10 of 500 took 0.383s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.11294843339257771 Acc: 0.9572482638888888\n",
      "val Loss: 0.08693110290914774 Acc: 0.966796875\n",
      "New best validation loss: 0.08693110290914774\n",
      "Epoch 11 of 500 took 0.392s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.11482492668761148 Acc: 0.9594184027777778\n",
      "val Loss: 0.0851835934445262 Acc: 0.966796875\n",
      "New best validation loss: 0.0851835934445262\n",
      "Epoch 12 of 500 took 0.406s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.11317803627914852 Acc: 0.9581163194444444\n",
      "val Loss: 0.12806338258087635 Acc: 0.96484375\n",
      "Epoch 13 of 500 took 0.418s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.10699283993906444 Acc: 0.9611545138888888\n",
      "val Loss: 0.0842036809772253 Acc: 0.9609375\n",
      "New best validation loss: 0.0842036809772253\n",
      "Epoch 14 of 500 took 0.377s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.10931492555472586 Acc: 0.9568142361111112\n",
      "val Loss: 0.08415637910366058 Acc: 0.96875\n",
      "New best validation loss: 0.08415637910366058\n",
      "Epoch 15 of 500 took 0.394s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.09472699463367462 Acc: 0.9650607638888888\n",
      "val Loss: 0.09258083999156952 Acc: 0.96484375\n",
      "Epoch 16 of 500 took 0.371s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.09130103120373355 Acc: 0.9657118055555556\n",
      "val Loss: 0.09125193394720554 Acc: 0.962890625\n",
      "Epoch 17 of 500 took 0.389s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.09075776818725798 Acc: 0.9631076388888888\n",
      "val Loss: 0.07489823084324598 Acc: 0.970703125\n",
      "New best validation loss: 0.07489823084324598\n",
      "Epoch 18 of 500 took 0.399s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.08079855392376582 Acc: 0.9670138888888888\n",
      "val Loss: 0.06394774001091719 Acc: 0.9765625\n",
      "New best validation loss: 0.06394774001091719\n",
      "Epoch 19 of 500 took 0.386s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.08464427209562725 Acc: 0.9665798611111112\n",
      "val Loss: 0.08524279110133648 Acc: 0.966796875\n",
      "Epoch 20 of 500 took 0.449s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.07456570491194725 Acc: 0.9709201388888888\n",
      "val Loss: 0.06240285933017731 Acc: 0.974609375\n",
      "New best validation loss: 0.06240285933017731\n",
      "Epoch 21 of 500 took 0.389s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.08092727946738403 Acc: 0.9665798611111112\n",
      "val Loss: 0.07092585600912571 Acc: 0.97265625\n",
      "Epoch 22 of 500 took 0.404s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.08149373717606068 Acc: 0.9691840277777778\n",
      "val Loss: 0.07945900969207287 Acc: 0.96875\n",
      "Epoch 23 of 500 took 0.393s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.07090742016832034 Acc: 0.9720052083333334\n",
      "val Loss: 0.0634401785209775 Acc: 0.970703125\n",
      "Epoch 24 of 500 took 0.380s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.07446939229137367 Acc: 0.9728732638888888\n",
      "val Loss: 0.05795093812048435 Acc: 0.974609375\n",
      "New best validation loss: 0.05795093812048435\n",
      "Epoch 25 of 500 took 0.399s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.0691419281065464 Acc: 0.974609375\n",
      "val Loss: 0.057325953617691994 Acc: 0.974609375\n",
      "New best validation loss: 0.057325953617691994\n",
      "Epoch 26 of 500 took 0.426s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.06245896882481045 Acc: 0.9759114583333334\n",
      "val Loss: 0.06618081964552402 Acc: 0.96875\n",
      "Epoch 27 of 500 took 0.447s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.05654384278588825 Acc: 0.9793836805555556\n",
      "val Loss: 0.052231489680707455 Acc: 0.97265625\n",
      "New best validation loss: 0.052231489680707455\n",
      "Epoch 28 of 500 took 0.385s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.06949531990620825 Acc: 0.9739583333333334\n",
      "val Loss: 0.12001636624336243 Acc: 0.95703125\n",
      "Epoch 29 of 500 took 0.385s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.06479771725005573 Acc: 0.9752604166666666\n",
      "val Loss: 0.05936348158866167 Acc: 0.96875\n",
      "Epoch 30 of 500 took 0.387s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.061191981865300074 Acc: 0.9759114583333334\n",
      "val Loss: 0.054487887769937515 Acc: 0.970703125\n",
      "Epoch 31 of 500 took 0.383s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.057709471219115786 Acc: 0.9780815972222222\n",
      "val Loss: 0.05544033460319042 Acc: 0.974609375\n",
      "Epoch 32 of 500 took 0.383s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.051078638061881065 Acc: 0.9806857638888888\n",
      "val Loss: 0.0516800582408905 Acc: 0.9765625\n",
      "New best validation loss: 0.0516800582408905\n",
      "Epoch 33 of 500 took 0.391s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.04882910040517648 Acc: 0.9787326388888888\n",
      "val Loss: 0.04130574129521847 Acc: 0.984375\n",
      "New best validation loss: 0.04130574129521847\n",
      "Epoch 34 of 500 took 0.393s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.047663833014667034 Acc: 0.9817708333333334\n",
      "val Loss: 0.03901654947549105 Acc: 0.978515625\n",
      "New best validation loss: 0.03901654947549105\n",
      "Epoch 35 of 500 took 0.404s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.051438830585943326 Acc: 0.9815538194444444\n",
      "val Loss: 0.05138906929641962 Acc: 0.970703125\n",
      "Epoch 36 of 500 took 0.403s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.05638535300062762 Acc: 0.9763454861111112\n",
      "val Loss: 0.04667721316218376 Acc: 0.978515625\n",
      "Epoch 37 of 500 took 0.388s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.04806072937531604 Acc: 0.9806857638888888\n",
      "val Loss: 0.050777556374669075 Acc: 0.98046875\n",
      "Epoch 38 of 500 took 0.386s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.052456890853742756 Acc: 0.9791666666666666\n",
      "val Loss: 0.033559774979949 Acc: 0.984375\n",
      "New best validation loss: 0.033559774979949\n",
      "Epoch 39 of 500 took 0.411s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.041340964121951 Acc: 0.9848090277777778\n",
      "val Loss: 0.03974525537341833 Acc: 0.98046875\n",
      "Epoch 40 of 500 took 0.382s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.038140750541869134 Acc: 0.9852430555555556\n",
      "val Loss: 0.03515554126352072 Acc: 0.978515625\n",
      "Epoch 41 of 500 took 0.545s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.03797337723275026 Acc: 0.9845920138888888\n",
      "val Loss: 0.036015977151691914 Acc: 0.98046875\n",
      "Epoch 42 of 500 took 0.468s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.03291504612813393 Acc: 0.9871961805555556\n",
      "val Loss: 0.033438571728765965 Acc: 0.986328125\n",
      "New best validation loss: 0.033438571728765965\n",
      "Epoch 43 of 500 took 0.723s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.04265246716224485 Acc: 0.9871961805555556\n",
      "val Loss: 0.027864525094628334 Acc: 0.986328125\n",
      "New best validation loss: 0.027864525094628334\n",
      "Epoch 44 of 500 took 0.564s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.04067130976667007 Acc: 0.984375\n",
      "val Loss: 0.033580430783331394 Acc: 0.984375\n",
      "Epoch 45 of 500 took 0.418s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.03890312359564834 Acc: 0.9852430555555556\n",
      "val Loss: 0.029748384840786457 Acc: 0.9921875\n",
      "Epoch 46 of 500 took 0.389s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.030550862352053326 Acc: 0.9895833333333334\n",
      "val Loss: 0.02603480312973261 Acc: 0.98828125\n",
      "New best validation loss: 0.02603480312973261\n",
      "Epoch 47 of 500 took 0.383s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.03364073826620976 Acc: 0.9876302083333334\n",
      "val Loss: 0.03112307097762823 Acc: 0.982421875\n",
      "Epoch 48 of 500 took 0.388s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.026747959562473826 Acc: 0.9898003472222222\n",
      "val Loss: 0.03106160555034876 Acc: 0.98828125\n",
      "Epoch 49 of 500 took 0.397s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.030858951724237867 Acc: 0.9861111111111112\n",
      "val Loss: 0.03102318663150072 Acc: 0.986328125\n",
      "Epoch 50 of 500 took 0.422s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.025912065990269184 Acc: 0.9908854166666666\n",
      "val Loss: 0.0227446798235178 Acc: 0.9921875\n",
      "New best validation loss: 0.0227446798235178\n",
      "Epoch 51 of 500 took 0.446s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.026768547172347706 Acc: 0.9898003472222222\n",
      "val Loss: 0.0283979969099164 Acc: 0.986328125\n",
      "Epoch 52 of 500 took 0.381s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.026949524465534423 Acc: 0.9904513888888888\n",
      "val Loss: 0.032202948816120625 Acc: 0.986328125\n",
      "Epoch 53 of 500 took 0.385s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.027648437664740615 Acc: 0.9891493055555556\n",
      "val Loss: 0.01975956466048956 Acc: 0.994140625\n",
      "New best validation loss: 0.01975956466048956\n",
      "Epoch 54 of 500 took 0.388s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.020766360219568014 Acc: 0.9921875\n",
      "val Loss: 0.025624025613069534 Acc: 0.990234375\n",
      "Epoch 55 of 500 took 0.370s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.025159055936253734 Acc: 0.9919704861111112\n",
      "val Loss: 0.024354422464966774 Acc: 0.98828125\n",
      "Epoch 56 of 500 took 0.377s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.022193438632206783 Acc: 0.9906684027777778\n",
      "val Loss: 0.02945991512387991 Acc: 0.98828125\n",
      "Epoch 57 of 500 took 0.385s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.022823220688021846 Acc: 0.9915364583333334\n",
      "val Loss: 0.022642841562628746 Acc: 0.990234375\n",
      "Epoch 58 of 500 took 0.381s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.023871901859011915 Acc: 0.9913194444444444\n",
      "val Loss: 0.03451195452362299 Acc: 0.986328125\n",
      "Epoch 59 of 500 took 0.386s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.02174815194060405 Acc: 0.9917534722222222\n",
      "val Loss: 0.027728681452572346 Acc: 0.98828125\n",
      "Epoch    60: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 60 of 500 took 0.374s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.025425506859189935 Acc: 0.9908854166666666\n",
      "val Loss: 0.02070158813148737 Acc: 0.990234375\n",
      "Epoch 61 of 500 took 0.384s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.01545184969695078 Acc: 0.9947916666666666\n",
      "val Loss: 0.018701151944696903 Acc: 0.994140625\n",
      "New best validation loss: 0.018701151944696903\n",
      "Epoch 62 of 500 took 0.402s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.01985664562218719 Acc: 0.9930555555555556\n",
      "val Loss: 0.018536093644797802 Acc: 0.9921875\n",
      "New best validation loss: 0.018536093644797802\n",
      "Epoch 63 of 500 took 0.405s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.018046825606789853 Acc: 0.9934895833333334\n",
      "val Loss: 0.023004697635769844 Acc: 0.990234375\n",
      "Epoch 64 of 500 took 0.390s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.015597773250192404 Acc: 0.994140625\n",
      "val Loss: 0.021518630906939507 Acc: 0.9921875\n",
      "Epoch 65 of 500 took 0.382s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.018724304003020126 Acc: 0.9932725694444444\n",
      "val Loss: 0.01678489428013563 Acc: 0.99609375\n",
      "New best validation loss: 0.01678489428013563\n",
      "Epoch 66 of 500 took 0.390s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.01855478963504235 Acc: 0.9930555555555556\n",
      "val Loss: 0.017905090004205704 Acc: 0.9921875\n",
      "Epoch 67 of 500 took 0.385s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.02059005552695857 Acc: 0.9924045138888888\n",
      "val Loss: 0.01959588471800089 Acc: 0.994140625\n",
      "Epoch 68 of 500 took 0.383s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.018673329510622554 Acc: 0.9934895833333334\n",
      "val Loss: 0.022509044967591763 Acc: 0.98828125\n",
      "Epoch 69 of 500 took 0.470s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.017100418866094615 Acc: 0.9934895833333334\n",
      "val Loss: 0.01590869575738907 Acc: 0.99609375\n",
      "New best validation loss: 0.01590869575738907\n",
      "Epoch 70 of 500 took 0.385s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.015096063518689739 Acc: 0.9952256944444444\n",
      "val Loss: 0.01438207644969225 Acc: 0.99609375\n",
      "New best validation loss: 0.01438207644969225\n",
      "Epoch 71 of 500 took 0.389s\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.013207050816466412 Acc: 0.9956597222222222\n",
      "val Loss: 0.012194613926112652 Acc: 0.99609375\n",
      "New best validation loss: 0.012194613926112652\n",
      "Epoch 72 of 500 took 0.388s\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.015497196672691239 Acc: 0.9945746527777778\n",
      "val Loss: 0.013452332466840744 Acc: 0.998046875\n",
      "Epoch 73 of 500 took 0.382s\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.015451524975813098 Acc: 0.9937065972222222\n",
      "val Loss: 0.017581157386302948 Acc: 0.99609375\n",
      "Epoch 74 of 500 took 0.442s\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.015891633565641113 Acc: 0.9950086805555556\n",
      "val Loss: 0.01864087302237749 Acc: 0.9921875\n",
      "Epoch 75 of 500 took 0.410s\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.014763095312648349 Acc: 0.9963107638888888\n",
      "val Loss: 0.016267186030745506 Acc: 0.990234375\n",
      "Epoch 76 of 500 took 0.396s\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.013954517535037465 Acc: 0.99609375\n",
      "val Loss: 0.01395946741104126 Acc: 0.9921875\n",
      "Epoch 77 of 500 took 0.577s\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.019267036838250026 Acc: 0.9930555555555556\n",
      "val Loss: 0.014605619013309479 Acc: 0.994140625\n",
      "Epoch    78: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 78 of 500 took 0.432s\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.0160215450450778 Acc: 0.9939236111111112\n",
      "val Loss: 0.014093957841396332 Acc: 0.994140625\n",
      "Epoch 79 of 500 took 0.630s\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.012137827308227619 Acc: 0.99609375\n",
      "val Loss: 0.014843148179352283 Acc: 0.99609375\n",
      "Epoch 80 of 500 took 0.650s\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.016439415307508573 Acc: 0.9950086805555556\n",
      "val Loss: 0.01523404847830534 Acc: 0.99609375\n",
      "Epoch 81 of 500 took 0.398s\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.011890741634286113 Acc: 0.9958767361111112\n",
      "val Loss: 0.01492484100162983 Acc: 0.99609375\n",
      "Epoch 82 of 500 took 0.389s\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.01753549500265055 Acc: 0.994140625\n",
      "val Loss: 0.014683051966130733 Acc: 0.99609375\n",
      "Epoch 83 of 500 took 0.383s\n",
      "\n",
      "Training complete in 0m 35s\n",
      "Best val loss: 0.012195\n",
      "ACCURACY TEST_0 FINAL : 93.855 %\n",
      "ACCURACY TEST_1 FINAL : 94.939 %\n",
      "CURRENT DATASET :  12\n",
      "(5309, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.4390053020583259 Acc: 0.8628472222222222\n",
      "val Loss: 0.012408625334501266 Acc: 0.9921875\n",
      "New best validation loss: 0.012408625334501266\n",
      "Epoch 1 of 500 took 0.321s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.04837235135750638 Acc: 0.9815538194444444\n",
      "val Loss: 0.0032101180404424667 Acc: 1.0\n",
      "New best validation loss: 0.0032101180404424667\n",
      "Epoch 2 of 500 took 0.278s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.032893859263923436 Acc: 0.9889322916666666\n",
      "val Loss: 0.007731201127171516 Acc: 0.998046875\n",
      "Epoch 3 of 500 took 0.409s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.02492305843366517 Acc: 0.9924045138888888\n",
      "val Loss: 0.002979797311127186 Acc: 1.0\n",
      "New best validation loss: 0.002979797311127186\n",
      "Epoch 4 of 500 took 0.355s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.0179251363604433 Acc: 0.9943576388888888\n",
      "val Loss: 0.001817610114812851 Acc: 1.0\n",
      "New best validation loss: 0.001817610114812851\n",
      "Epoch 5 of 500 took 0.371s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.0142411430262857 Acc: 0.9950086805555556\n",
      "val Loss: 0.002697845920920372 Acc: 1.0\n",
      "Epoch 6 of 500 took 0.370s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.011458577536460426 Acc: 0.9973958333333334\n",
      "val Loss: 0.002257627435028553 Acc: 1.0\n",
      "Epoch 7 of 500 took 0.374s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.015233314958297543 Acc: 0.9950086805555556\n",
      "val Loss: 0.00227978453040123 Acc: 1.0\n",
      "Epoch 8 of 500 took 0.360s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.012817480290929476 Acc: 0.9956597222222222\n",
      "val Loss: 0.0023514237254858017 Acc: 1.0\n",
      "Epoch 9 of 500 took 0.388s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.010756162719594108 Acc: 0.9971788194444444\n",
      "val Loss: 0.0023957332596182823 Acc: 1.0\n",
      "Epoch 10 of 500 took 0.319s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.009734228667285707 Acc: 0.9963107638888888\n",
      "val Loss: 0.00067091453820467 Acc: 1.0\n",
      "New best validation loss: 0.00067091453820467\n",
      "Epoch 11 of 500 took 0.306s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00932457774049706 Acc: 0.9967447916666666\n",
      "val Loss: 0.001672627404332161 Acc: 1.0\n",
      "Epoch 12 of 500 took 0.317s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.01162004739873939 Acc: 0.9956597222222222\n",
      "val Loss: 0.0004532523453235626 Acc: 1.0\n",
      "New best validation loss: 0.0004532523453235626\n",
      "Epoch 13 of 500 took 0.374s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.0064052097085449435 Acc: 0.9976128472222222\n",
      "val Loss: 0.000278642401099205 Acc: 1.0\n",
      "New best validation loss: 0.000278642401099205\n",
      "Epoch 14 of 500 took 0.306s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.007828125161015324 Acc: 0.9973958333333334\n",
      "val Loss: 0.000593157485127449 Acc: 1.0\n",
      "Epoch 15 of 500 took 0.307s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.007082196832117107 Acc: 0.9989149305555556\n",
      "val Loss: 0.0004464397206902504 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.323s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.006930841805620326 Acc: 0.9976128472222222\n",
      "val Loss: 0.000606633722782135 Acc: 1.0\n",
      "Epoch 17 of 500 took 0.302s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.0070464543791280854 Acc: 0.9984809027777778\n",
      "val Loss: 0.0004165060818195343 Acc: 1.0\n",
      "Epoch 18 of 500 took 0.368s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.005240462099512418 Acc: 0.9984809027777778\n",
      "val Loss: 0.0009142179042100906 Acc: 1.0\n",
      "Epoch 19 of 500 took 0.310s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.007406009982029597 Acc: 0.9978298611111112\n",
      "val Loss: 0.0002042967826128006 Acc: 1.0\n",
      "New best validation loss: 0.0002042967826128006\n",
      "Epoch 20 of 500 took 0.313s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.007826128043234348 Acc: 0.9978298611111112\n",
      "val Loss: 0.0010385997593402863 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.294s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.004784807769788636 Acc: 0.9984809027777778\n",
      "val Loss: 0.00019301101565361023 Acc: 1.0\n",
      "New best validation loss: 0.00019301101565361023\n",
      "Epoch 22 of 500 took 0.323s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.005331415527810653 Acc: 0.998046875\n",
      "val Loss: 0.00019130855798721313 Acc: 1.0\n",
      "New best validation loss: 0.00019130855798721313\n",
      "Epoch 23 of 500 took 0.320s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.004437487520691421 Acc: 0.9982638888888888\n",
      "val Loss: 0.0001962650567293167 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.309s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.0034617803369959197 Acc: 0.9991319444444444\n",
      "val Loss: 0.00012871995568275452 Acc: 1.0\n",
      "New best validation loss: 0.00012871995568275452\n",
      "Epoch 25 of 500 took 0.307s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.0044147419846720165 Acc: 0.9984809027777778\n",
      "val Loss: 0.00015545636415481567 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.297s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.010473953146073554 Acc: 0.9965277777777778\n",
      "val Loss: 8.626654744148254e-05 Acc: 1.0\n",
      "New best validation loss: 8.626654744148254e-05\n",
      "Epoch 27 of 500 took 0.307s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.004386472101840708 Acc: 0.9986979166666666\n",
      "val Loss: 0.0003265049308538437 Acc: 1.0\n",
      "Epoch 28 of 500 took 0.307s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.006476566971590121 Acc: 0.998046875\n",
      "val Loss: 0.00021859817206859589 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.300s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.004041908205383354 Acc: 0.9984809027777778\n",
      "val Loss: 0.00033960863947868347 Acc: 1.0\n",
      "Epoch 30 of 500 took 0.298s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00297701358795166 Acc: 0.9993489583333334\n",
      "val Loss: 0.00010059401392936707 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.309s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.0038299542955226367 Acc: 0.9991319444444444\n",
      "val Loss: 0.0001275148242712021 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.308s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.002619354933914211 Acc: 0.9995659722222222\n",
      "val Loss: 8.483417332172394e-05 Acc: 1.0\n",
      "New best validation loss: 8.483417332172394e-05\n",
      "Epoch 33 of 500 took 0.312s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.0029855529881185955 Acc: 0.9989149305555556\n",
      "val Loss: 3.193877637386322e-05 Acc: 1.0\n",
      "New best validation loss: 3.193877637386322e-05\n",
      "Epoch 34 of 500 took 0.358s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.0027645151648256513 Acc: 0.9989149305555556\n",
      "val Loss: 0.000145716592669487 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.302s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.004300163800103797 Acc: 0.9991319444444444\n",
      "val Loss: 3.428943455219269e-05 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.574s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.0021347185182902548 Acc: 0.9995659722222222\n",
      "val Loss: 5.7196244597435e-05 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.306s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.002745265399830209 Acc: 0.9991319444444444\n",
      "val Loss: 0.00011455267667770386 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.543s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.001841255049738619 Acc: 0.9995659722222222\n",
      "val Loss: 2.8353184461593628e-05 Acc: 1.0\n",
      "New best validation loss: 2.8353184461593628e-05\n",
      "Epoch 39 of 500 took 0.714s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.002190011708686749 Acc: 0.9993489583333334\n",
      "val Loss: 3.7338584661483765e-05 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.310s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0020276933080620235 Acc: 0.9995659722222222\n",
      "val Loss: 3.45427542924881e-05 Acc: 1.0\n",
      "Epoch 41 of 500 took 0.321s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.001500901145239671 Acc: 0.9993489583333334\n",
      "val Loss: 4.3312087655067444e-05 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.301s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.0021636425000098017 Acc: 0.9991319444444444\n",
      "val Loss: 1.55717134475708e-05 Acc: 1.0\n",
      "New best validation loss: 1.55717134475708e-05\n",
      "Epoch 43 of 500 took 0.305s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0016993886480728786 Acc: 0.9993489583333334\n",
      "val Loss: 4.2943283915519714e-05 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.308s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.0032683869099451434 Acc: 0.9989149305555556\n",
      "val Loss: 2.8112903237342834e-05 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.317s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.001975822728127241 Acc: 0.9993489583333334\n",
      "val Loss: 1.739896833896637e-05 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.308s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0014149330866833527 Acc: 0.9993489583333334\n",
      "val Loss: 7.88811594247818e-05 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.347s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.0015544879974590407 Acc: 0.9993489583333334\n",
      "val Loss: 1.4191493391990662e-05 Acc: 1.0\n",
      "New best validation loss: 1.4191493391990662e-05\n",
      "Epoch 48 of 500 took 0.317s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.0014417732858823405 Acc: 0.9997829861111112\n",
      "val Loss: 2.2683292627334595e-05 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.308s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.0017944583669304848 Acc: 0.9991319444444444\n",
      "val Loss: 1.9591301679611206e-05 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.288s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.002314626860121886 Acc: 0.9993489583333334\n",
      "val Loss: 1.198798418045044e-05 Acc: 1.0\n",
      "New best validation loss: 1.198798418045044e-05\n",
      "Epoch 51 of 500 took 0.300s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.001289936403433482 Acc: 0.9995659722222222\n",
      "val Loss: 1.1375173926353455e-05 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.284s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0014971842368443806 Acc: 0.9997829861111112\n",
      "val Loss: 0.00020421110093593597 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.294s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.001563683876560794 Acc: 0.9995659722222222\n",
      "val Loss: 7.767975330352783e-05 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.290s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.001762172310716576 Acc: 0.9995659722222222\n",
      "val Loss: 0.00010411813855171204 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.294s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0016916851616568035 Acc: 0.9993489583333334\n",
      "val Loss: 0.0002701263874769211 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.284s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.00226271307716767 Acc: 0.9993489583333334\n",
      "val Loss: 2.537667751312256e-05 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.295s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.001576551960574256 Acc: 0.9995659722222222\n",
      "val Loss: 2.1046027541160583e-05 Acc: 1.0\n",
      "Epoch    58: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 58 of 500 took 0.284s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0008238145253724522 Acc: 0.9997829861111112\n",
      "val Loss: 1.531653106212616e-05 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.299s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0008838544082310465 Acc: 0.9997829861111112\n",
      "val Loss: 1.2202188372612e-05 Acc: 1.0\n",
      "Epoch 60 of 500 took 0.358s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.0013574900933437878 Acc: 0.9995659722222222\n",
      "val Loss: 1.0298565030097961e-05 Acc: 1.0\n",
      "New best validation loss: 1.0298565030097961e-05\n",
      "Epoch 61 of 500 took 0.303s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.0017294733681612546 Acc: 0.9995659722222222\n",
      "val Loss: 8.065253496170044e-06 Acc: 1.0\n",
      "New best validation loss: 8.065253496170044e-06\n",
      "Epoch 62 of 500 took 0.305s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.0014540818002488879 Acc: 0.9993489583333334\n",
      "val Loss: 5.995854735374451e-06 Acc: 1.0\n",
      "New best validation loss: 5.995854735374451e-06\n",
      "Epoch 63 of 500 took 0.312s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.002044158884220653 Acc: 0.9993489583333334\n",
      "val Loss: 7.342547178268433e-06 Acc: 1.0\n",
      "Epoch 64 of 500 took 0.356s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.001239350169069237 Acc: 0.9997829861111112\n",
      "val Loss: 9.624287486076355e-06 Acc: 1.0\n",
      "Epoch 65 of 500 took 0.297s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.0006507179803318448 Acc: 1.0\n",
      "val Loss: 7.821246981620789e-06 Acc: 1.0\n",
      "Epoch 66 of 500 took 0.292s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.0015736427158117294 Acc: 0.9995659722222222\n",
      "val Loss: 7.037073373794556e-06 Acc: 1.0\n",
      "Epoch 67 of 500 took 0.329s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.0008417300672994719 Acc: 0.9995659722222222\n",
      "val Loss: 1.3425946235656738e-05 Acc: 1.0\n",
      "Epoch 68 of 500 took 0.313s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0011401484823889202 Acc: 0.9997829861111112\n",
      "val Loss: 1.1077150702476501e-05 Acc: 1.0\n",
      "Epoch    69: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 69 of 500 took 0.316s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0007992844200796551 Acc: 0.9997829861111112\n",
      "val Loss: 7.72625207901001e-06 Acc: 1.0\n",
      "Epoch 70 of 500 took 0.303s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.0007146003966530164 Acc: 0.9995659722222222\n",
      "val Loss: 1.0410323739051819e-05 Acc: 1.0\n",
      "Epoch 71 of 500 took 0.309s\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.001566819174008237 Acc: 0.9995659722222222\n",
      "val Loss: 1.0870397090911865e-05 Acc: 1.0\n",
      "Epoch 72 of 500 took 0.292s\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.0009818115375108188 Acc: 0.9995659722222222\n",
      "val Loss: 1.161918044090271e-05 Acc: 1.0\n",
      "Epoch 73 of 500 took 0.307s\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.0011750602473815281 Acc: 0.9997829861111112\n",
      "val Loss: 9.043142199516296e-06 Acc: 1.0\n",
      "Epoch 74 of 500 took 0.332s\n",
      "\n",
      "Training complete in 0m 24s\n",
      "Best val loss: 0.000006\n",
      "ACCURACY TEST_0 FINAL : 99.752 %\n",
      "ACCURACY TEST_1 FINAL : 99.535 %\n",
      "CURRENT DATASET :  13\n",
      "(5313, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.47668053747879136 Acc: 0.8446180555555556\n",
      "val Loss: 0.0580093078315258 Acc: 0.978515625\n",
      "New best validation loss: 0.0580093078315258\n",
      "Epoch 1 of 500 took 0.320s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.12256712425086233 Acc: 0.9552951388888888\n",
      "val Loss: 0.0630054073408246 Acc: 0.97265625\n",
      "Epoch 2 of 500 took 0.294s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.08931716779867808 Acc: 0.9641927083333334\n",
      "val Loss: 0.049363027326762676 Acc: 0.982421875\n",
      "New best validation loss: 0.049363027326762676\n",
      "Epoch 3 of 500 took 0.311s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.078795591990153 Acc: 0.9698350694444444\n",
      "val Loss: 0.06307950336486101 Acc: 0.96875\n",
      "Epoch 4 of 500 took 0.304s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.0742109361001187 Acc: 0.9702690972222222\n",
      "val Loss: 0.04999782517552376 Acc: 0.984375\n",
      "Epoch 5 of 500 took 0.356s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.0730690508046084 Acc: 0.9711371527777778\n",
      "val Loss: 0.05068914499133825 Acc: 0.982421875\n",
      "Epoch 6 of 500 took 0.381s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.0645719211962488 Acc: 0.9759114583333334\n",
      "val Loss: 0.045171864330768585 Acc: 0.98046875\n",
      "New best validation loss: 0.045171864330768585\n",
      "Epoch 7 of 500 took 0.512s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.05709674136920108 Acc: 0.9776475694444444\n",
      "val Loss: 0.050101193599402905 Acc: 0.978515625\n",
      "Epoch 8 of 500 took 0.413s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.0483542847343617 Acc: 0.9802517361111112\n",
      "val Loss: 0.05453147832304239 Acc: 0.978515625\n",
      "Epoch 9 of 500 took 0.613s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.05477058245903916 Acc: 0.9791666666666666\n",
      "val Loss: 0.04064100794494152 Acc: 0.986328125\n",
      "New best validation loss: 0.04064100794494152\n",
      "Epoch 10 of 500 took 0.645s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.05020215786579582 Acc: 0.9813368055555556\n",
      "val Loss: 0.05357083771377802 Acc: 0.978515625\n",
      "Epoch 11 of 500 took 0.386s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.04629230820056465 Acc: 0.9819878472222222\n",
      "val Loss: 0.04436808172613382 Acc: 0.98046875\n",
      "Epoch 12 of 500 took 0.342s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.05973121182372173 Acc: 0.9772135416666666\n",
      "val Loss: 0.06326186284422874 Acc: 0.974609375\n",
      "Epoch 13 of 500 took 0.269s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.05863132721020116 Acc: 0.9787326388888888\n",
      "val Loss: 0.06232115626335144 Acc: 0.970703125\n",
      "Epoch 14 of 500 took 0.272s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.04462324931389756 Acc: 0.9811197916666666\n",
      "val Loss: 0.042813695035874844 Acc: 0.98046875\n",
      "Epoch 15 of 500 took 0.338s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.044493517321017056 Acc: 0.9806857638888888\n",
      "val Loss: 0.044298636727035046 Acc: 0.982421875\n",
      "Epoch    16: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 16 of 500 took 0.360s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.03640370577987698 Acc: 0.9865451388888888\n",
      "val Loss: 0.03650171495974064 Acc: 0.986328125\n",
      "New best validation loss: 0.03650171495974064\n",
      "Epoch 17 of 500 took 0.411s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.035955982800159186 Acc: 0.9848090277777778\n",
      "val Loss: 0.03230298403650522 Acc: 0.98828125\n",
      "New best validation loss: 0.03230298403650522\n",
      "Epoch 18 of 500 took 0.337s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.043185202611817256 Acc: 0.9839409722222222\n",
      "val Loss: 0.03761683404445648 Acc: 0.982421875\n",
      "Epoch 19 of 500 took 0.268s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.03140348604776793 Acc: 0.9891493055555556\n",
      "val Loss: 0.03058177512139082 Acc: 0.98828125\n",
      "New best validation loss: 0.03058177512139082\n",
      "Epoch 20 of 500 took 0.278s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.028563680385963783 Acc: 0.9893663194444444\n",
      "val Loss: 0.03858646098524332 Acc: 0.984375\n",
      "Epoch 21 of 500 took 0.272s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.02951356577169564 Acc: 0.9915364583333334\n",
      "val Loss: 0.03734079748392105 Acc: 0.982421875\n",
      "Epoch 22 of 500 took 0.322s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.03894895946400033 Acc: 0.9854600694444444\n",
      "val Loss: 0.027603711001574993 Acc: 0.9921875\n",
      "New best validation loss: 0.027603711001574993\n",
      "Epoch 23 of 500 took 0.345s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.028541203691727586 Acc: 0.9900173611111112\n",
      "val Loss: 0.037357709370553493 Acc: 0.984375\n",
      "Epoch 24 of 500 took 0.444s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.031045107791821163 Acc: 0.9878472222222222\n",
      "val Loss: 0.032801415771245956 Acc: 0.990234375\n",
      "Epoch 25 of 500 took 0.368s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.03218156440804402 Acc: 0.9869791666666666\n",
      "val Loss: 0.03658616729080677 Acc: 0.986328125\n",
      "Epoch 26 of 500 took 0.372s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.032081852149632245 Acc: 0.9880642361111112\n",
      "val Loss: 0.03204913157969713 Acc: 0.990234375\n",
      "Epoch 27 of 500 took 0.389s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.02852384207977189 Acc: 0.98828125\n",
      "val Loss: 0.022907466627657413 Acc: 0.994140625\n",
      "New best validation loss: 0.022907466627657413\n",
      "Epoch 28 of 500 took 0.363s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.025881349264333647 Acc: 0.9900173611111112\n",
      "val Loss: 0.03401707857847214 Acc: 0.986328125\n",
      "Epoch 29 of 500 took 0.364s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.024003299108395975 Acc: 0.9926215277777778\n",
      "val Loss: 0.027560322545468807 Acc: 0.9921875\n",
      "Epoch 30 of 500 took 0.342s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.03293005951369802 Acc: 0.9887152777777778\n",
      "val Loss: 0.03135566134005785 Acc: 0.990234375\n",
      "Epoch 31 of 500 took 0.349s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.031343655557268195 Acc: 0.9880642361111112\n",
      "val Loss: 0.031555757857859135 Acc: 0.9921875\n",
      "Epoch 32 of 500 took 0.463s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.028272069990634918 Acc: 0.9889322916666666\n",
      "val Loss: 0.02472531795501709 Acc: 0.9921875\n",
      "Epoch 33 of 500 took 0.358s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.026269823519719973 Acc: 0.9906684027777778\n",
      "val Loss: 0.027838340029120445 Acc: 0.9921875\n",
      "Epoch    34: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 34 of 500 took 0.360s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.02881645183596346 Acc: 0.9891493055555556\n",
      "val Loss: 0.0261520529165864 Acc: 0.9921875\n",
      "Epoch 35 of 500 took 0.302s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.028304024547752406 Acc: 0.990234375\n",
      "val Loss: 0.028883985243737698 Acc: 0.990234375\n",
      "Epoch 36 of 500 took 0.280s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.025953322286821075 Acc: 0.9891493055555556\n",
      "val Loss: 0.029269516468048096 Acc: 0.990234375\n",
      "Epoch 37 of 500 took 0.266s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.02995384820840425 Acc: 0.9895833333333334\n",
      "val Loss: 0.025587470270693302 Acc: 0.9921875\n",
      "Epoch 38 of 500 took 0.334s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.022424100794725947 Acc: 0.9924045138888888\n",
      "val Loss: 0.029679257422685623 Acc: 0.9921875\n",
      "Epoch 39 of 500 took 0.280s\n",
      "\n",
      "Training complete in 0m 14s\n",
      "Best val loss: 0.022907\n",
      "ACCURACY TEST_0 FINAL : 79.417 %\n",
      "ACCURACY TEST_1 FINAL : 87.027 %\n",
      "CURRENT DATASET :  14\n",
      "(5306, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.6663797659178575 Acc: 0.7953559027777778\n",
      "val Loss: 0.0511060431599617 Acc: 0.986328125\n",
      "New best validation loss: 0.0511060431599617\n",
      "Epoch 1 of 500 took 0.301s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.108468782570627 Acc: 0.9633246527777778\n",
      "val Loss: 0.010552230291068554 Acc: 1.0\n",
      "New best validation loss: 0.010552230291068554\n",
      "Epoch 2 of 500 took 0.347s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.06331501570012835 Acc: 0.98046875\n",
      "val Loss: 0.011543301865458488 Acc: 0.99609375\n",
      "Epoch 3 of 500 took 0.317s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.05456366669386625 Acc: 0.9806857638888888\n",
      "val Loss: 0.008678922429680824 Acc: 1.0\n",
      "New best validation loss: 0.008678922429680824\n",
      "Epoch 4 of 500 took 0.362s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.037558188299751945 Acc: 0.98828125\n",
      "val Loss: 0.010321147739887238 Acc: 0.99609375\n",
      "Epoch 5 of 500 took 0.370s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.03683376208775573 Acc: 0.9869791666666666\n",
      "val Loss: 0.007717782631516457 Acc: 1.0\n",
      "New best validation loss: 0.007717782631516457\n",
      "Epoch 6 of 500 took 0.347s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.03193390602245927 Acc: 0.9887152777777778\n",
      "val Loss: 0.00592818483710289 Acc: 1.0\n",
      "New best validation loss: 0.00592818483710289\n",
      "Epoch 7 of 500 took 0.387s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.03081082371580932 Acc: 0.9898003472222222\n",
      "val Loss: 0.005230709910392761 Acc: 1.0\n",
      "New best validation loss: 0.005230709910392761\n",
      "Epoch 8 of 500 took 0.534s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.027233047566066187 Acc: 0.9908854166666666\n",
      "val Loss: 0.005571105517446995 Acc: 0.998046875\n",
      "Epoch 9 of 500 took 0.412s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.01851222462331255 Acc: 0.9939236111111112\n",
      "val Loss: 0.0066227056086063385 Acc: 0.998046875\n",
      "Epoch 10 of 500 took 0.581s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.02338950191107061 Acc: 0.9924045138888888\n",
      "val Loss: 0.00446732435375452 Acc: 1.0\n",
      "New best validation loss: 0.00446732435375452\n",
      "Epoch 11 of 500 took 0.681s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.01997388143920236 Acc: 0.9930555555555556\n",
      "val Loss: 0.003035455010831356 Acc: 1.0\n",
      "New best validation loss: 0.003035455010831356\n",
      "Epoch 12 of 500 took 0.390s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.016809712474544842 Acc: 0.994140625\n",
      "val Loss: 0.004293153993785381 Acc: 1.0\n",
      "Epoch 13 of 500 took 0.351s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.015419080387800932 Acc: 0.9943576388888888\n",
      "val Loss: 0.0026769880205392838 Acc: 1.0\n",
      "New best validation loss: 0.0026769880205392838\n",
      "Epoch 14 of 500 took 0.390s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.018137072419954672 Acc: 0.9924045138888888\n",
      "val Loss: 0.005367271602153778 Acc: 1.0\n",
      "Epoch 15 of 500 took 0.411s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.015948939602822065 Acc: 0.9956597222222222\n",
      "val Loss: 0.00310385599732399 Acc: 1.0\n",
      "Epoch 16 of 500 took 0.304s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.014657171132663885 Acc: 0.9950086805555556\n",
      "val Loss: 0.004303311929106712 Acc: 0.998046875\n",
      "Epoch 17 of 500 took 0.284s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.012154237781133916 Acc: 0.99609375\n",
      "val Loss: 0.00580370519310236 Acc: 0.998046875\n",
      "Epoch 18 of 500 took 0.290s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.019171517807990313 Acc: 0.9939236111111112\n",
      "val Loss: 0.0019297413527965546 Acc: 1.0\n",
      "New best validation loss: 0.0019297413527965546\n",
      "Epoch 19 of 500 took 0.365s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.013174145844661526 Acc: 0.9956597222222222\n",
      "val Loss: 0.0035266606137156487 Acc: 1.0\n",
      "Epoch 20 of 500 took 0.300s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.01332370052114129 Acc: 0.9947916666666666\n",
      "val Loss: 0.0028586536645889282 Acc: 1.0\n",
      "Epoch 21 of 500 took 0.284s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.012996689416468143 Acc: 0.9952256944444444\n",
      "val Loss: 0.003193451091647148 Acc: 1.0\n",
      "Epoch 22 of 500 took 0.300s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.010312263698627552 Acc: 0.9969618055555556\n",
      "val Loss: 0.0025166068226099014 Acc: 1.0\n",
      "Epoch 23 of 500 took 0.298s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.009044834464374516 Acc: 0.9973958333333334\n",
      "val Loss: 0.0021610213443636894 Acc: 1.0\n",
      "Epoch 24 of 500 took 0.294s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.010659941886034276 Acc: 0.9958767361111112\n",
      "val Loss: 0.0015619564801454544 Acc: 1.0\n",
      "New best validation loss: 0.0015619564801454544\n",
      "Epoch 25 of 500 took 0.300s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.0071459319442510605 Acc: 0.9984809027777778\n",
      "val Loss: 0.0018447339534759521 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.284s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.011228849490483602 Acc: 0.9965277777777778\n",
      "val Loss: 0.002589746378362179 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.291s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.010859646265291505 Acc: 0.9963107638888888\n",
      "val Loss: 0.0007780659943819046 Acc: 1.0\n",
      "New best validation loss: 0.0007780659943819046\n",
      "Epoch 28 of 500 took 0.292s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.008129881953613626 Acc: 0.9978298611111112\n",
      "val Loss: 0.002620878629386425 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.281s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00738278626360827 Acc: 0.9978298611111112\n",
      "val Loss: 0.002315867692232132 Acc: 1.0\n",
      "Epoch 30 of 500 took 0.292s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.007371863350272179 Acc: 0.9978298611111112\n",
      "val Loss: 0.0027618780732154846 Acc: 1.0\n",
      "Epoch 31 of 500 took 0.293s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.006630201875749562 Acc: 0.9973958333333334\n",
      "val Loss: 0.0018337694928050041 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.292s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.006710459995600913 Acc: 0.9978298611111112\n",
      "val Loss: 0.002541976049542427 Acc: 1.0\n",
      "Epoch 33 of 500 took 0.288s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00550845337824689 Acc: 0.9984809027777778\n",
      "val Loss: 0.0014348290860652924 Acc: 1.0\n",
      "Epoch    34: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 34 of 500 took 0.290s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.006238631541944212 Acc: 0.998046875\n",
      "val Loss: 0.0006565386429429054 Acc: 1.0\n",
      "New best validation loss: 0.0006565386429429054\n",
      "Epoch 35 of 500 took 0.301s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.006616338673565123 Acc: 0.9971788194444444\n",
      "val Loss: 0.0007572202011942863 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.286s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.004794911274479495 Acc: 0.9986979166666666\n",
      "val Loss: 0.001134183257818222 Acc: 1.0\n",
      "Epoch 37 of 500 took 0.333s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.004367167078372505 Acc: 0.9989149305555556\n",
      "val Loss: 0.0011233491823077202 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.294s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00640652815086974 Acc: 0.9978298611111112\n",
      "val Loss: 0.0012469673529267311 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.350s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.005080496788852745 Acc: 0.9982638888888888\n",
      "val Loss: 0.0009223353117704391 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.300s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.006698283677299817 Acc: 0.9973958333333334\n",
      "val Loss: 0.0015382356941699982 Acc: 1.0\n",
      "Epoch    41: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 41 of 500 took 0.287s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.005100219717456235 Acc: 0.9982638888888888\n",
      "val Loss: 0.001809544861316681 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.290s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.005023564832905929 Acc: 0.9982638888888888\n",
      "val Loss: 0.0015325341373682022 Acc: 1.0\n",
      "Epoch 43 of 500 took 0.399s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0062959204531378215 Acc: 0.9982638888888888\n",
      "val Loss: 0.0017178980633616447 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.275s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.003915081525014507 Acc: 0.9995659722222222\n",
      "val Loss: 0.0018658172339200974 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.301s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.004935406355394257 Acc: 0.9984809027777778\n",
      "val Loss: 0.00172406155616045 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.289s\n",
      "\n",
      "Training complete in 0m 16s\n",
      "Best val loss: 0.000657\n",
      "ACCURACY TEST_0 FINAL : 98.510 %\n",
      "ACCURACY TEST_1 FINAL : 99.845 %\n",
      "CURRENT DATASET :  15\n",
      "(5309, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5668281639615694 Acc: 0.8038194444444444\n",
      "val Loss: 0.07745433412492275 Acc: 0.9765625\n",
      "New best validation loss: 0.07745433412492275\n",
      "Epoch 1 of 500 took 0.292s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.15877869932187927 Acc: 0.9346788194444444\n",
      "val Loss: 0.0554223507642746 Acc: 0.982421875\n",
      "New best validation loss: 0.0554223507642746\n",
      "Epoch 2 of 500 took 0.287s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.12483509216043684 Acc: 0.9520399305555556\n",
      "val Loss: 0.04779237601906061 Acc: 0.986328125\n",
      "New best validation loss: 0.04779237601906061\n",
      "Epoch 3 of 500 took 0.294s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.10193195897671911 Acc: 0.9613715277777778\n",
      "val Loss: 0.04687940422445536 Acc: 0.986328125\n",
      "New best validation loss: 0.04687940422445536\n",
      "Epoch 4 of 500 took 0.299s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.09146530429522197 Acc: 0.9633246527777778\n",
      "val Loss: 0.04530692007392645 Acc: 0.982421875\n",
      "New best validation loss: 0.04530692007392645\n",
      "Epoch 5 of 500 took 0.292s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.07359963138070372 Acc: 0.9702690972222222\n",
      "val Loss: 0.04966678377240896 Acc: 0.98046875\n",
      "Epoch 6 of 500 took 0.344s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.07696049784620602 Acc: 0.9674479166666666\n",
      "val Loss: 0.030330464243888855 Acc: 0.990234375\n",
      "New best validation loss: 0.030330464243888855\n",
      "Epoch 7 of 500 took 0.475s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.06722192073033915 Acc: 0.9735243055555556\n",
      "val Loss: 0.02539132535457611 Acc: 0.9921875\n",
      "New best validation loss: 0.02539132535457611\n",
      "Epoch 8 of 500 took 0.287s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.056744245605336294 Acc: 0.9759114583333334\n",
      "val Loss: 0.02451220154762268 Acc: 0.9921875\n",
      "New best validation loss: 0.02451220154762268\n",
      "Epoch 9 of 500 took 0.314s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.05709375047849284 Acc: 0.9780815972222222\n",
      "val Loss: 0.02383767906576395 Acc: 0.990234375\n",
      "New best validation loss: 0.02383767906576395\n",
      "Epoch 10 of 500 took 0.344s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.05117207362006108 Acc: 0.9796006944444444\n",
      "val Loss: 0.021112673915922642 Acc: 0.994140625\n",
      "New best validation loss: 0.021112673915922642\n",
      "Epoch 11 of 500 took 0.584s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.044597751254008874 Acc: 0.9858940972222222\n",
      "val Loss: 0.018629424273967743 Acc: 0.99609375\n",
      "New best validation loss: 0.018629424273967743\n",
      "Epoch 12 of 500 took 0.592s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.04478424270119932 Acc: 0.9835069444444444\n",
      "val Loss: 0.014853822998702526 Acc: 0.998046875\n",
      "New best validation loss: 0.014853822998702526\n",
      "Epoch 13 of 500 took 0.390s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.05101259445978536 Acc: 0.9796006944444444\n",
      "val Loss: 0.022859939374029636 Acc: 0.994140625\n",
      "Epoch 14 of 500 took 0.379s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.0380543606976668 Acc: 0.9845920138888888\n",
      "val Loss: 0.014005938544869423 Acc: 0.998046875\n",
      "New best validation loss: 0.014005938544869423\n",
      "Epoch 15 of 500 took 0.319s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.042255525891151696 Acc: 0.9848090277777778\n",
      "val Loss: 0.021594470366835594 Acc: 0.9921875\n",
      "Epoch 16 of 500 took 0.311s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.03914559063398176 Acc: 0.9856770833333334\n",
      "val Loss: 0.01652309112250805 Acc: 0.99609375\n",
      "Epoch 17 of 500 took 0.295s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.03827221350123485 Acc: 0.986328125\n",
      "val Loss: 0.016436118632555008 Acc: 0.99609375\n",
      "Epoch 18 of 500 took 0.288s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.04216791006426016 Acc: 0.9835069444444444\n",
      "val Loss: 0.011253026314079762 Acc: 0.998046875\n",
      "New best validation loss: 0.011253026314079762\n",
      "Epoch 19 of 500 took 0.291s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.034054968506097794 Acc: 0.9871961805555556\n",
      "val Loss: 0.008766604587435722 Acc: 0.998046875\n",
      "New best validation loss: 0.008766604587435722\n",
      "Epoch 20 of 500 took 0.385s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.040750703463951744 Acc: 0.984375\n",
      "val Loss: 0.008707272820174694 Acc: 0.998046875\n",
      "New best validation loss: 0.008707272820174694\n",
      "Epoch 21 of 500 took 0.397s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.03121664675159587 Acc: 0.9884982638888888\n",
      "val Loss: 0.008202549070119858 Acc: 1.0\n",
      "New best validation loss: 0.008202549070119858\n",
      "Epoch 22 of 500 took 0.412s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.0341816863252057 Acc: 0.9867621527777778\n",
      "val Loss: 0.006290612742304802 Acc: 1.0\n",
      "New best validation loss: 0.006290612742304802\n",
      "Epoch 23 of 500 took 0.416s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.028561751565171614 Acc: 0.990234375\n",
      "val Loss: 0.007840469479560852 Acc: 0.998046875\n",
      "Epoch 24 of 500 took 0.408s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.027431571959621377 Acc: 0.9906684027777778\n",
      "val Loss: 0.005930197425186634 Acc: 1.0\n",
      "New best validation loss: 0.005930197425186634\n",
      "Epoch 25 of 500 took 0.332s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.018997064791619778 Acc: 0.9934895833333334\n",
      "val Loss: 0.007662637159228325 Acc: 0.998046875\n",
      "Epoch 26 of 500 took 0.321s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.026492233129425183 Acc: 0.9911024305555556\n",
      "val Loss: 0.0046661123633384705 Acc: 1.0\n",
      "New best validation loss: 0.0046661123633384705\n",
      "Epoch 27 of 500 took 0.337s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.025034100852078862 Acc: 0.9915364583333334\n",
      "val Loss: 0.010169966146349907 Acc: 0.99609375\n",
      "Epoch 28 of 500 took 0.354s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.02633023044715325 Acc: 0.9884982638888888\n",
      "val Loss: 0.013741961680352688 Acc: 0.99609375\n",
      "Epoch 29 of 500 took 0.395s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.028072055222259626 Acc: 0.9880642361111112\n",
      "val Loss: 0.02816090453416109 Acc: 0.98828125\n",
      "Epoch 30 of 500 took 0.401s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.021961409132927656 Acc: 0.9911024305555556\n",
      "val Loss: 0.005519721657037735 Acc: 0.998046875\n",
      "Epoch 31 of 500 took 0.403s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.02236625852270259 Acc: 0.9919704861111112\n",
      "val Loss: 0.0041602011770009995 Acc: 1.0\n",
      "New best validation loss: 0.0041602011770009995\n",
      "Epoch 32 of 500 took 0.405s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.020018759390546217 Acc: 0.9911024305555556\n",
      "val Loss: 0.009098537266254425 Acc: 0.99609375\n",
      "Epoch 33 of 500 took 0.437s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.018532719670070544 Acc: 0.9926215277777778\n",
      "val Loss: 0.01371585950255394 Acc: 0.994140625\n",
      "Epoch 34 of 500 took 0.392s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.02102590823132131 Acc: 0.9913194444444444\n",
      "val Loss: 0.008432154543697834 Acc: 0.99609375\n",
      "Epoch 35 of 500 took 0.326s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.02035737710280551 Acc: 0.9928385416666666\n",
      "val Loss: 0.0032349620014429092 Acc: 1.0\n",
      "New best validation loss: 0.0032349620014429092\n",
      "Epoch 36 of 500 took 0.394s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.019299295213487413 Acc: 0.9937065972222222\n",
      "val Loss: 0.0028488384559750557 Acc: 1.0\n",
      "New best validation loss: 0.0028488384559750557\n",
      "Epoch 37 of 500 took 0.394s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.021617367553214233 Acc: 0.9924045138888888\n",
      "val Loss: 0.002611592411994934 Acc: 1.0\n",
      "New best validation loss: 0.002611592411994934\n",
      "Epoch 38 of 500 took 0.464s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.02772402483969927 Acc: 0.98828125\n",
      "val Loss: 0.002598828636109829 Acc: 1.0\n",
      "New best validation loss: 0.002598828636109829\n",
      "Epoch 39 of 500 took 0.404s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.019146769928435486 Acc: 0.9932725694444444\n",
      "val Loss: 0.0042443545535206795 Acc: 1.0\n",
      "Epoch 40 of 500 took 0.415s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.015150568758447966 Acc: 0.9954427083333334\n",
      "val Loss: 0.0020143697038292885 Acc: 1.0\n",
      "New best validation loss: 0.0020143697038292885\n",
      "Epoch 41 of 500 took 0.408s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.014293787173098989 Acc: 0.9952256944444444\n",
      "val Loss: 0.004591377452015877 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.447s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.01597880556558569 Acc: 0.9943576388888888\n",
      "val Loss: 0.0031024860218167305 Acc: 1.0\n",
      "Epoch 43 of 500 took 0.487s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.01703372359689739 Acc: 0.9930555555555556\n",
      "val Loss: 0.003549216315150261 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.561s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.013548402322663201 Acc: 0.9947916666666666\n",
      "val Loss: 0.008752718567848206 Acc: 0.99609375\n",
      "Epoch 45 of 500 took 0.779s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.011538178815195957 Acc: 0.9952256944444444\n",
      "val Loss: 0.004927978850901127 Acc: 1.0\n",
      "Epoch 46 of 500 took 0.710s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.014196268386311002 Acc: 0.9943576388888888\n",
      "val Loss: 0.0016741855069994926 Acc: 1.0\n",
      "New best validation loss: 0.0016741855069994926\n",
      "Epoch 47 of 500 took 0.762s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.01565298443246219 Acc: 0.9947916666666666\n",
      "val Loss: 0.0015801237896084785 Acc: 1.0\n",
      "New best validation loss: 0.0015801237896084785\n",
      "Epoch 48 of 500 took 0.626s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.014873960676292578 Acc: 0.9954427083333334\n",
      "val Loss: 0.0031387703493237495 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.530s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.012553564428041378 Acc: 0.9954427083333334\n",
      "val Loss: 0.0012164311483502388 Acc: 1.0\n",
      "New best validation loss: 0.0012164311483502388\n",
      "Epoch 50 of 500 took 0.409s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.014676811328778664 Acc: 0.9950086805555556\n",
      "val Loss: 0.0032299794256687164 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.405s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.012767632802327475 Acc: 0.9956597222222222\n",
      "val Loss: 0.002585548907518387 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.408s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.012282595555815432 Acc: 0.9952256944444444\n",
      "val Loss: 0.001372089609503746 Acc: 1.0\n",
      "Epoch 53 of 500 took 0.408s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.009080546287198862 Acc: 0.9967447916666666\n",
      "val Loss: 0.0025283992290496826 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.435s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.011765195470717218 Acc: 0.99609375\n",
      "val Loss: 0.004346165806055069 Acc: 1.0\n",
      "Epoch 55 of 500 took 0.405s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.008785948467751345 Acc: 0.9976128472222222\n",
      "val Loss: 0.0015539871528744698 Acc: 1.0\n",
      "Epoch    56: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 56 of 500 took 0.397s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0074165308227141695 Acc: 0.9973958333333334\n",
      "val Loss: 0.0013924147933721542 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.403s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.01161578395921323 Acc: 0.9954427083333334\n",
      "val Loss: 0.002371756359934807 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.401s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.015140739683475759 Acc: 0.9945746527777778\n",
      "val Loss: 0.0011747702956199646 Acc: 1.0\n",
      "New best validation loss: 0.0011747702956199646\n",
      "Epoch 59 of 500 took 0.394s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.011944239389979176 Acc: 0.9954427083333334\n",
      "val Loss: 0.0019078012555837631 Acc: 1.0\n",
      "Epoch 60 of 500 took 0.398s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.006494635483250022 Acc: 0.9978298611111112\n",
      "val Loss: 0.0012718643993139267 Acc: 1.0\n",
      "Epoch 61 of 500 took 0.400s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.0071502625942230225 Acc: 0.998046875\n",
      "val Loss: 0.0015245284885168076 Acc: 1.0\n",
      "Epoch 62 of 500 took 0.452s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.00647966092866328 Acc: 0.9971788194444444\n",
      "val Loss: 0.0018907459452748299 Acc: 1.0\n",
      "Epoch 63 of 500 took 0.410s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.008276498203890191 Acc: 0.998046875\n",
      "val Loss: 0.0009226826950907707 Acc: 1.0\n",
      "New best validation loss: 0.0009226826950907707\n",
      "Epoch 64 of 500 took 0.399s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.00898102562253674 Acc: 0.9969618055555556\n",
      "val Loss: 0.0018767556175589561 Acc: 1.0\n",
      "Epoch 65 of 500 took 0.395s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.005820469568587012 Acc: 0.9982638888888888\n",
      "val Loss: 0.0015323227271437645 Acc: 1.0\n",
      "Epoch 66 of 500 took 0.430s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.006700992584228516 Acc: 0.998046875\n",
      "val Loss: 0.002411479130387306 Acc: 1.0\n",
      "Epoch 67 of 500 took 0.416s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.009608035544968314 Acc: 0.9956597222222222\n",
      "val Loss: 0.0014361552894115448 Acc: 1.0\n",
      "Epoch 68 of 500 took 0.545s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0072213612082931734 Acc: 0.9973958333333334\n",
      "val Loss: 0.0010619638487696648 Acc: 1.0\n",
      "Epoch 69 of 500 took 0.563s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.009311155364331272 Acc: 0.9956597222222222\n",
      "val Loss: 0.001174774020910263 Acc: 1.0\n",
      "Epoch    70: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 70 of 500 took 0.559s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.009801763575524092 Acc: 0.9950086805555556\n",
      "val Loss: 0.0011872751638293266 Acc: 1.0\n",
      "Epoch 71 of 500 took 0.589s\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.005675433358798425 Acc: 0.9984809027777778\n",
      "val Loss: 0.0009938469156622887 Acc: 1.0\n",
      "Epoch 72 of 500 took 0.565s\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.004852622643940979 Acc: 0.9982638888888888\n",
      "val Loss: 0.0010103145614266396 Acc: 1.0\n",
      "Epoch 73 of 500 took 0.596s\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.005726353886226813 Acc: 0.9984809027777778\n",
      "val Loss: 0.0011475058272480965 Acc: 1.0\n",
      "Epoch 74 of 500 took 0.533s\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.0048334248260491425 Acc: 0.9986979166666666\n",
      "val Loss: 0.0009457245469093323 Acc: 1.0\n",
      "Epoch 75 of 500 took 0.623s\n",
      "\n",
      "Training complete in 0m 32s\n",
      "Best val loss: 0.000923\n",
      "ACCURACY TEST_0 FINAL : 91.090 %\n",
      "ACCURACY TEST_1 FINAL : 92.484 %\n",
      "CURRENT DATASET :  16\n",
      "(5312, 1, 8, 52)\n",
      "SourceNetwork(\n",
      "  (_conv1): Conv2d(1, 32, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu1): PReLU(num_parameters=32)\n",
      "  (_dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (_conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (_pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu2): PReLU(num_parameters=64)\n",
      "  (_dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (_fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (_batch_norm3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (_prelu3): PReLU(num_parameters=500)\n",
      "  (_dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (_output): Linear(in_features=500, out_features=7, bias=True)\n",
      ")\n",
      "Number Parameters:  549091\n",
      "Number Parameters:  1098778\n",
      "odict_keys(['_conv1', '_pool1', '_batch_norm1', '_prelu1', '_dropout1', '_conv2', '_pool2', '_batch_norm2', '_prelu2', '_dropout2', '_fc1', '_batch_norm3', '_prelu3', '_dropout3', '_output'])\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.6241288201676475 Acc: 0.7801649305555556\n",
      "val Loss: 0.08007173612713814 Acc: 0.970703125\n",
      "New best validation loss: 0.08007173612713814\n",
      "Epoch 1 of 500 took 0.336s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.15999165922403336 Acc: 0.9385850694444444\n",
      "val Loss: 0.04767232947051525 Acc: 0.982421875\n",
      "New best validation loss: 0.04767232947051525\n",
      "Epoch 2 of 500 took 0.538s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.0923164693845643 Acc: 0.9639756944444444\n",
      "val Loss: 0.040141637437045574 Acc: 0.986328125\n",
      "New best validation loss: 0.040141637437045574\n",
      "Epoch 3 of 500 took 0.606s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.08495902704695861 Acc: 0.9674479166666666\n",
      "val Loss: 0.038989389315247536 Acc: 0.984375\n",
      "New best validation loss: 0.038989389315247536\n",
      "Epoch 4 of 500 took 0.495s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.0785022032343679 Acc: 0.96875\n",
      "val Loss: 0.02131505310535431 Acc: 0.994140625\n",
      "New best validation loss: 0.02131505310535431\n",
      "Epoch 5 of 500 took 0.439s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.06855102669861582 Acc: 0.9741753472222222\n",
      "val Loss: 0.026098771020770073 Acc: 0.990234375\n",
      "Epoch 6 of 500 took 0.345s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.05287373552305831 Acc: 0.9813368055555556\n",
      "val Loss: 0.02364099957048893 Acc: 0.9921875\n",
      "Epoch 7 of 500 took 0.346s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.046089810940126576 Acc: 0.9837239583333334\n",
      "val Loss: 0.014068678952753544 Acc: 0.99609375\n",
      "New best validation loss: 0.014068678952753544\n",
      "Epoch 8 of 500 took 0.348s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.04970103543665674 Acc: 0.98046875\n",
      "val Loss: 0.015644933562725782 Acc: 0.994140625\n",
      "Epoch 9 of 500 took 0.400s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.05052098362810082 Acc: 0.9806857638888888\n",
      "val Loss: 0.0260061239823699 Acc: 0.990234375\n",
      "Epoch 10 of 500 took 0.353s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.034522778251104884 Acc: 0.9878472222222222\n",
      "val Loss: 0.01153042446821928 Acc: 0.994140625\n",
      "New best validation loss: 0.01153042446821928\n",
      "Epoch 11 of 500 took 0.409s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.031224129825002618 Acc: 0.9891493055555556\n",
      "val Loss: 0.00976147223263979 Acc: 0.998046875\n",
      "New best validation loss: 0.00976147223263979\n",
      "Epoch 12 of 500 took 0.365s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.03417301426331202 Acc: 0.9869791666666666\n",
      "val Loss: 0.012097714468836784 Acc: 0.998046875\n",
      "Epoch 13 of 500 took 0.370s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.039602898268236056 Acc: 0.9835069444444444\n",
      "val Loss: 0.007295290008187294 Acc: 0.998046875\n",
      "New best validation loss: 0.007295290008187294\n",
      "Epoch 14 of 500 took 0.343s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.029866421905656654 Acc: 0.9893663194444444\n",
      "val Loss: 0.009491551667451859 Acc: 0.99609375\n",
      "Epoch 15 of 500 took 0.353s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.022964169633471303 Acc: 0.9930555555555556\n",
      "val Loss: 0.007429864257574081 Acc: 0.998046875\n",
      "Epoch 16 of 500 took 0.426s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.034125074123342834 Acc: 0.9889322916666666\n",
      "val Loss: 0.009320677258074284 Acc: 0.99609375\n",
      "Epoch 17 of 500 took 0.393s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.03365421807393432 Acc: 0.9869791666666666\n",
      "val Loss: 0.005793058313429356 Acc: 1.0\n",
      "New best validation loss: 0.005793058313429356\n",
      "Epoch 18 of 500 took 0.384s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.02479118336406019 Acc: 0.9913194444444444\n",
      "val Loss: 0.005496184341609478 Acc: 0.998046875\n",
      "New best validation loss: 0.005496184341609478\n",
      "Epoch 19 of 500 took 0.341s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.021273865312751796 Acc: 0.9924045138888888\n",
      "val Loss: 0.006321044638752937 Acc: 0.998046875\n",
      "Epoch 20 of 500 took 0.327s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.019648784616341192 Acc: 0.9930555555555556\n",
      "val Loss: 0.004131031222641468 Acc: 1.0\n",
      "New best validation loss: 0.004131031222641468\n",
      "Epoch 21 of 500 took 0.339s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.020513140130788088 Acc: 0.9932725694444444\n",
      "val Loss: 0.004188754595816135 Acc: 0.998046875\n",
      "Epoch 22 of 500 took 0.332s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.01778254026754035 Acc: 0.9945746527777778\n",
      "val Loss: 0.0032192524522542953 Acc: 1.0\n",
      "New best validation loss: 0.0032192524522542953\n",
      "Epoch 23 of 500 took 0.335s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.01938261991987626 Acc: 0.9934895833333334\n",
      "val Loss: 0.003187159076333046 Acc: 1.0\n",
      "New best validation loss: 0.003187159076333046\n",
      "Epoch 24 of 500 took 0.340s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.019861705859916076 Acc: 0.9930555555555556\n",
      "val Loss: 0.008325557224452496 Acc: 0.998046875\n",
      "Epoch 25 of 500 took 0.381s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.02178192511200905 Acc: 0.9930555555555556\n",
      "val Loss: 0.004275031387805939 Acc: 1.0\n",
      "Epoch 26 of 500 took 0.337s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.024578870739787817 Acc: 0.9900173611111112\n",
      "val Loss: 0.003619726747274399 Acc: 1.0\n",
      "Epoch 27 of 500 took 0.355s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.020195578121476702 Acc: 0.9921875\n",
      "val Loss: 0.002254719380289316 Acc: 1.0\n",
      "New best validation loss: 0.002254719380289316\n",
      "Epoch 28 of 500 took 0.359s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.011188769506083595 Acc: 0.9967447916666666\n",
      "val Loss: 0.003053886815905571 Acc: 1.0\n",
      "Epoch 29 of 500 took 0.342s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.013828269516428312 Acc: 0.9950086805555556\n",
      "val Loss: 0.001658647321164608 Acc: 1.0\n",
      "New best validation loss: 0.001658647321164608\n",
      "Epoch 30 of 500 took 0.356s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.013257951475679874 Acc: 0.9952256944444444\n",
      "val Loss: 0.0016145315021276474 Acc: 1.0\n",
      "New best validation loss: 0.0016145315021276474\n",
      "Epoch 31 of 500 took 0.336s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.014745277042190233 Acc: 0.99609375\n",
      "val Loss: 0.002003464847803116 Acc: 1.0\n",
      "Epoch 32 of 500 took 0.413s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.014078081637207005 Acc: 0.9943576388888888\n",
      "val Loss: 0.0030219657346606255 Acc: 0.998046875\n",
      "Epoch 33 of 500 took 0.358s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.0122455269512203 Acc: 0.9956597222222222\n",
      "val Loss: 0.001508120447397232 Acc: 1.0\n",
      "New best validation loss: 0.001508120447397232\n",
      "Epoch 34 of 500 took 0.341s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.015856762054479785 Acc: 0.9943576388888888\n",
      "val Loss: 0.0017879698425531387 Acc: 1.0\n",
      "Epoch 35 of 500 took 0.372s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.01600239353461398 Acc: 0.9947916666666666\n",
      "val Loss: 0.0020048003643751144 Acc: 1.0\n",
      "Epoch 36 of 500 took 0.312s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.01208104793396261 Acc: 0.9956597222222222\n",
      "val Loss: 0.0015018908306956291 Acc: 1.0\n",
      "New best validation loss: 0.0015018908306956291\n",
      "Epoch 37 of 500 took 0.360s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.01187444602449735 Acc: 0.9965277777777778\n",
      "val Loss: 0.0019688522443175316 Acc: 1.0\n",
      "Epoch 38 of 500 took 0.368s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.017010630056675937 Acc: 0.9934895833333334\n",
      "val Loss: 0.0015203412622213364 Acc: 1.0\n",
      "Epoch 39 of 500 took 0.569s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.01724788427559866 Acc: 0.9943576388888888\n",
      "val Loss: 0.0011407854035496712 Acc: 1.0\n",
      "New best validation loss: 0.0011407854035496712\n",
      "Epoch 40 of 500 took 0.401s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.012020833065940274 Acc: 0.9947916666666666\n",
      "val Loss: 0.0010326467454433441 Acc: 1.0\n",
      "New best validation loss: 0.0010326467454433441\n",
      "Epoch 41 of 500 took 0.434s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.010497122019943263 Acc: 0.9971788194444444\n",
      "val Loss: 0.0019013583660125732 Acc: 1.0\n",
      "Epoch 42 of 500 took 0.718s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.01146746069813768 Acc: 0.99609375\n",
      "val Loss: 0.0029696356505155563 Acc: 1.0\n",
      "Epoch 43 of 500 took 0.467s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.008636717011945115 Acc: 0.9954427083333334\n",
      "val Loss: 0.0013419250026345253 Acc: 1.0\n",
      "Epoch 44 of 500 took 0.301s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.011376347548017899 Acc: 0.9954427083333334\n",
      "val Loss: 0.0012761419638991356 Acc: 1.0\n",
      "Epoch 45 of 500 took 0.296s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.009827978339874081 Acc: 0.9963107638888888\n",
      "val Loss: 0.0010114172473549843 Acc: 1.0\n",
      "New best validation loss: 0.0010114172473549843\n",
      "Epoch 46 of 500 took 0.284s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.01121999261279901 Acc: 0.9958767361111112\n",
      "val Loss: 0.001062401570379734 Acc: 1.0\n",
      "Epoch 47 of 500 took 0.293s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.01498013703773419 Acc: 0.99609375\n",
      "val Loss: 0.0006682788953185081 Acc: 1.0\n",
      "New best validation loss: 0.0006682788953185081\n",
      "Epoch 48 of 500 took 0.289s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.009645302003870407 Acc: 0.9969618055555556\n",
      "val Loss: 0.0007012588903307915 Acc: 1.0\n",
      "Epoch 49 of 500 took 0.298s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.006604235567566421 Acc: 0.9973958333333334\n",
      "val Loss: 0.0008679041638970375 Acc: 1.0\n",
      "Epoch 50 of 500 took 0.289s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.009332951261765428 Acc: 0.9967447916666666\n",
      "val Loss: 0.000700710341334343 Acc: 1.0\n",
      "Epoch 51 of 500 took 0.295s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.008868325242979659 Acc: 0.9969618055555556\n",
      "val Loss: 0.0007588807493448257 Acc: 1.0\n",
      "Epoch 52 of 500 took 0.344s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.007151257505433427 Acc: 0.9978298611111112\n",
      "val Loss: 0.0004886044189333916 Acc: 1.0\n",
      "New best validation loss: 0.0004886044189333916\n",
      "Epoch 53 of 500 took 0.392s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.009766242208166255 Acc: 0.9963107638888888\n",
      "val Loss: 0.0005296450108289719 Acc: 1.0\n",
      "Epoch 54 of 500 took 0.316s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.008957658325218491 Acc: 0.9965277777777778\n",
      "val Loss: 0.00042378809303045273 Acc: 1.0\n",
      "New best validation loss: 0.00042378809303045273\n",
      "Epoch 55 of 500 took 0.300s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.013179720689853033 Acc: 0.9945746527777778\n",
      "val Loss: 0.00045548565685749054 Acc: 1.0\n",
      "Epoch 56 of 500 took 0.351s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.009789757275333008 Acc: 0.9965277777777778\n",
      "val Loss: 0.0005676904693245888 Acc: 1.0\n",
      "Epoch 57 of 500 took 0.299s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.009705275814566348 Acc: 0.9967447916666666\n",
      "val Loss: 0.0004580514505505562 Acc: 1.0\n",
      "Epoch 58 of 500 took 0.305s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.007098976367463668 Acc: 0.9971788194444444\n",
      "val Loss: 0.0005688853561878204 Acc: 1.0\n",
      "Epoch 59 of 500 took 0.300s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.01008064423998197 Acc: 0.9971788194444444\n",
      "val Loss: 0.0005328934639692307 Acc: 1.0\n",
      "Epoch 60 of 500 took 0.308s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.00953070100189911 Acc: 0.9963107638888888\n",
      "val Loss: 0.0004745339974761009 Acc: 1.0\n",
      "Epoch    61: reducing learning rate of group 0 to 4.6714e-04.\n",
      "Epoch 61 of 500 took 0.307s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.004870392951286501 Acc: 0.9984809027777778\n",
      "val Loss: 0.0003394884988665581 Acc: 1.0\n",
      "New best validation loss: 0.0003394884988665581\n",
      "Epoch 62 of 500 took 0.303s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.006232672784891393 Acc: 0.9986979166666666\n",
      "val Loss: 0.00029195379465818405 Acc: 1.0\n",
      "New best validation loss: 0.00029195379465818405\n",
      "Epoch 63 of 500 took 0.308s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.00738956354972389 Acc: 0.9967447916666666\n",
      "val Loss: 0.0003326553851366043 Acc: 1.0\n",
      "Epoch 64 of 500 took 0.312s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0061972797848284245 Acc: 0.9978298611111112\n",
      "val Loss: 0.0004216562956571579 Acc: 1.0\n",
      "Epoch 65 of 500 took 0.287s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.003961289767175913 Acc: 0.9986979166666666\n",
      "val Loss: 0.0003067236393690109 Acc: 1.0\n",
      "Epoch 66 of 500 took 0.281s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.006635996668289105 Acc: 0.9973958333333334\n",
      "val Loss: 0.0003210613504052162 Acc: 1.0\n",
      "Epoch 67 of 500 took 0.283s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.006864134274009202 Acc: 0.9976128472222222\n",
      "val Loss: 0.00033788103610277176 Acc: 1.0\n",
      "Epoch 68 of 500 took 0.320s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.004039494113789665 Acc: 0.9991319444444444\n",
      "val Loss: 0.0003221724182367325 Acc: 1.0\n",
      "Epoch    69: reducing learning rate of group 0 to 9.3429e-05.\n",
      "Epoch 69 of 500 took 0.338s\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.005605551414191723 Acc: 0.9982638888888888\n",
      "val Loss: 0.0003791525959968567 Acc: 1.0\n",
      "Epoch 70 of 500 took 0.316s\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.004412839085691505 Acc: 0.9989149305555556\n",
      "val Loss: 0.00036090798676013947 Acc: 1.0\n",
      "Epoch 71 of 500 took 0.296s\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.004863634498582946 Acc: 0.9984809027777778\n",
      "val Loss: 0.0003123898059129715 Acc: 1.0\n",
      "Epoch 72 of 500 took 0.284s\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.006869912199262116 Acc: 0.9978298611111112\n",
      "val Loss: 0.0003066370263695717 Acc: 1.0\n",
      "Epoch 73 of 500 took 0.294s\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.004702088992214865 Acc: 0.9986979166666666\n",
      "val Loss: 0.0002871323376893997 Acc: 1.0\n",
      "New best validation loss: 0.0002871323376893997\n",
      "Epoch 74 of 500 took 0.412s\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.0070073107360965675 Acc: 0.9973958333333334\n",
      "val Loss: 0.00029519200325012207 Acc: 1.0\n",
      "Epoch 75 of 500 took 0.306s\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.003790822397503588 Acc: 0.9993489583333334\n",
      "val Loss: 0.00029931310564279556 Acc: 1.0\n",
      "Epoch 76 of 500 took 0.315s\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.004751327344112926 Acc: 0.9984809027777778\n",
      "val Loss: 0.00028400495648384094 Acc: 1.0\n",
      "New best validation loss: 0.00028400495648384094\n",
      "Epoch 77 of 500 took 0.313s\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.00552408868033025 Acc: 0.9978298611111112\n",
      "val Loss: 0.00028114765882492065 Acc: 1.0\n",
      "New best validation loss: 0.00028114765882492065\n",
      "Epoch 78 of 500 took 0.313s\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.0038645269038776555 Acc: 0.9991319444444444\n",
      "val Loss: 0.00030785519629716873 Acc: 1.0\n",
      "Epoch 79 of 500 took 0.291s\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.006560553693109089 Acc: 0.9976128472222222\n",
      "val Loss: 0.0002972260117530823 Acc: 1.0\n",
      "Epoch 80 of 500 took 0.348s\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.006788835498607821 Acc: 0.9971788194444444\n",
      "val Loss: 0.0002787318080663681 Acc: 1.0\n",
      "New best validation loss: 0.0002787318080663681\n",
      "Epoch 81 of 500 took 0.304s\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.0068188934173021055 Acc: 0.9978298611111112\n",
      "val Loss: 0.00029153935611248016 Acc: 1.0\n",
      "Epoch 82 of 500 took 0.306s\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.005009408005409771 Acc: 0.9989149305555556\n",
      "val Loss: 0.0003020288422703743 Acc: 1.0\n",
      "Epoch 83 of 500 took 0.309s\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.003170920846362909 Acc: 0.9993489583333334\n",
      "val Loss: 0.00029251258820295334 Acc: 1.0\n",
      "Epoch 84 of 500 took 0.430s\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.004611963199244605 Acc: 0.9984809027777778\n",
      "val Loss: 0.0003023911267518997 Acc: 1.0\n",
      "Epoch 85 of 500 took 0.433s\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.0037425292862786185 Acc: 0.9991319444444444\n",
      "val Loss: 0.0002877935767173767 Acc: 1.0\n",
      "Epoch 86 of 500 took 0.447s\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.00420371846606334 Acc: 0.9989149305555556\n",
      "val Loss: 0.0003647534176707268 Acc: 1.0\n",
      "Epoch    87: reducing learning rate of group 0 to 1.8686e-05.\n",
      "Epoch 87 of 500 took 0.574s\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.004599105825440751 Acc: 0.9982638888888888\n",
      "val Loss: 0.00029148999601602554 Acc: 1.0\n",
      "Epoch 88 of 500 took 0.448s\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.003943025651905272 Acc: 0.9991319444444444\n",
      "val Loss: 0.0002972511574625969 Acc: 1.0\n",
      "Epoch 89 of 500 took 0.363s\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.003896146495309141 Acc: 0.9989149305555556\n",
      "val Loss: 0.0002892538905143738 Acc: 1.0\n",
      "Epoch 90 of 500 took 0.381s\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.0077412803657352924 Acc: 0.9982638888888888\n",
      "val Loss: 0.000311422161757946 Acc: 1.0\n",
      "Epoch 91 of 500 took 0.334s\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.0033926176321175364 Acc: 0.9989149305555556\n",
      "val Loss: 0.00027733761817216873 Acc: 1.0\n",
      "New best validation loss: 0.00027733761817216873\n",
      "Epoch 92 of 500 took 0.344s\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.005505510347170962 Acc: 0.9984809027777778\n",
      "val Loss: 0.00030251219868659973 Acc: 1.0\n",
      "Epoch 93 of 500 took 0.338s\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.005902707680231995 Acc: 0.9976128472222222\n",
      "val Loss: 0.0002438211813569069 Acc: 1.0\n",
      "New best validation loss: 0.0002438211813569069\n",
      "Epoch 94 of 500 took 0.336s\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.0023412818813489545 Acc: 0.9995659722222222\n",
      "val Loss: 0.0002724751830101013 Acc: 1.0\n",
      "Epoch 95 of 500 took 0.350s\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.005238557027445899 Acc: 0.9982638888888888\n",
      "val Loss: 0.00016503408551216125 Acc: 1.0\n",
      "New best validation loss: 0.00016503408551216125\n",
      "Epoch 96 of 500 took 0.357s\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.004914374815093147 Acc: 0.9989149305555556\n",
      "val Loss: 0.0002564378082752228 Acc: 1.0\n",
      "Epoch 97 of 500 took 0.355s\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.008015891278369559 Acc: 0.9971788194444444\n",
      "val Loss: 0.0002849726006388664 Acc: 1.0\n",
      "Epoch 98 of 500 took 0.423s\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.005468325585954719 Acc: 0.9976128472222222\n",
      "val Loss: 0.0003131888806819916 Acc: 1.0\n",
      "Epoch 99 of 500 took 0.329s\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.004423923273053434 Acc: 0.9984809027777778\n",
      "val Loss: 0.0002926373854279518 Acc: 1.0\n",
      "Epoch 100 of 500 took 0.320s\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.007131717892156707 Acc: 0.9976128472222222\n",
      "val Loss: 0.00029598455876111984 Acc: 1.0\n",
      "Epoch 101 of 500 took 0.342s\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.00449725276687079 Acc: 0.9986979166666666\n",
      "val Loss: 0.000252310186624527 Acc: 1.0\n",
      "Epoch   102: reducing learning rate of group 0 to 3.7372e-06.\n",
      "Epoch 102 of 500 took 0.302s\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.006406588583356804 Acc: 0.998046875\n",
      "val Loss: 0.00027910247445106506 Acc: 1.0\n",
      "Epoch 103 of 500 took 0.310s\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.006000390690233972 Acc: 0.9982638888888888\n",
      "val Loss: 0.0002808207646012306 Acc: 1.0\n",
      "Epoch 104 of 500 took 0.387s\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.004421882331371307 Acc: 0.9984809027777778\n",
      "val Loss: 0.0002819625660777092 Acc: 1.0\n",
      "Epoch 105 of 500 took 0.335s\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.004745144862681627 Acc: 0.9984809027777778\n",
      "val Loss: 0.0002652108669281006 Acc: 1.0\n",
      "Epoch 106 of 500 took 0.368s\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.003947742386824555 Acc: 0.9986979166666666\n",
      "val Loss: 0.00029249489307403564 Acc: 1.0\n",
      "Epoch 107 of 500 took 0.334s\n",
      "\n",
      "Training complete in 0m 38s\n",
      "Best val loss: 0.000165\n",
      "ACCURACY TEST_0 FINAL : 96.773 %\n",
      "ACCURACY TEST_1 FINAL : 98.760 %\n",
      "AVERAGE ACCURACY TEST 0 96.810\n",
      "AVERAGE ACCURACY TEST 1 97.577\n",
      "TEST 0 SO FAR:  [[99.41066997518611, 99.69021065675341, 92.44348095385568, 100.0, 99.81383803909401, 98.72789326714242, 99.34903905765654, 99.96901146575767, 99.93800371977682, 98.26356589147287, 98.91540130151844, 94.56859093730603, 99.37984496124031, 82.26906385616863, 98.78957169459963, 90.99658491151816, 96.12162581445858], [99.41066997518611, 99.90706319702602, 91.04986063796841, 100.0, 99.87589202606267, 98.75892026062675, 99.19404835709858, 100.0, 99.96900185988841, 99.1937984496124, 99.00836690424543, 93.85474860335195, 99.75193798449612, 79.41723496590204, 98.51024208566108, 91.08972368829556, 96.77319267762954]]\n",
      "TEST 1 SO FAR:  [[100.0, 99.25488978578082, 96.3975155279503, 99.9689633767846, 100.0, 91.692498450093, 100.0, 100.0, 99.9689633767846, 99.00836690424543, 98.10852713178295, 95.83980130394288, 99.22432516289172, 88.17504655493482, 99.84500929944204, 93.91304347826087, 99.34903905765654], [100.0, 99.7826761875194, 94.6583850931677, 99.9689633767846, 100.0, 93.58338499690018, 100.0, 100.0, 99.84481688392303, 99.87604586303068, 98.51162790697674, 94.93945979509469, 99.53459509773504, 87.02669149596524, 99.84500929944204, 92.48447204968944, 98.76007439553626]]\n",
      "CURRENT AVERAGE :  97.26431308865989\n",
      "ACCURACY FINAL TEST 0:  [[99.41066997518611, 99.69021065675341, 92.44348095385568, 100.0, 99.81383803909401, 98.72789326714242, 99.34903905765654, 99.96901146575767, 99.93800371977682, 98.26356589147287, 98.91540130151844, 94.56859093730603, 99.37984496124031, 82.26906385616863, 98.78957169459963, 90.99658491151816, 96.12162581445858], [99.41066997518611, 99.90706319702602, 91.04986063796841, 100.0, 99.87589202606267, 98.75892026062675, 99.19404835709858, 100.0, 99.96900185988841, 99.1937984496124, 99.00836690424543, 93.85474860335195, 99.75193798449612, 79.41723496590204, 98.51024208566108, 91.08972368829556, 96.77319267762954]]\n",
      "ACCURACY FINAL TEST 0:  96.89444406401637\n",
      "ACCURACY FINAL TEST 1:  [[100.0, 99.25488978578082, 96.3975155279503, 99.9689633767846, 100.0, 91.692498450093, 100.0, 100.0, 99.9689633767846, 99.00836690424543, 98.10852713178295, 95.83980130394288, 99.22432516289172, 88.17504655493482, 99.84500929944204, 93.91304347826087, 99.34903905765654], [100.0, 99.7826761875194, 94.6583850931677, 99.9689633767846, 100.0, 93.58338499690018, 100.0, 100.0, 99.84481688392303, 99.87604586303068, 98.51162790697674, 94.93945979509469, 99.53459509773504, 87.02669149596524, 99.84500929944204, 92.48447204968944, 98.76007439553626]]\n",
      "ACCURACY FINAL TEST 1:  97.6341821133034\n",
      "ACCURACY FINAL:  97.26431308865989\n"
     ]
    }
   ],
   "source": [
    "accuracy_one_by_one = []\n",
    "array_training_error = []\n",
    "array_validation_error = []\n",
    "# learning_rate=0.002335721469090121 (for network enhanced)\n",
    "\n",
    "\n",
    "# this is the number of times that the tests are repeated in full, more repeats means less chance for random variance\n",
    "number_repeated_tests=2\n",
    "\n",
    "with open(\"results/evaluation_dataset_TARGET_convnet_enhanced.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"Test\")\n",
    "    \n",
    "    \n",
    "# I changed it so it only runs the trial with number 4\n",
    "\n",
    "    \n",
    "for training_cycle in range(4, 5):\n",
    "    test_0 = []\n",
    "    test_1 = []\n",
    "    for i in range(number_repeated_tests):\n",
    "        accuracy_test0, accuracy_test1 = calculate_fitness(examples_training, labels_training, examples_test0,\n",
    "                                                           labels_test0, examples_test1, labels_test1,\n",
    "                                                           learning_rate=0.002335721469090121,\n",
    "                                                           training_cycle=training_cycle)\n",
    "\n",
    "        test_0.append(accuracy_test0)\n",
    "        test_1.append(accuracy_test1)\n",
    "        print(\"TEST 0 SO FAR: \", test_0)\n",
    "        print(\"TEST 1 SO FAR: \", test_1)\n",
    "        print(\"CURRENT AVERAGE : \", (np.mean(test_0) + np.mean(test_1)) / 2.)\n",
    "\n",
    "    print(\"ACCURACY FINAL TEST 0: \", test_0)\n",
    "    print(\"ACCURACY FINAL TEST 0: \", np.mean(test_0))\n",
    "    print(\"ACCURACY FINAL TEST 1: \", test_1)\n",
    "    print(\"ACCURACY FINAL TEST 1: \", np.mean(test_1))\n",
    "    print(\"ACCURACY FINAL: \", (np.mean(test_0) + np.mean(test_1)) / 2.)\n",
    "\n",
    "    with open(\"results/evaluation_dataset_TARGET_convnet_enhanced.txt\", \"a\") as myfile:\n",
    "        myfile.write(\"ConvNet Training Cycle : \" + str(training_cycle) + \"\\n\\n\")\n",
    "        myfile.write(\"Test 0: \\n\")\n",
    "        myfile.write(str(test_0) + '\\n')\n",
    "        myfile.write(str(np.mean(test_0, axis=0)) + '\\n')\n",
    "        myfile.write(str(np.mean(test_0)) + '\\n')\n",
    "        myfile.write(\"Test 1: \\n\")\n",
    "        myfile.write(str(test_1) + '\\n')\n",
    "        myfile.write(str(np.mean(test_1, axis=0)) + '\\n')\n",
    "        myfile.write(str(np.mean(test_1)) + '\\n')\n",
    "        myfile.write(\"Test Mean: \\n\")\n",
    "        myfile.write(str(np.mean(test_0, axis=0)) + '\\n')\n",
    "        myfile.write(str((np.mean(test_0) + np.mean(test_1)) / 2.) + '\\n')\n",
    "        myfile.write(\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of File\n",
    "\n",
    "**Check `results/evaluation_dataset_TARGET_convnet_enhanced.txt` for helpful metrics. Most of it will appear as arrays that are 17 long, indicating the 17 patients that the results are averaged over.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
